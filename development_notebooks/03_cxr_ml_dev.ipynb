{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is concerned with running various ML models on chest imaging reports, and various aspects of its implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic imports\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm   # For keeping track of loops\n",
    "from joblib import Parallel, delayed\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom imports\n",
    "from custom_functions import *\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import src.plots as plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set plotting params\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "plt.style.reload_library()\n",
    "rcparams = plots.stdrcparams1()\n",
    "mpl.rcParams.update(rcparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models/algorithms/classifiers\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Evaluation of models\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import *\n",
    "\n",
    "# Text vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data: Hospital A (2013), Hospital A (2016), Hospital B (2017-18), and MIMIC III."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data locations\n",
    "basedir = Path(\"../..\")\n",
    "training_path = basedir / \"Analysis_Data\" / \"train_ML\"\n",
    "train_data1a = training_path / 'hospital_a_2013_bi_data_processed_minus_history_plus_conclusion-03-2021.csv'\n",
    "train_data1b = training_path / 'hospital_a_2013_cxr_annotated.csv'\n",
    "\n",
    "train_data2 = training_path / 'hospital_a_2016_bi_data_processed_minus_history_plus_conclusion.csv'\n",
    "\n",
    "test_data3a = training_path / 'hospital_b_2017_cxr_annotated.csv'\n",
    "test_data3b = training_path / 'hospital_b_2017_cxr_annotated_2023_jesse_curt_merged.csv'\n",
    "test_data3c = training_path / 'hospital_b_2017_cxr_annotated_2023_three_annotators_merged.csv'\n",
    "test_data3_whole = basedir / \"Analysis_Data\" / \"hospital_b_2017\" / 'cxr.csv'\n",
    "\n",
    "whole_cxr_training = training_path / \"cxr_whole_training_dataset.csv\"\n",
    "\n",
    "mimic3_path = basedir / \"Analysis_Data\" / \"MIMIC_III\" / \"labeled_subset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figures\n",
    "figure_path = basedir / \"Figures\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hospital A (2013) read in and minor processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust which to read in desired Hospital A (2013) CXR reports\n",
    "# 'a' is for originally processed file\n",
    "# 'b' is for file processed by pipeline\n",
    "which = 'b'\n",
    "cols = {\n",
    "        'a': ['segmented_report', 'score'],\n",
    "        'b': ['seg_cxr_text', 'cxr_score']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which == 'a':\n",
    "    # open Hospital A (2013) processed files - segmented_reports\n",
    "    segmented = pd.read_csv(train_data1a)\n",
    "    segmented = segmented.drop(columns='Unnamed: 0').drop_duplicates()\n",
    "    \n",
    "elif which == 'b':\n",
    "    # open Hospital A (2013) processed files - segmented_reports\n",
    "    segmented = pd.read_csv(train_data1b)\n",
    "    \n",
    "else:\n",
    "    raise ValueError(\"Type either 'a' or 'b', lower case.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing remaining punctuation marks.\n",
    "segmented[cols[which][0]] = segmented[cols[which][0]].str.replace(r\"'\", r\"\", regex=True)\n",
    "segmented[cols[which][0]] = segmented[cols[which][0]].str.replace(r\"\\[\", r\"\", regex=True)\n",
    "segmented[cols[which][0]] = segmented[cols[which][0]].str.replace(r\"]\", r\"\", regex=True)\n",
    "segmented[cols[which][0]] = segmented[cols[which][0]].str.replace(r\",\", r\"\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hospital A (2016) read in and minor processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_cohort2 = pd.read_csv(train_data2)\n",
    "\n",
    "# Replace some remaining punctuation marks\n",
    "segmented_cohort2[\"segmented_report\"] = segmented_cohort2[\"segmented_report\"].str.replace(r\"'\", r\"\", regex=True)\n",
    "segmented_cohort2[\"segmented_report\"] = segmented_cohort2[\"segmented_report\"].str.replace(r\"\\[\", r\"\", regex=True)\n",
    "segmented_cohort2[\"segmented_report\"] = segmented_cohort2[\"segmented_report\"].str.replace(r\"\\]\", r\"\", regex=True)\n",
    "segmented_cohort2[\"segmented_report\"] = segmented_cohort2[\"segmented_report\"].str.replace(r\",\", r\"\", regex=True)\n",
    "segmented_cohort2 = segmented_cohort2.drop(columns='Unnamed: 0').drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hospital B (2017-2018) read in and minor processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_cohort3_original = pd.read_csv(test_data3a)\n",
    "\n",
    "# Removing remaining punctuation marks\n",
    "segmented_cohort3_original['seg_cxr_text'] = segmented_cohort3_original['seg_cxr_text'].str.replace(r\"'\", r\"\", regex=True)\n",
    "segmented_cohort3_original['seg_cxr_text'] = segmented_cohort3_original['seg_cxr_text'].str.replace(r\"\\[\", r\"\", regex=True)\n",
    "segmented_cohort3_original['seg_cxr_text'] = segmented_cohort3_original['seg_cxr_text'].str.replace(r\"\\]\", r\"\", regex=True)\n",
    "segmented_cohort3_original['seg_cxr_text'] = segmented_cohort3_original['seg_cxr_text'].str.replace(r\",\", r\"\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CXR whole training dataset read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(whole_cxr_training)\n",
    "\n",
    "# Removing remaining punctuation marks\n",
    "training_data['seg_cxr_text'] = training_data['seg_cxr_text'].str.replace(r\"'\", r\"\", regex=True)\n",
    "training_data['seg_cxr_text'] = training_data['seg_cxr_text'].str.replace(r\"\\[\", r\"\", regex=True)\n",
    "training_data['seg_cxr_text'] = training_data['seg_cxr_text'].str.replace(r\"\\]\", r\"\", regex=True)\n",
    "training_data['seg_cxr_text'] = training_data['seg_cxr_text'].str.replace(r\",\", r\"\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating bootstrapped AUCs, calibration, and feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_boot = 100   # Make smaller if wanting the notebook to run faster.\n",
    "n_boot1 = 10\n",
    "\n",
    "XG_test_auc = []\n",
    "XG_tprs = []\n",
    "XG_fops = []\n",
    "XG_preds = []\n",
    "XG_dws = []\n",
    "XG_importances = []\n",
    "\n",
    "LR_test_auc = []\n",
    "LR_tprs = []\n",
    "LR_fops = []\n",
    "LR_preds = []\n",
    "LR_dws = []\n",
    "LR_importances = []\n",
    "\n",
    "RF_test_auc = []\n",
    "RF_tprs = []\n",
    "RF_fops = []\n",
    "RF_preds = []\n",
    "RF_dws = []\n",
    "RF_importances = []\n",
    "\n",
    "DT_test_auc = []\n",
    "DT_tprs = []\n",
    "DT_fops = []\n",
    "DT_preds = []\n",
    "DT_dws = []\n",
    "DT_importances = []\n",
    "\n",
    "mean_fpr = np.arange(0, 1.01, 0.01)\n",
    "mean_mpv = np.arange(0, 1.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A lot of graphs generated by this notebook depend on this loop, including the calibration curve\n",
    "# (which is part of the panel where the interrater agreement graph is)\n",
    "if __name__ == '__main__':\n",
    "    for i in tqdm(range(n_boot1)):\n",
    "\n",
    "        # This line resamples the data, WITH replacement\n",
    "        boot_segmented = training_data.sample(n=len(training_data), replace=True, axis=0)\n",
    "        \n",
    "        encounters = boot_segmented['encounter_id'].unique()\n",
    "        cv = KFold()\n",
    "        \n",
    "        # # Accounting for potential label imbalance\n",
    "        # count_0 = pd.Series(y_train).value_counts()[0]\n",
    "        # count_1 = pd.Series(y_train).value_counts()[1]\n",
    "        # weight_0 = count_0 / len(y_train)\n",
    "        # weight_1 = count_1 / len(y_train)\n",
    "        # print(f\" %No: {weight_0*100:.2f}%, %Yes: {weight_1*100:.2f}%\")\n",
    "        \n",
    "        # Training each model\n",
    "        print(\"Working on XGBoost\")\n",
    "        output1, output2, output3, output4, output5 = Parallel(n_jobs=5)(delayed(nested_cv)(\n",
    "            boot_segmented,\n",
    "            cols,\n",
    "            which,\n",
    "            encounters,\n",
    "            train_index,\n",
    "            test_index,\n",
    "            mean_fpr,\n",
    "            mean_mpv,\n",
    "            model=\"XGBoost\"\n",
    "            ) for train_index, test_index in cv.split(encounters))\n",
    "        \n",
    "        XG_test_auc.append(np.mean([output1[0], output2[0], output3[0], output4[0], output5[0]]))\n",
    "        XG_preds.extend(output1[1])\n",
    "        XG_preds.extend(output2[1])\n",
    "        XG_preds.extend(output3[1])\n",
    "        XG_preds.extend(output4[1])\n",
    "        XG_preds.extend(output5[1])\n",
    "        XG_tprs.append(np.mean([output1[2], output2[2], output3[2], output4[2], output5[2]], axis=0))\n",
    "        XG_fops.append(np.mean([output1[3], output2[3], output3[3], output4[3], output5[3]], axis=0))\n",
    "        XG_dws.append(np.mean([output1[5], output2[5], output3[5], output4[5], output5[5]], axis=0))\n",
    "        XG_importances.extend(pd.DataFrame(\n",
    "            output1[6]+output2[6]+output3[6]+output4[6]+output5[6]).groupby('feature').mean().reset_index().to_dict(orient='records'))\n",
    "        \n",
    "\n",
    "        print(\"Working on Logistic Regression\")\n",
    "        output1, output2, output3, output4, output5 = Parallel(n_jobs=5)(delayed(nested_cv)(\n",
    "            boot_segmented,\n",
    "            cols,\n",
    "            which,\n",
    "            encounters,\n",
    "            train_index,\n",
    "            test_index,\n",
    "            mean_fpr,\n",
    "            mean_mpv,\n",
    "            model=\"LogisticRegression\"\n",
    "            ) for train_index, test_index in cv.split(encounters))\n",
    "        \n",
    "        LR_test_auc.append(np.mean([output1[0], output2[0], output3[0], output4[0], output5[0]]))\n",
    "        LR_preds.extend(output1[1])\n",
    "        LR_preds.extend(output2[1])\n",
    "        LR_preds.extend(output3[1])\n",
    "        LR_preds.extend(output4[1])\n",
    "        LR_preds.extend(output5[1])\n",
    "        LR_tprs.append(np.mean([output1[2], output2[2], output3[2], output4[2], output5[2]], axis=0))\n",
    "        LR_fops.append(np.mean([output1[3], output2[3], output3[3], output4[3], output5[3]], axis=0))\n",
    "        LR_dws.append(np.mean([output1[5], output2[5], output3[5], output4[5], output5[5]], axis=0))\n",
    "        LR_importances.extend(pd.DataFrame(\n",
    "            output1[6]+output2[6]+output3[6]+output4[6]+output5[6]).groupby('feature').mean().reset_index().to_dict(orient='records'))\n",
    "\n",
    "\n",
    "        print(\"Working on Random Forest\")\n",
    "        output1, output2, output3, output4, output5 = Parallel(n_jobs=5)(delayed(nested_cv)(\n",
    "            boot_segmented,\n",
    "            cols,\n",
    "            which,\n",
    "            encounters,\n",
    "            train_index,\n",
    "            test_index,\n",
    "            mean_fpr,\n",
    "            mean_mpv,\n",
    "            model=\"RandomForest\"\n",
    "            ) for train_index, test_index in cv.split(encounters))\n",
    "        \n",
    "        RF_test_auc.append(np.mean([output1[0], output2[0], output3[0], output4[0], output5[0]]))\n",
    "        RF_preds.extend(output1[1])\n",
    "        RF_preds.extend(output2[1])\n",
    "        RF_preds.extend(output3[1])\n",
    "        RF_preds.extend(output4[1])\n",
    "        RF_preds.extend(output5[1])\n",
    "        RF_tprs.append(np.mean([output1[2], output2[2], output3[2], output4[2], output5[2]], axis=0))\n",
    "        RF_fops.append(np.mean([output1[3], output2[3], output3[3], output4[3], output5[3]], axis=0))\n",
    "        RF_dws.append(np.mean([output1[5], output2[5], output3[5], output4[5], output5[5]], axis=0))\n",
    "        RF_importances.extend(pd.DataFrame(\n",
    "            output1[6]+output2[6]+output3[6]+output4[6]+output5[6]).groupby('feature').mean().reset_index().to_dict(orient='records'))\n",
    "\n",
    "\n",
    "        print(\"Working on Decision Tree\")\n",
    "        output1, output2, output3, output4, output5 = Parallel(n_jobs=5)(delayed(nested_cv)(\n",
    "            boot_segmented,\n",
    "            cols,\n",
    "            which,\n",
    "            encounters,\n",
    "            train_index,\n",
    "            test_index,\n",
    "            mean_fpr,\n",
    "            mean_mpv,\n",
    "            model=\"DecisionTree\"\n",
    "            ) for train_index, test_index in cv.split(encounters))\n",
    "            \n",
    "        DT_test_auc.append(np.mean([output1[0], output2[0], output3[0], output4[0], output5[0]]))\n",
    "        DT_preds.extend(output1[1])\n",
    "        DT_preds.extend(output2[1])\n",
    "        DT_preds.extend(output3[1])\n",
    "        DT_preds.extend(output4[1])\n",
    "        DT_preds.extend(output5[1])\n",
    "        DT_tprs.append(np.mean([output1[2], output2[2], output3[2], output4[2], output5[2]], axis=0))\n",
    "        DT_fops.append(np.mean([output1[3], output2[3], output3[3], output4[3], output5[3]], axis=0))\n",
    "        DT_dws.append(np.mean([output1[5], output2[5], output3[5], output4[5], output5[5]], axis=0))\n",
    "        DT_importances.extend(pd.DataFrame( \n",
    "            output1[6]+output2[6]+output3[6]+output4[6]+output5[6]).groupby('feature').mean().reset_index().to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might want to save results here since the above loop takes hours to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XG_data = {\n",
    "#     \"XG_test_auc\": XG_test_auc,\n",
    "#     \"XG_tprs\": XG_tprs,\n",
    "#     \"XG_fops\": XG_fops,\n",
    "#     \"XG_preds\": XG_preds,\n",
    "#     \"XG_dws\": XG_dws,\n",
    "#     \"XG_importances\": XG_importances,\n",
    "# }\n",
    "\n",
    "# LR_data = {\n",
    "#     \"LR_test_auc\": LR_test_auc,\n",
    "#     \"LR_tprs\": LR_tprs,\n",
    "#     \"LR_fops\": LR_fops,\n",
    "#     \"LR_preds\": LR_preds,\n",
    "#     \"LR_dws\": LR_dws,\n",
    "#     \"LR_importances\": LR_importances,\n",
    "# }\n",
    "\n",
    "# RF_data = {\n",
    "#     \"RF_test_auc\": RF_test_auc,\n",
    "#     \"RF_tprs\": RF_tprs,\n",
    "#     \"RF_fops\": RF_fops,\n",
    "#     \"RF_preds\": RF_preds,\n",
    "#     \"RF_dws\": RF_dws,\n",
    "#     \"RF_importances\": RF_importances,\n",
    "# }\n",
    "\n",
    "# DT_data = {\n",
    "#     \"DT_test_auc\": DT_test_auc,\n",
    "#     \"DT_tprs\": DT_tprs,\n",
    "#     \"DT_fops\": DT_fops,\n",
    "#     \"DT_preds\": DT_preds,\n",
    "#     \"DT_dws\": DT_dws,\n",
    "#     \"DT_importances\": DT_importances,\n",
    "# }\n",
    "\n",
    "\n",
    "# with open(\"XG_data.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(XG_data, file)\n",
    "    \n",
    "# with open(\"LR_data.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(LR_data, file)\n",
    "    \n",
    "# with open(\"RF_data.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(RF_data, file)\n",
    "    \n",
    "# with open(\"DT_data.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(DT_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can load the data from the pickle files\n",
    "with open(\"XG_data.pkl\", \"rb\") as file:\n",
    "    XG_data = pickle.load(file)\n",
    "    \n",
    "with open(\"LR_data.pkl\", \"rb\") as file:\n",
    "    LR_data = pickle.load(file)\n",
    "    \n",
    "with open(\"RF_data.pkl\", \"rb\") as file:\n",
    "    RF_data = pickle.load(file)\n",
    "    \n",
    "with open(\"DT_data.pkl\", \"rb\") as file:\n",
    "    DT_data = pickle.load(file)\n",
    "    \n",
    "\n",
    "XG_test_auc = XG_data['XG_test_auc']\n",
    "XG_tprs = XG_data['XG_tprs']\n",
    "XG_fops = XG_data['XG_fops']\n",
    "XG_preds = XG_data['XG_preds']\n",
    "XG_dws = XG_data['XG_dws']\n",
    "XG_importances = XG_data['XG_importances']\n",
    "\n",
    "LR_test_auc = LR_data['LR_test_auc']\n",
    "LR_tprs = LR_data['LR_tprs']\n",
    "LR_fops = LR_data['LR_fops']\n",
    "LR_preds = LR_data['LR_preds']\n",
    "LR_dws = LR_data['LR_dws']\n",
    "LR_importances = LR_data['LR_importances']\n",
    "\n",
    "RF_test_auc = RF_data['RF_test_auc']\n",
    "RF_tprs = RF_data['RF_tprs']\n",
    "RF_fops = RF_data['RF_fops']\n",
    "RF_preds = RF_data['RF_preds']\n",
    "RF_dws = RF_data['RF_dws']\n",
    "RF_importances = RF_data['RF_importances']\n",
    "\n",
    "DT_test_auc = DT_data['DT_test_auc']\n",
    "DT_tprs = DT_data['DT_tprs']\n",
    "DT_fops = DT_data['DT_fops']\n",
    "DT_preds = DT_data['DT_preds']\n",
    "DT_dws = DT_data['DT_dws']\n",
    "DT_importances = DT_data['DT_importances']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modifying data collected in the loop, for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "mean_DT_tpr = np.mean(DT_tprs, axis=0)\n",
    "mean_DT_tpr[-1] = 1.0\n",
    "DT_tpr_CI95 = [\n",
    "        np.percentile(DT_tprs, 2.5, axis=0),\n",
    "        np.percentile(DT_tprs, 97.5, axis=0)\n",
    "        ]\n",
    "\n",
    "mean_DT_auc = np.mean(DT_test_auc)\n",
    "DT_auc_CI95 = [\n",
    "        np.percentile(DT_test_auc, 2.5),\n",
    "        np.percentile(DT_test_auc, 97.5)\n",
    "        ]\n",
    "\n",
    "DT_importances_df = pd.DataFrame(DT_importances)\n",
    "\n",
    "mean_DT_fop = np.mean(DT_fops, axis=0)\n",
    "DT_fop_CI95 = [\n",
    "        np.percentile(DT_fops, 2.5, axis=0),\n",
    "        np.percentile(DT_fops, 97.5, axis=0)\n",
    "        ]\n",
    "mean_DT_dws = np.mean(DT_dws, axis=0)\n",
    "DT_dws_CI95 = [\n",
    "        np.percentile(DT_dws, 2.5, axis=0),\n",
    "        np.percentile(DT_dws, 97.5, axis=0)\n",
    "        ]\n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "mean_LR_tpr = np.mean(LR_tprs, axis=0)\n",
    "mean_LR_tpr[-1] = 1.0\n",
    "LR_tpr_CI95 = [\n",
    "        np.percentile(LR_tprs, 2.5, axis=0),\n",
    "        np.percentile(LR_tprs, 97.5, axis=0)\n",
    "        ]\n",
    "\n",
    "mean_LR_auc = np.mean(LR_test_auc)\n",
    "LR_auc_CI95 = [\n",
    "        np.percentile(LR_test_auc, 2.5),\n",
    "        np.percentile(LR_test_auc, 97.5)\n",
    "        ]\n",
    "\n",
    "LR_importances_df = pd.DataFrame(LR_importances)\n",
    "\n",
    "mean_LR_fop = np.mean(LR_fops, axis=0)\n",
    "LR_fop_CI95 = [\n",
    "        np.percentile(LR_fops, 2.5, axis=0),\n",
    "        np.percentile(LR_fops, 97.5, axis=0)\n",
    "        ]\n",
    "mean_LR_dws = np.mean(LR_dws, axis=0)\n",
    "LR_dws_CI95 = [\n",
    "        np.percentile(LR_dws, 2.5, axis=0),\n",
    "        np.percentile(LR_dws, 97.5, axis=0)\n",
    "        ]\n",
    "\n",
    "\n",
    "# Random Forest\n",
    "mean_RF_tpr = np.mean(RF_tprs, axis=0)\n",
    "mean_RF_tpr[-1] = 1.0\n",
    "RF_tpr_CI95 = [\n",
    "        np.percentile(RF_tprs, 2.5, axis=0),\n",
    "        np.percentile(RF_tprs, 97.5, axis=0)\n",
    "        ]\n",
    "\n",
    "mean_RF_auc = np.mean(RF_test_auc)\n",
    "RF_auc_CI95 = [\n",
    "        np.percentile(RF_test_auc, 2.5),\n",
    "        np.percentile(RF_test_auc, 97.5)\n",
    "        ]\n",
    "\n",
    "RF_importances_df = pd.DataFrame(RF_importances)\n",
    "\n",
    "mean_RF_fop = np.mean(RF_fops, axis=0)\n",
    "RF_fop_CI95 = [\n",
    "        np.percentile(RF_fops, 2.5, axis=0),\n",
    "        np.percentile(RF_fops, 97.5, axis=0)\n",
    "        ]\n",
    "mean_RF_dws = np.mean(RF_dws, axis=0)\n",
    "RF_dws_CI95 = [\n",
    "        np.percentile(RF_dws, 2.5, axis=0),\n",
    "        np.percentile(RF_dws, 97.5, axis=0)\n",
    "        ]\n",
    "\n",
    "\n",
    "# XGBoost\n",
    "mean_XG_tpr = np.mean(XG_tprs, axis=0)\n",
    "mean_XG_tpr[-1] = 1.0\n",
    "XG_tpr_CI95 = [\n",
    "        np.percentile(XG_tprs, 2.5, axis=0),\n",
    "        np.percentile(XG_tprs, 97.5, axis=0)\n",
    "        ]\n",
    "\n",
    "mean_XG_auc = np.mean(XG_test_auc)\n",
    "XG_auc_CI95 = [\n",
    "        np.percentile(XG_test_auc, 2.5),\n",
    "        np.percentile(XG_test_auc, 97.5)\n",
    "        ]\n",
    "\n",
    "XG_importances_df = pd.DataFrame(XG_importances)\n",
    "\n",
    "mean_XG_fop = np.mean(XG_fops, axis=0)\n",
    "XG_fop_CI95 = [\n",
    "        np.percentile(XG_fops, 2.5, axis=0),\n",
    "        np.percentile(XG_fops, 97.5, axis=0)\n",
    "        ]\n",
    "mean_XG_dws = np.mean(XG_dws, axis=0)\n",
    "XG_dws_CI95 = [\n",
    "        np.percentile(XG_dws, 2.5, axis=0),\n",
    "        np.percentile(XG_dws, 97.5, axis=0)\n",
    "        ]\n",
    "\n",
    "# For AUC\n",
    "models = ['Decision\\nTree', 'Logistic\\nRegression', 'Random\\nForest', 'XGBoost']\n",
    "heights = [mean_DT_auc, mean_LR_auc, mean_RF_auc, mean_XG_auc]\n",
    "CI95 = [\n",
    "        [\n",
    "                heights[0] - DT_auc_CI95[0],\n",
    "                heights[1] - LR_auc_CI95[0],\n",
    "                heights[2] - RF_auc_CI95[0],\n",
    "                heights[3] - XG_auc_CI95[0]\n",
    "        ],\n",
    "        [\n",
    "                DT_auc_CI95[1] - heights[0],\n",
    "                LR_auc_CI95[1] - heights[1],\n",
    "                RF_auc_CI95[1] - heights[2],\n",
    "                XG_auc_CI95[1] - heights[3]\n",
    "        ]\n",
    "       ]\n",
    "\n",
    "temp_list = []\n",
    "for item1, item2, item3, item4 in zip(DT_test_auc, LR_test_auc, RF_test_auc, XG_test_auc):\n",
    "    temp = {'Decision\\nTree': item1, 'Logistic\\nRegression': item2, 'Random\\nForest': item3, 'XGBoost': item4}\n",
    "    temp_list.append(temp)\n",
    "heights1 = pd.DataFrame(temp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting ROC curves with uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot([0, 1], [0, 1], linestyle=\"--\", color=\"k\", alpha=0.8)\n",
    "\n",
    "ax.plot(mean_fpr, mean_DT_tpr, color='#66c2a5', label=f\"{heights[0]:.2f} ({DT_auc_CI95[0]:.2f}-{DT_auc_CI95[1]:.2f})\")\n",
    "ax.fill_between(mean_fpr, DT_tpr_CI95[0], DT_tpr_CI95[1],\n",
    "                color='#66c2a5', alpha=0.2)\n",
    "\n",
    "ax.plot(mean_fpr, mean_LR_tpr, color='#fc8d62', label=f\"{heights[1]:.2f} ({LR_auc_CI95[0]:.2f}-{LR_auc_CI95[1]:.2f})\")\n",
    "ax.fill_between(mean_fpr, LR_tpr_CI95[0], LR_tpr_CI95[1],\n",
    "                color='#fc8d62', alpha=0.2)\n",
    "\n",
    "ax.plot(mean_fpr, mean_RF_tpr, color='#8da0cb', label=f\"{heights[2]:.2f} ({RF_auc_CI95[0]:.2f}-{RF_auc_CI95[1]:.2f})\")\n",
    "ax.fill_between(mean_fpr, RF_tpr_CI95[0], RF_tpr_CI95[1],\n",
    "                color='#8da0cb', alpha=0.2)\n",
    "\n",
    "ax.plot(mean_fpr, mean_XG_tpr, color='#e78ac3', label=f\"{heights[3]:.2f} ({XG_auc_CI95[0]:.2f}-{XG_auc_CI95[1]:.2f})\")\n",
    "ax.fill_between(mean_fpr, XG_tpr_CI95[0], XG_tpr_CI95[1],\n",
    "                color='#e78ac3', alpha=0.2)\n",
    "\n",
    "ax.set_xlabel(\"False Positive Rate\")\n",
    "ax.set_ylabel(\"True Positive Rate\")\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\n",
    "ax.grid(linestyle=':')\n",
    "ax.legend(loc='best', frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figure_path / \"fig1_ROC_curves_all_models.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot(mean_fpr, mean_DT_tpr, color='#66c2a5', label=f\"Decision tree performance:\\n{mean_DT_auc:.2f}\")\n",
    "ax1.fill_between(mean_fpr, DT_tpr_CI95[0], DT_tpr_CI95[1],\n",
    "                 color='#66c2a5', alpha=0.2)\n",
    "\n",
    "ax1.plot([0, 1], [0, 1], linestyle=\"--\", color=\"k\", alpha=0.8)\n",
    "\n",
    "ax1.set_ylabel(\"True Positive Rate\")\n",
    "ax1.set_xlabel(\"False Positive Rate\")\n",
    "# ax1.set_title(\"Decision Tree\")\n",
    "ax1.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\n",
    "ax1.grid(linestyle=':')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figure_path / \"ROC_curves_DT.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots()\n",
    "\n",
    "ax2.plot(mean_fpr, mean_LR_tpr, color='#fc8d62', label=f\"Logistic regression performance:\\n{mean_LR_auc:.2f}\")\n",
    "ax2.fill_between(mean_fpr, LR_tpr_CI95[0], LR_tpr_CI95[1],\n",
    "                 alpha=0.2, color='#fc8d62')\n",
    "ax2.plot([0, 1], [0, 1], linestyle=\"--\", color=\"k\", alpha=0.8)\n",
    "\n",
    "ax2.set_ylabel(\"True Positive Rate\")\n",
    "ax2.set_xlabel(\"False Positive Rate\")\n",
    "# ax2.set_title(\"Logistic Regression\")\n",
    "ax2.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\n",
    "ax2.grid(linestyle=':')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figure_path / \"ROC_curves_LR.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3, ax3 = plt.subplots()\n",
    "\n",
    "ax3.plot(mean_fpr, mean_RF_tpr, color='#8da0cb', label=f\"Random Forest performance:\\n{mean_RF_auc:.2f}\")\n",
    "ax3.fill_between(mean_fpr, RF_tpr_CI95[0], RF_tpr_CI95[1],\n",
    "                 color='#8da0cb', alpha=0.2)\n",
    "ax3.plot([0, 1], [0, 1], linestyle=\"--\", color=\"k\", alpha=0.8)\n",
    "\n",
    "ax3.set_ylabel(\"True Positive Rate\")\n",
    "ax3.set_xlabel(\"False Positive Rate\")\n",
    "# ax3.set_title(\"Random Forest\")\n",
    "ax3.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\n",
    "ax3.grid(linestyle=':')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figure_path / \"ROC_curves_RF.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4, ax4 = plt.subplots()\n",
    "\n",
    "ax4.plot(mean_fpr, mean_XG_tpr, color='#e78ac3', label=f\"XGBoost performance:\\n{mean_XG_auc:.2f}\")\n",
    "ax4.fill_between(mean_fpr, XG_tpr_CI95[0], XG_tpr_CI95[1],\n",
    "                 color='#e78ac3', alpha=0.2)\n",
    "ax4.plot([0, 1], [0, 1], linestyle=\"--\", color=\"k\", alpha=0.8)\n",
    "\n",
    "ax4.set_ylabel(\"True Positive Rate\")\n",
    "ax4.set_xlabel(\"False Positive Rate\")\n",
    "# ax4.set_title(\"XGBoost\")\n",
    "ax4.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\n",
    "ax4.grid(linestyle=':')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figure_path / \"ROC_curves_XG.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig5, ax5 = plt.subplots()\n",
    "\n",
    "sns.pointplot(data=heights1, errorbar=(\"pi\", 95), ax=ax5,\n",
    "              capsize=0.1, color=\"0\", linestyle=\"none\")\n",
    "sns.swarmplot(data=heights1, ax=ax5,\n",
    "              palette=['#66c2a5', '#fc8d62', '#8da0cb', '#e78ac3'],\n",
    "              alpha=0.5)\n",
    "\n",
    "ax5.set_ylabel('Performance (AUROC)')\n",
    "ax5.set_xlabel('')\n",
    "ax5.grid(linestyle=':', axis='y')\n",
    "ax5.set_ylim(0.5, 1.0)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figure_path / 'fig1_auc_different_models.pdf')\n",
    "# plt.savefig(figure_path / 'fig1_auc_different_models.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Plotting feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_words = ['edema', 'pulmonary edema', 'bilateral', 'atelectasis', 'diffuse', 'interstitial', 'ards', 'no', 'clear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig6, ax6 = plt.subplots()\n",
    "\n",
    "top15_DT = (\n",
    "    DT_importances_df.groupby('feature')['importance'].mean().nlargest(15, keep=\"all\").index\n",
    ")\n",
    "DT_importances_df_filtered = DT_importances_df[\n",
    "    DT_importances_df['feature'].isin(top15_DT)\n",
    "    ].sort_values(by='importance', ascending=False)\n",
    "\n",
    "sns.pointplot(data=DT_importances_df_filtered,\n",
    "              x=\"importance\", y=\"feature\", errorbar=(\"pi\", 95), ax=ax6,\n",
    "              capsize=0.1, color=\"0\", linestyle=\"none\")\n",
    "sns.stripplot(data=DT_importances_df_filtered,\n",
    "              x=\"importance\", y=\"feature\", ax=ax6, color=\"#66c2a5\", alpha=0.5)\n",
    "\n",
    "for tick in ax6.yaxis.get_major_ticks():\n",
    "     if tick.label1.get_text() in imp_words:\n",
    "         tick.label1.set_fontweight('bold')\n",
    "     else:\n",
    "         pass\n",
    "ax6.set_xlabel('Importance')\n",
    "ax6.set_ylabel('')\n",
    "ax6.grid(linestyle=':', axis='x')\n",
    "custom_legend = [Line2D([0], [0], marker='o', color='w', label='Decision Tree',\n",
    "                        markerfacecolor='#66c2a5', markersize=7, alpha=0.5)]\n",
    "ax6.legend(handles=custom_legend, loc='best', frameon=False)\n",
    "# ax6.set_title(\"Decision Tree\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figure_path / 'fig1_importance_DT.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig7, ax7 = plt.subplots()\n",
    "\n",
    "top7_LR = (\n",
    "    LR_importances_df.groupby('feature')['importance'].mean().nlargest(7, keep=\"all\").index\n",
    ")\n",
    "bottom7_LR = (\n",
    "    LR_importances_df.groupby('feature')['importance'].mean().nsmallest(7, keep=\"all\").index\n",
    ")\n",
    "LR1 = LR_importances_df.loc[LR_importances_df['feature'].isin(top7_LR)].sort_values(by='importance')\n",
    "LR2 = LR_importances_df.loc[LR_importances_df['feature'].isin(bottom7_LR)].sort_values(by='importance')\n",
    "LR_importances_df_filtered = pd.concat([LR2, LR1])\n",
    "\n",
    "sns.pointplot(data=LR_importances_df_filtered,\n",
    "              x=\"importance\", y=\"feature\", errorbar=(\"pi\", 95), ax=ax7,\n",
    "              capsize=0.1, color=\"0\", linestyle=\"none\")\n",
    "sns.stripplot(data=LR_importances_df_filtered,\n",
    "              x=\"importance\", y=\"feature\", ax=ax7, color=\"#fc8d62\", alpha=0.5)\n",
    "\n",
    "for tick in ax7.yaxis.get_major_ticks():\n",
    "     if tick.label1.get_text() in imp_words:\n",
    "         tick.label1.set_fontweight('bold')\n",
    "     else:\n",
    "         pass\n",
    "ax7.set_xlabel('Importance')\n",
    "ax7.set_ylabel('')\n",
    "ax7.grid(linestyle=':', axis='x')\n",
    "custom_legend = [Line2D([0], [0], marker='o', color='w', label='Logistic Regression',\n",
    "                        markerfacecolor='#fc8d62', markersize=7, alpha=0.5)]\n",
    "ax7.legend(handles=custom_legend, loc='best', frameon=False)\n",
    "# ax7.set_title(\"Logistic Regression\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figure_path /'fig1_importance_LR.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig8, ax8 = plt.subplots()\n",
    "\n",
    "top15_RF = (\n",
    "    RF_importances_df.groupby('feature')['importance'].mean().nlargest(15, keep=\"all\").index\n",
    ")\n",
    "RF_importances_df_filtered = RF_importances_df[\n",
    "    RF_importances_df['feature'].isin(top15_RF)\n",
    "    ].sort_values(by='importance', ascending=False)\n",
    "\n",
    "sns.pointplot(data=RF_importances_df_filtered,\n",
    "              x=\"importance\", y=\"feature\", errorbar=(\"pi\", 95), ax=ax8,\n",
    "              capsize=0.1, color=\"0\", linestyle=\"none\")\n",
    "sns.stripplot(data=RF_importances_df_filtered,\n",
    "              x=\"importance\", y=\"feature\", ax=ax8, color=\"#8da0cb\", alpha=0.5)\n",
    "\n",
    "for tick in ax8.yaxis.get_major_ticks():\n",
    "     if tick.label1.get_text() in imp_words:\n",
    "         tick.label1.set_fontweight('bold')\n",
    "     else:\n",
    "         pass\n",
    "ax8.set_xlabel('Importance')\n",
    "ax8.grid(linestyle=':', axis='x')\n",
    "ax8.set_ylabel('')\n",
    "custom_legend = [Line2D([0], [0], marker='o', color='w', label='Random Forest',\n",
    "                        markerfacecolor='#8da0cb', markersize=7, alpha=0.5)]\n",
    "ax8.legend(handles=custom_legend, loc='best', frameon=False)\n",
    "# ax8.set_title(\"Random Forest\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figure_path / 'fig1_importance_RF.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig9, ax9 = plt.subplots()\n",
    "\n",
    "top15_XG = (\n",
    "    XG_importances_df.groupby('feature')['importance'].mean().nlargest(15, keep=\"all\").index\n",
    ")\n",
    "XG_importances_df_filtered = XG_importances_df[\n",
    "    XG_importances_df['feature'].isin(top15_XG)\n",
    "    ].sort_values(by='importance', ascending=False)\n",
    "\n",
    "sns.pointplot(data=XG_importances_df_filtered,\n",
    "              x=\"importance\", y=\"feature\", errorbar=(\"pi\", 95), ax=ax9,\n",
    "              capsize=0.1, color=\"0\", linestyle=\"none\")\n",
    "sns.stripplot(data=XG_importances_df_filtered,\n",
    "              x=\"importance\", y=\"feature\", ax=ax9, color=\"#e78ac3\", alpha=0.5)\n",
    "\n",
    "for tick in ax9.yaxis.get_major_ticks():\n",
    "     if tick.label1.get_text() in imp_words:\n",
    "         tick.label1.set_fontweight('bold')\n",
    "     else:\n",
    "         pass\n",
    "ax9.set_xlabel('Importance')\n",
    "ax9.grid(linestyle=':', axis='x')\n",
    "ax9.set_ylabel('')\n",
    "custom_legend = [Line2D([0], [0], marker='o', color='w', label='XGBoost',\n",
    "                        markerfacecolor='#e78ac3', markersize=7, alpha=0.5)]\n",
    "ax9.legend(handles=custom_legend, loc='best', frameon=False)\n",
    "# ax9.set_title(\"XGBoost\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figure_path / 'fig1_importance_XG.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig10, ax10 = plt.subplots(3, 2, figsize=plots.stdfigsize(101, n_rows=3, n_cols=2, layout='double'))\n",
    "\n",
    "ax10[0,0].plot([0, 1], [0, 1], linestyle=\"--\", color=\"k\", alpha=0.8, label=\"No-skill line\")\n",
    "\n",
    "# ax10[0,0].plot(mean_fpr, mean_DT_tpr, color='#66c2a5', label=f\"Decision tree performance:\\n{mean_DT_auc:.2f}\")\n",
    "# ax10[0,0].fill_between(mean_fpr, DT_tpr_CI95[0], DT_tpr_CI95[1], color='#66c2a5', alpha=0.2)\n",
    "\n",
    "# ax10[0,0].plot(mean_fpr, mean_LR_tpr, color='#fc8d62', label=\"Logistic regression\")\n",
    "# ax10[0,0].fill_between(mean_fpr, LR_tpr_CI95[0], LR_tpr_CI95[1], color='#fc8d62', alpha=0.2)\n",
    "\n",
    "# ax10[0,0].plot(mean_fpr, mean_RF_tpr, color='#8da0cb', label=\"Random Forest\")\n",
    "# ax10[0,0].fill_between(mean_fpr, RF_tpr_CI95[0], RF_tpr_CI95[1], color='#8da0cb', alpha=0.2)\n",
    "\n",
    "ax10[0,0].plot(mean_fpr, mean_XG_tpr, color='#e78ac3', label=f\"XGBoost\\nMean AUROC: {mean_XG_auc:.2f}\")\n",
    "ax10[0,0].fill_between(mean_fpr, XG_tpr_CI95[0], XG_tpr_CI95[1], color='#e78ac3', alpha=0.2)\n",
    "\n",
    "ax10[0,0].set_xlabel(\"False Positive Rate\")\n",
    "ax10[0,0].set_ylabel(\"True Positive Rate\")\n",
    "ax10[0,0].set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\n",
    "ax10[0,0].grid(linestyle=':')\n",
    "ax10[0,0].legend(loc='lower right')\n",
    "ax10[0,0].text(-0.2, 1.05, \"a\", transform=ax10[0,0].transAxes, fontweight='bold', va='top')\n",
    "\n",
    "\n",
    "sns.pointplot(data=heights1, errorbar=(\"pi\", 95), ax=ax10[0,1],\n",
    "              capsize=0.1, color=\"0\", linestyle=\"none\", markersize=5)\n",
    "sns.swarmplot(data=heights1, ax=ax10[0,1], size=3.3,\n",
    "              palette=['#66c2a5', '#fc8d62', '#8da0cb', '#e78ac3'],\n",
    "              alpha=0.5)\n",
    "\n",
    "ax10[0,1].set_ylabel('Performance (AUROC)')\n",
    "ax10[0,1].grid(linestyle=':', axis='y')\n",
    "ax10[0,1].set_ylim(0.5, 1.0)\n",
    "ax10[0,1].text(-0.2, 1.05, \"b\", transform=ax10[0,1].transAxes, fontweight='bold', va='top')\n",
    "\n",
    "\n",
    "sns.pointplot(data=DT_importances_df_filtered, markersize=5,\n",
    "              x=\"importance\", y=\"feature\", errorbar=(\"pi\", 95), ax=ax10[1,0],\n",
    "              capsize=0.1, color=\"0\", linestyle=\"none\")\n",
    "sns.stripplot(data=DT_importances_df_filtered,\n",
    "              x=\"importance\", y=\"feature\", ax=ax10[1,0], color=\"#66c2a5\", alpha=0.5)\n",
    "\n",
    "for tick in ax10[1,0].yaxis.get_major_ticks():\n",
    "     if tick.label1.get_text() in imp_words:\n",
    "         tick.label1.set_fontweight('bold')\n",
    "     else:\n",
    "         pass\n",
    "ax10[1,0].set_xlabel('Importance')\n",
    "ax10[1,0].set_ylabel('')\n",
    "ax10[1,0].grid(linestyle=':', axis='x')\n",
    "custom_legend = [Line2D([0], [0], marker='o', color='w', label='Decision Tree',\n",
    "                        markerfacecolor='#66c2a5', markersize=7, alpha=0.5)]\n",
    "ax10[1,0].legend(handles=custom_legend, loc='lower right')\n",
    "ax10[1,0].text(-0.2, 1.05, \"c\", transform=ax10[1,0].transAxes, fontweight='bold', va='top')\n",
    "\n",
    "\n",
    "sns.pointplot(data=LR_importances_df_filtered, markersize=5,\n",
    "              x=\"importance\", y=\"feature\", errorbar=(\"pi\", 95), ax=ax10[1,1],\n",
    "              capsize=0.1, color=\"0\", linestyle=\"none\")\n",
    "sns.stripplot(data=LR_importances_df_filtered,\n",
    "              x=\"importance\", y=\"feature\", ax=ax10[1,1], color=\"#fc8d62\", alpha=0.5)\n",
    "\n",
    "for tick in ax10[1,1].yaxis.get_major_ticks():\n",
    "     if tick.label1.get_text() in imp_words:\n",
    "         tick.label1.set_fontweight('bold')\n",
    "     else:\n",
    "         pass\n",
    "ax10[1,1].set_xlabel('Importance')\n",
    "ax10[1,1].set_ylabel('')\n",
    "ax10[1,1].grid(linestyle=':', axis='x')\n",
    "custom_legend = [Line2D([0], [0], marker='o', color='w', label='Logistic Regression',\n",
    "                        markerfacecolor='#fc8d62', markersize=7, alpha=0.5)]\n",
    "ax10[1,1].legend(handles=custom_legend, loc='best')\n",
    "\n",
    "\n",
    "sns.pointplot(data=RF_importances_df_filtered, markersize=5,\n",
    "              x=\"importance\", y=\"feature\", errorbar=(\"pi\", 95), ax=ax10[2,0],\n",
    "              capsize=0.1, color=\"0\", linestyle=\"none\")\n",
    "sns.stripplot(data=RF_importances_df_filtered,\n",
    "              x=\"importance\", y=\"feature\", ax=ax10[2,0], color=\"#8da0cb\", alpha=0.5)\n",
    "                           \n",
    "for tick in ax10[2,0].yaxis.get_major_ticks():\n",
    "     if tick.label1.get_text() in imp_words:\n",
    "         tick.label1.set_fontweight('bold')\n",
    "     else:\n",
    "         pass\n",
    "ax10[2,0].set_xlabel('Importance')\n",
    "ax10[2,0].grid(linestyle=':', axis='x')\n",
    "ax10[2,0].set_ylabel('')\n",
    "custom_legend = [Line2D([0], [0], marker='o', color='w', label='Random Forest',\n",
    "                        markerfacecolor='#8da0cb', markersize=7, alpha=0.5)]\n",
    "ax10[2,0].legend(handles=custom_legend, loc='lower right')\n",
    "\n",
    "\n",
    "sns.pointplot(data=XG_importances_df_filtered, markersize=5,\n",
    "              x=\"importance\", y=\"feature\", errorbar=(\"pi\", 95), ax=ax10[2,1],\n",
    "              capsize=0.1, color=\"0\", linestyle=\"none\")\n",
    "sns.stripplot(data=XG_importances_df_filtered,\n",
    "              x=\"importance\", y=\"feature\", ax=ax10[2,1], color=\"#e78ac3\", alpha=0.5)\n",
    "\n",
    "for tick in ax10[2,1].yaxis.get_major_ticks():\n",
    "     if tick.label1.get_text() in imp_words:\n",
    "         tick.label1.set_fontweight('bold')\n",
    "     else:\n",
    "         pass\n",
    "ax10[2,1].set_xlabel('Importance')\n",
    "ax10[2,1].grid(linestyle=':', axis='x')\n",
    "ax10[2,1].set_ylabel('')\n",
    "custom_legend = [Line2D([0], [0], marker='o', color='w', label='XGBoost',\n",
    "                        markerfacecolor='#e78ac3', markersize=7, alpha=0.5)]\n",
    "ax10[2,1].legend(handles=custom_legend, loc='lower right')\n",
    "\n",
    "fig10.tight_layout()\n",
    "# plt.savefig(figure_path / 'fig1.png')\n",
    "# plt.savefig(figure_path / 'fig1.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Plotting calibration curves with uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig11, ax11 = plt.subplots(2, 2, figsize=plots.stdfigsize(105, n_rows=2, n_cols=2, layout='double'))\n",
    "\n",
    "# Logistic Regression\n",
    "ax11[0,0].plot(\n",
    "    mean_mpv, mean_DT_fop, color='#66c2a5', marker=\"o\",\n",
    "    label=f\"Decision Tree\\nMean DW = {mean_DT_dws:.2f}\")\n",
    "ax11[0,0].fill_between(mean_mpv, DT_fop_CI95[0], DT_fop_CI95[1], color='#66c2a5', alpha=0.2)\n",
    "\n",
    "# Logistic Regression\n",
    "ax11[0,1].plot(\n",
    "    mean_mpv, mean_LR_fop, color='#fc8d62', marker=\"o\",\n",
    "    label=f\"Logistic Regression\\nMean DW = {mean_LR_dws:.2f}\")\n",
    "ax11[0,1].fill_between(mean_mpv, LR_fop_CI95[0], LR_fop_CI95[1], color='#fc8d62', alpha=0.2)\n",
    "\n",
    "# Random Forest\n",
    "ax11[1,0].plot(\n",
    "    mean_mpv, mean_RF_fop, color='#8da0cb', marker=\"o\",\n",
    "    label=f\"Random Forest\\nMean DW = {mean_RF_dws:.2f}\")\n",
    "ax11[1,0].fill_between(mean_mpv,RF_fop_CI95[0], RF_fop_CI95[1], color='#8da0cb', alpha=0.2)\n",
    "\n",
    "# XGBoost\n",
    "ax11[1,1].plot(\n",
    "    mean_mpv, mean_XG_fop, color='#e78ac3', marker=\"o\",\n",
    "    label=f\"XGBoost\\nMean DW = {mean_XG_dws:.2f}\")\n",
    "ax11[1,1].fill_between(mean_mpv, XG_fop_CI95[0], XG_fop_CI95[1], color='#e78ac3', alpha=0.2)\n",
    "\n",
    "# Plot properties\n",
    "ax11[0,0].plot(mean_mpv, mean_mpv, linestyle=\"--\", color=\"k\", alpha=0.8, label=\"Perfectly calibrated\")\n",
    "ax11[0,0].set_ylabel(\"Fraction of positive labels\")\n",
    "ax11[0,0].set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\n",
    "ax11[0,0].grid(linestyle=':')\n",
    "ax11[0,0].legend(loc='best')\n",
    "ax11[0,0].text(-0.075, 1.05, \"a\", transform=ax11[0,0].transAxes, fontweight='bold', va='top')\n",
    "\n",
    "ax11[0,1].plot(mean_mpv, mean_mpv, linestyle=\"--\", color=\"k\", alpha=0.8)\n",
    "ax11[0,1].set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\n",
    "ax11[0,1].grid(linestyle=':')\n",
    "ax11[0,1].legend(loc='best')\n",
    "ax11[0,1].text(-0.075, 1.05, \"b\", transform=ax11[0,1].transAxes, fontweight='bold', va='top')\n",
    "\n",
    "ax11[1,0].plot(mean_mpv, mean_mpv, linestyle=\"--\", color=\"k\", alpha=0.8)\n",
    "ax11[1,0].set_ylabel(\"Fraction of positive labels\")\n",
    "ax11[1,0].set_xlabel(\"Mean predicted probability\")\n",
    "ax11[1,0].set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\n",
    "ax11[1,0].grid(linestyle=':')\n",
    "ax11[1,0].legend(loc='best')\n",
    "ax11[1,0].text(-0.075, 1.05, \"c\", transform=ax11[1,0].transAxes, fontweight='bold', va='top')\n",
    "\n",
    "ax11[1,1].plot(mean_mpv, mean_mpv, linestyle=\"--\", color=\"k\", alpha=0.8)\n",
    "ax11[1,1].set_xlabel(\"Mean predicted probability\")\n",
    "ax11[1,1].set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\n",
    "ax11[1,1].grid(linestyle=':')\n",
    "ax11[1,1].legend(loc='best')\n",
    "ax11[1,1].text(-0.075, 1.05, \"d\", transform=ax11[1,1].transAxes, fontweight='bold', va='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figure_path / \"fig2.pdf\")\n",
    "# plt.savefig(figure_path / \"fig2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figu, eje = plt.subplots(2, 2, figsize=plots.stdfigsize(0, n_rows=2, n_cols=2, layout='double'))\n",
    "\n",
    "# Decision Tree\n",
    "eje[0,0].hist(DT_preds, bins=20)\n",
    "\n",
    "eje[0,0].tick_params(axis='x')\n",
    "eje[0,0].tick_params(axis='y')\n",
    "eje[0,0].set_ylabel(\"Counts\")\n",
    "eje[0,0].set_title(\"Decision Tree\")\n",
    "eje[0,0].grid(linestyle=':')\n",
    "eje[0,0].set(ylim=[0, 35000])\n",
    "\n",
    "# Logistic Regression\n",
    "eje[0,1].hist(LR_preds, bins=20)\n",
    "\n",
    "eje[0,1].tick_params(axis='x')\n",
    "eje[0,1].tick_params(axis='y')\n",
    "eje[0,1].set_title(\"Logistic Regression\")\n",
    "eje[0,1].grid(linestyle=':')\n",
    "eje[0,1].set(ylim=[0, 35000])\n",
    "\n",
    "# Random Forest\n",
    "eje[1,0].hist(RF_preds, bins=20)\n",
    "\n",
    "eje[1,0].tick_params(axis='x')\n",
    "eje[1,0].tick_params(axis='y')\n",
    "eje[1,0].set_ylabel(\"Counts\")\n",
    "eje[1,0].set_xlabel(\"Estimated probabilities\")\n",
    "eje[1,0].set_title(\"Random Forest\")\n",
    "eje[1,0].grid(linestyle=':')\n",
    "eje[1,0].set(ylim=[0, 35000])\n",
    "\n",
    "# XGBoost\n",
    "eje[1,1].hist(XG_preds, bins=20)\n",
    "\n",
    "eje[1,1].tick_params(axis='x')\n",
    "eje[1,1].tick_params(axis='y')\n",
    "eje[1,1].set_xlabel(\"Estimated probabilities\")\n",
    "eje[1,1].set_title(\"XGBoost\")\n",
    "eje[1,1].grid(linestyle=':')\n",
    "eje[1,1].set(ylim=[0, 35000])\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figure_path / \"probability_histograms.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalizability figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in Hospital B (2017-18)\n",
    "segmented_cohort3_jesse_curt = pd.read_csv(test_data3b)\n",
    "segmented_cohort3_three_annot = pd.read_csv(test_data3c)\n",
    "\n",
    "segmented_cohort3_jesse_curt['seg_cxr_text'] = segmented_cohort3_jesse_curt['seg_cxr_text'].str.replace(r\"'\", r\"\", regex=True)\n",
    "segmented_cohort3_jesse_curt['seg_cxr_text'] = segmented_cohort3_jesse_curt['seg_cxr_text'].str.replace(r\"\\[\", r\"\", regex=True)\n",
    "segmented_cohort3_jesse_curt['seg_cxr_text'] = segmented_cohort3_jesse_curt['seg_cxr_text'].str.replace(r\"\\]\", r\"\", regex=True)\n",
    "segmented_cohort3_jesse_curt['seg_cxr_text'] = segmented_cohort3_jesse_curt['seg_cxr_text'].str.replace(r\",\", r\"\", regex=True)\n",
    "\n",
    "segmented_cohort3_three_annot['seg_cxr_text'] = segmented_cohort3_three_annot['seg_cxr_text'].str.replace(r\"'\", r\"\", regex=True)\n",
    "segmented_cohort3_three_annot['seg_cxr_text'] = segmented_cohort3_three_annot['seg_cxr_text'].str.replace(r\"\\[\", r\"\", regex=True)\n",
    "segmented_cohort3_three_annot['seg_cxr_text'] = segmented_cohort3_three_annot['seg_cxr_text'].str.replace(r\"\\]\", r\"\", regex=True)\n",
    "segmented_cohort3_three_annot['seg_cxr_text'] = segmented_cohort3_three_annot['seg_cxr_text'].str.replace(r\",\", r\"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in MIMIC III\n",
    "mimic_iii = pd.read_csv(mimic3_path / \"cxr.csv\")\n",
    "\n",
    "# Removing remaining punctuation marks\n",
    "mimic_iii['seg_cxr_text'] = mimic_iii['seg_cxr_text'].str.replace(r\"'\", r\"\", regex=True)\n",
    "mimic_iii['seg_cxr_text'] = mimic_iii['seg_cxr_text'].str.replace(r\"\\[\", r\"\", regex=True)\n",
    "mimic_iii['seg_cxr_text'] = mimic_iii['seg_cxr_text'].str.replace(r\"\\]\", r\"\", regex=True)\n",
    "mimic_iii['seg_cxr_text'] = mimic_iii['seg_cxr_text'].str.replace(r\",\", r\"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hospital A (2013)\n",
    "X1 = segmented[cols[which][0]].to_numpy()\n",
    "Y1 = segmented[cols[which][1]].to_numpy()\n",
    "\n",
    "# # Accounting for potential label imbalance\n",
    "# count_0_Y1 = pd.Series(Y1).value_counts()[0]\n",
    "# count_1_Y1 = pd.Series(Y1).value_counts()[1]\n",
    "# weight_0_Y1 = count_0_Y1/ len(Y1)\n",
    "# weight_1_Y1 = count_1_Y1 / len(Y1)\n",
    "\n",
    "# Hospital A (2016)\n",
    "X2 = segmented_cohort2['segmented_report'].to_numpy()\n",
    "Y2 = segmented_cohort2['score'].to_numpy()\n",
    "\n",
    "# # Accounting for potential label imbalance\n",
    "# count_0_Y2 = pd.Series(Y2).value_counts()[0]\n",
    "# count_1_Y2 = pd.Series(Y2).value_counts()[1]\n",
    "# weight_0_Y2 = count_0_Y2 / len(Y2)\n",
    "# weight_1_Y2 = count_1_Y2 / len(Y2)\n",
    "\n",
    "# Hospital B (2017-18)\n",
    "X3_original = segmented_cohort3_original['seg_cxr_text'].values\n",
    "Y3_original = segmented_cohort3_original['score_final'].values\n",
    "X3_jesse_curt = segmented_cohort3_jesse_curt['seg_cxr_text'].values\n",
    "X3_three_annot = segmented_cohort3_three_annot['seg_cxr_text'].values\n",
    "\n",
    "# MIMIC III\n",
    "X4 = mimic_iii['seg_cxr_text'].to_numpy()\n",
    "Y4 = mimic_iii['curt_bl_infiltrates_(1=yes)'].to_numpy()\n",
    "\n",
    "which1 = 'a'\n",
    "cols1 = {\n",
    "    'a': ['seg_cxr_text', 'score_final'],\n",
    "    'b': ['seg_cxr_text', 'score']\n",
    "    }\n",
    "\n",
    "which2 = 'a'\n",
    "cols2 = {\n",
    "    'a': ['seg_cxr_text', 'curt_bl_infiltrates_(1=yes)'],\n",
    "    'b': ['seg_cxr_text', 'cxr_score_predicted']\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get optimized hyperparameters for each of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(basedir / \"Development_notebooks\" /  \"hyperparameters\" / \"XG_hyperparams_hospital_a_2013.json\", \"r\") as xg_file:\n",
    "    xg_hyperparams = json.load(xg_file)\n",
    "\n",
    "xg_hyperparams['base_score'] = float(xg_hyperparams['base_score'])    \n",
    "xg_hyperparams['n_estimators'] = int(xg_hyperparams['n_estimators'])\n",
    "xg_hyperparams['max_depth'] = int(xg_hyperparams['max_depth'])\n",
    "xg_hyperparams['learning_rate'] = float(xg_hyperparams['learning_rate'])\n",
    "xg_hyperparams['gamma'] = float(xg_hyperparams['gamma'])\n",
    "xg_hyperparams['min_child_weight'] = float(xg_hyperparams['min_child_weight'])\n",
    "xg_hyperparams['max_delta_step'] = float(xg_hyperparams['max_delta_step'])\n",
    "xg_hyperparams['subsample'] = float(xg_hyperparams['subsample'])\n",
    "\n",
    "\n",
    "with open(basedir / \"Development_notebooks\" /  \"hyperparameters\" / \"XG_hyperparams_hospital_a_2016.json\", \"r\") as xg_file2:\n",
    "    xg_hyperparams2 = json.load(xg_file2)\n",
    "\n",
    "xg_hyperparams2['base_score'] = float(xg_hyperparams2['base_score']) \n",
    "xg_hyperparams2['n_estimators'] = int(xg_hyperparams2['n_estimators'])\n",
    "xg_hyperparams2['max_depth'] = int(xg_hyperparams2['max_depth'])\n",
    "xg_hyperparams2['learning_rate'] = float(xg_hyperparams2['learning_rate'])\n",
    "xg_hyperparams2['gamma'] = float(xg_hyperparams2['gamma'])\n",
    "xg_hyperparams2['min_child_weight'] = float(xg_hyperparams2['min_child_weight'])\n",
    "xg_hyperparams2['max_delta_step'] = float(xg_hyperparams2['max_delta_step'])\n",
    "xg_hyperparams2['subsample'] = float(xg_hyperparams2['subsample'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on Hospital A (2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize\n",
    "vect1 = CountVectorizer(\n",
    "    tokenizer=tokenizer_better,\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=200\n",
    "    )\n",
    "\n",
    "vect1.fit(X1)\n",
    "X1_vect_1 = vect1.transform(X1).toarray()\n",
    "\n",
    "XG_model_1 = XGBClassifier(\n",
    "    **xg_hyperparams,\n",
    "    tree_method='hist',\n",
    "    random_state=0\n",
    "    )\n",
    "\n",
    "XG_model_1.fit(X1_vect_1, Y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on Hospital A (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tprs_1_2 = []\n",
    "aucs_1_2 = []\n",
    "fops_1_2 = []\n",
    "preds_1_2 = []\n",
    "\n",
    "for i in tqdm(range(n_boot)):\n",
    "    # This line resamples the data, WITH replacement\n",
    "    boot_segmented_2 = segmented_cohort2.sample(\n",
    "        n=len(segmented_cohort2),\n",
    "        replace=True,\n",
    "        axis=0\n",
    "        )\n",
    "    \n",
    "    encounters = boot_segmented_2['_id'].unique()\n",
    "    \n",
    "    cv = KFold()\n",
    "    output1, output2, output3, output4, output5 = Parallel(n_jobs=5)(delayed(custom_cv_not_train)(\n",
    "        XG_model_1,\n",
    "        boot_segmented_2,\n",
    "        {'a': ['segmented_report', 'score']},\n",
    "        'a',\n",
    "        encounters,\n",
    "        vect1,\n",
    "        train_index,\n",
    "        mean_fpr,\n",
    "        mean_mpv\n",
    "        ) for train_index, test_index in cv.split(encounters))\n",
    "    \n",
    "    aucs_1_2.append(np.mean([output1[0], output2[0], output3[0], output4[0], output5[0]]))\n",
    "    preds_1_2.extend(output1[1])\n",
    "    preds_1_2.extend(output2[1])\n",
    "    preds_1_2.extend(output3[1])\n",
    "    preds_1_2.extend(output4[1])\n",
    "    preds_1_2.extend(output5[1])\n",
    "    tprs_1_2.append(np.mean([output1[2], output2[2], output3[2], output4[2], output5[2]], axis=0))\n",
    "    fops_1_2.append(np.mean([output1[3], output2[3], output3[3], output4[3], output5[3]], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on Hospital B (2017-18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tprs_1_3 = []\n",
    "aucs_1_3 = []\n",
    "fops_1_3 = []\n",
    "preds_1_3 = []\n",
    "\n",
    "for i in tqdm(range(n_boot)):\n",
    "    # This line resamples the data, WITH replacement\n",
    "    boot_segmented_3 = segmented_cohort3_original.sample(\n",
    "        n=len(segmented_cohort3_original),\n",
    "        replace=True,\n",
    "        axis=0\n",
    "        )\n",
    "    \n",
    "    encounters = boot_segmented_3['icu_id'].unique()\n",
    "    \n",
    "    cv = KFold()\n",
    "    output1, output2, output3, output4, output5 = Parallel(n_jobs=5)(delayed(custom_cv_not_train)(\n",
    "        XG_model_1,\n",
    "        boot_segmented_3,\n",
    "        cols1,\n",
    "        which1,\n",
    "        encounters,\n",
    "        vect1,\n",
    "        train_index,\n",
    "        mean_fpr,\n",
    "        mean_mpv\n",
    "        ) for train_index, test_index in cv.split(encounters))\n",
    "    \n",
    "    aucs_1_3.append(np.mean([output1[0], output2[0], output3[0], output4[0], output5[0]]))\n",
    "    preds_1_3.extend(output1[1])\n",
    "    preds_1_3.extend(output2[1])\n",
    "    preds_1_3.extend(output3[1])\n",
    "    preds_1_3.extend(output4[1])\n",
    "    preds_1_3.extend(output5[1])\n",
    "    tprs_1_3.append(np.mean([output1[2], output2[2], output3[2], output4[2], output5[2]], axis=0))\n",
    "    fops_1_3.append(np.mean([output1[3], output2[3], output3[3], output4[3], output5[3]], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on a labeled subset of MIMIC III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tprs_1_mimic = []\n",
    "aucs_1_mimic = []\n",
    "fops_1_mimic = []\n",
    "preds_1_mimic = []\n",
    "\n",
    "for i in tqdm(range(n_boot)):\n",
    "    # This line resamples the data, WITH replacement\n",
    "    boot_mimic3 = mimic_iii.sample(\n",
    "        n=len(mimic_iii),\n",
    "        replace=True,\n",
    "        axis=0\n",
    "        )\n",
    "    \n",
    "    encounters = boot_mimic3['encounter_id'].unique()\n",
    "    \n",
    "    cv = KFold()\n",
    "    output1, output2, output3, output4, output5 = Parallel(n_jobs=5)(delayed(custom_cv_not_train)(\n",
    "        XG_model_1,\n",
    "        boot_mimic3,\n",
    "        cols2,\n",
    "        which2,\n",
    "        encounters,\n",
    "        vect1,\n",
    "        train_index,\n",
    "        mean_fpr,\n",
    "        mean_mpv\n",
    "        ) for train_index, test_index in cv.split(encounters))\n",
    "    \n",
    "    aucs_1_mimic.append(np.mean([output1[0], output2[0], output3[0], output4[0], output5[0]]))\n",
    "    preds_1_mimic.extend(output1[1])\n",
    "    preds_1_mimic.extend(output2[1])\n",
    "    preds_1_mimic.extend(output3[1])\n",
    "    preds_1_mimic.extend(output4[1])\n",
    "    preds_1_mimic.extend(output5[1])\n",
    "    tprs_1_mimic.append(np.mean([output1[2], output2[2], output3[2], output4[2], output5[2]], axis=0))\n",
    "    fops_1_mimic.append(np.mean([output1[3], output2[3], output3[3], output4[3], output5[3]], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on Hospital A (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XG2_imp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize\n",
    "vect2 = CountVectorizer(\n",
    "    tokenizer=tokenizer_better,\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=200\n",
    "    )\n",
    "\n",
    "vect2.fit(X2)\n",
    "X2_vect_2 = vect2.transform(X2).toarray()\n",
    "features2 = {value: key for key, value in vect2.vocabulary_.items()}\n",
    "\n",
    "XG_model_2 = XGBClassifier(\n",
    "    **xg_hyperparams2,\n",
    "    tree_method='hist',\n",
    "    random_state=0\n",
    "    )\n",
    "    \n",
    "XG_model_2.fit(X2_vect_2, Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_imp_XG2 = XG_model_2.feature_importances_\n",
    "for i in range(len(raw_imp_XG2)):\n",
    "    temp = {'feature': features2[i], 'importance': raw_imp_XG2[i]}\n",
    "    XG2_imp.append(temp)\n",
    "    \n",
    "XG2_imp_df = pd.DataFrame(XG2_imp).sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figu, eje1 = plt.subplots()\n",
    "\n",
    "sns.pointplot(data=XG2_imp_df.nlargest(15, columns=\"importance\", keep='all'),\n",
    "              x=\"importance\", y=\"feature\", errorbar=(\"pi\", 95), ax=eje1,\n",
    "              capsize=0.1, color=\"0\", linestyle=\"none\")\n",
    "sns.swarmplot(data=XG2_imp_df.nlargest(15, columns=\"importance\", keep='all'),\n",
    "              x=\"importance\", y=\"feature\", ax=eje1, color=\"tab:blue\", alpha=0.5)\n",
    "\n",
    "eje1.set_xlabel('Normalized mean performance gain')\n",
    "eje1.grid(linestyle=':', axis='x')\n",
    "eje1.set_ylabel('')\n",
    "eje1.set_title(\"Importances - XGBoost trained on Hospital A (2016)\")\n",
    "figu.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on Hospital A (2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tprs_2_1 = []\n",
    "aucs_2_1 = []\n",
    "fops_2_1 = []\n",
    "preds_2_1 = []\n",
    "\n",
    "for i in tqdm(range(n_boot)):\n",
    "    # This line resamples the data, WITH replacement\n",
    "    boot_segmented_1 = segmented.sample(\n",
    "        n=len(segmented),\n",
    "        replace=True,\n",
    "        axis=0\n",
    "        )\n",
    "    \n",
    "    encounters = boot_segmented_1['encounter_id'].unique()\n",
    "    \n",
    "    cv = KFold()\n",
    "    output1, output2, output3, output4, output5 = Parallel(n_jobs=5)(delayed(custom_cv_not_train)(\n",
    "        XG_model_2,\n",
    "        boot_segmented_1,\n",
    "        cols,\n",
    "        which,\n",
    "        encounters,\n",
    "        vect2,\n",
    "        train_index,\n",
    "        mean_fpr,\n",
    "        mean_mpv\n",
    "        ) for train_index, test_index in cv.split(encounters))\n",
    "    \n",
    "    aucs_2_1.append(np.mean([output1[0], output2[0], output3[0], output4[0], output5[0]]))\n",
    "    preds_2_1.extend(output1[1])\n",
    "    preds_2_1.extend(output2[1])\n",
    "    preds_2_1.extend(output3[1])\n",
    "    preds_2_1.extend(output4[1])\n",
    "    preds_2_1.extend(output5[1])\n",
    "    tprs_2_1.append(np.mean([output1[2], output2[2], output3[2], output4[2], output5[2]], axis=0))\n",
    "    fops_2_1.append(np.mean([output1[3], output2[3], output3[3], output4[3], output5[3]], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on Hospital B (2017-18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tprs_2_3 = []\n",
    "aucs_2_3 = []\n",
    "fops_2_3 = []\n",
    "preds_2_3 = []\n",
    "\n",
    "for i in tqdm(range(n_boot)):\n",
    "    # This line resamples the data, WITH replacement\n",
    "    boot_segmented_3 = segmented_cohort3_original.sample(\n",
    "        n=len(segmented_cohort3_original),\n",
    "        replace=True,\n",
    "        axis=0\n",
    "        )\n",
    "    \n",
    "    encounters = boot_segmented_3['icu_id'].unique()\n",
    "\n",
    "    cv = KFold()\n",
    "    output1, output2, output3, output4, output5 = Parallel(n_jobs=5)(delayed(custom_cv_not_train)(\n",
    "        XG_model_2,\n",
    "        boot_segmented_3,\n",
    "        cols1,\n",
    "        which1,\n",
    "        encounters,\n",
    "        vect2,\n",
    "        train_index,\n",
    "        mean_fpr,\n",
    "        mean_mpv\n",
    "        ) for train_index, test_index in cv.split(encounters))\n",
    "    \n",
    "    aucs_2_3.append(np.mean([output1[0], output2[0], output3[0], output4[0], output5[0]]))\n",
    "    preds_2_3.extend(output1[1])\n",
    "    preds_2_3.extend(output2[1])\n",
    "    preds_2_3.extend(output3[1])\n",
    "    preds_2_3.extend(output4[1])\n",
    "    preds_2_3.extend(output5[1])\n",
    "    tprs_2_3.append(np.mean([output1[2], output2[2], output3[2], output4[2], output5[2]], axis=0))\n",
    "    fops_2_3.append(np.mean([output1[3], output2[3], output3[3], output4[3], output5[3]], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on a labeled subset of MIMIC III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tprs_2_mimic = []\n",
    "aucs_2_mimic = []\n",
    "fops_2_mimic = []\n",
    "preds_2_mimic = []\n",
    "\n",
    "for i in tqdm(range(n_boot)):\n",
    "    # This line resamples the data, WITH replacement\n",
    "    boot_mimic3 = mimic_iii.sample(\n",
    "        n=len(mimic_iii),\n",
    "        replace=True,\n",
    "        axis=0\n",
    "        )\n",
    "    \n",
    "    encounters = boot_mimic3['encounter_id'].unique()\n",
    "    \n",
    "    cv = KFold()\n",
    "    output1, output2, output3, output4, output5 = Parallel(n_jobs=5)(delayed(custom_cv_not_train)(\n",
    "        XG_model_2,\n",
    "        boot_mimic3,\n",
    "        cols2,\n",
    "        which2,\n",
    "        encounters,\n",
    "        vect2,\n",
    "        train_index,\n",
    "        mean_fpr,\n",
    "        mean_mpv\n",
    "        ) for train_index, test_index in cv.split(encounters))\n",
    "    \n",
    "    aucs_2_mimic.append(np.mean([output1[0], output2[0], output3[0], output4[0], output5[0]]))\n",
    "    preds_2_mimic.extend(output1[1])\n",
    "    preds_2_mimic.extend(output2[1])\n",
    "    preds_2_mimic.extend(output3[1])\n",
    "    preds_2_mimic.extend(output4[1])\n",
    "    preds_2_mimic.extend(output5[1])\n",
    "    tprs_2_mimic.append(np.mean([output1[2], output2[2], output3[2], output4[2], output5[2]], axis=0))\n",
    "    fops_2_mimic.append(np.mean([output1[3], output2[3], output3[3], output4[3], output5[3]], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hospital A (2013) on Hospital A (2016)\n",
    "mean_tpr_1_2 = np.mean(tprs_1_2, axis=0)\n",
    "mean_tpr_1_2[-1] = 1.0\n",
    "tpr_1_2_CI95 = [\n",
    "    np.percentile(tprs_1_2, 25, axis=0),\n",
    "    np.percentile(tprs_1_2, 75, axis=0)\n",
    "    ]\n",
    "\n",
    "mean_auc_1_2 = np.mean(aucs_1_2)\n",
    "auc_1_2_CI95 = [\n",
    "    np.percentile(aucs_1_2, 2.5),\n",
    "    np.percentile(aucs_1_2, 97.5)\n",
    "    ]\n",
    "\n",
    "\n",
    "# Hospital A (2013) on Hospital B (2017-18)\n",
    "mean_tpr_1_3 = np.mean(tprs_1_3, axis=0)\n",
    "mean_tpr_1_3[-1] = 1.0\n",
    "tpr_1_3_CI95 = [\n",
    "    np.percentile(tprs_1_3, 2.5, axis=0),\n",
    "    np.percentile(tprs_1_3, 97.5, axis=0)\n",
    "    ]\n",
    "\n",
    "mean_auc_1_3 = np.mean(aucs_1_3)\n",
    "auc_1_3_CI95 = [\n",
    "    np.percentile(aucs_1_3, 2.5),\n",
    "    np.percentile(aucs_1_3, 97.5)\n",
    "    ]\n",
    "\n",
    "\n",
    "# Hospital A (2013) on MIMIC-III\n",
    "mean_tpr_1_mimic = np.mean(tprs_1_mimic, axis=0)\n",
    "mean_tpr_1_mimic[-1] = 1.0\n",
    "tpr_1_mimic_CI95 = [\n",
    "    np.percentile(tprs_1_mimic, 2.5, axis=0),\n",
    "    np.percentile(tprs_1_mimic, 97.5, axis=0)\n",
    "    ]\n",
    "\n",
    "mean_auc_1_mimic = np.mean(aucs_1_mimic)\n",
    "auc_1_mimic_CI95 = [\n",
    "    np.percentile(aucs_1_mimic, 2.5),\n",
    "    np.percentile(aucs_1_mimic, 97.5)\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "# Hospital A (2016) on Hospital A (2013)\n",
    "mean_tpr_2_1 = np.mean(tprs_2_1, axis=0)\n",
    "mean_tpr_2_1[-1] = 1.0\n",
    "tpr_2_1_CI95 = [\n",
    "    np.percentile(tprs_2_1, 2.5, axis=0),\n",
    "    np.percentile(tprs_2_1, 97.5, axis=0)\n",
    "    ]\n",
    "\n",
    "mean_auc_2_1 = np.mean(aucs_2_1)\n",
    "auc_2_1_CI95 = [\n",
    "    np.percentile(aucs_2_1, 2.5),\n",
    "    np.percentile(aucs_2_1, 97.5)\n",
    "    ]\n",
    "\n",
    "\n",
    "# Hospital A (2016) on Hospital B (2017-18)\n",
    "mean_tpr_2_3 = np.mean(tprs_2_3, axis=0)\n",
    "mean_tpr_2_3[-1] = 1.0\n",
    "tpr_2_3_CI95 = [\n",
    "    np.percentile(tprs_2_3, 2.5, axis=0),\n",
    "    np.percentile(tprs_2_3, 97.5, axis=0)\n",
    "    ]\n",
    "\n",
    "mean_auc_2_3 = np.mean(aucs_2_3)\n",
    "auc_2_3_CI95 = [\n",
    "    np.percentile(aucs_2_3, 2.5),\n",
    "    np.percentile(aucs_2_3, 97.5)\n",
    "    ]\n",
    "\n",
    "# Hospital A (2016) on MIMIC-III\n",
    "mean_tpr_2_mimic = np.mean(tprs_2_mimic, axis=0)\n",
    "mean_tpr_2_mimic[-1] = 1.0\n",
    "tpr_2_mimic_CI95 = [\n",
    "    np.percentile(tprs_2_mimic, 2.5, axis=0),\n",
    "    np.percentile(tprs_2_mimic, 97.5, axis=0)\n",
    "    ]\n",
    "\n",
    "mean_auc_2_mimic = np.mean(aucs_2_mimic)\n",
    "auc_2_mimic_CI95 = [\n",
    "    np.percentile(aucs_2_mimic, 2.5),\n",
    "    np.percentile(aucs_2_mimic, 97.5)\n",
    "    ]\n",
    "\n",
    "# For AUC plot\n",
    "temp_list1 = []\n",
    "for item1, item2 in zip(aucs_1_3, aucs_1_mimic):\n",
    "    temp = {'Hospital B (2017-18)': item1, 'MIMIC (2001-12)': item2}\n",
    "    temp_list1.append(temp)\n",
    "heights1 = pd.DataFrame(temp_list1)\n",
    "\n",
    "temp_list2 = []\n",
    "for item1, item2 in zip(aucs_2_3, aucs_2_mimic):\n",
    "    temp = {'Hospital B (2017-18)': item1, 'MIMIC (2001-12)': item2}\n",
    "    temp_list2.append(temp)\n",
    "heights2 = pd.DataFrame(temp_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig12, ax12 = plt.subplots()\n",
    "\n",
    "sns.pointplot(data=heights1, errorbar=(\"pi\", 95), ax=ax12,\n",
    "              capsize=0.1, color=\"0\", linestyle=\"none\")\n",
    "sns.swarmplot(data=heights1, ax=ax12, color=\"tab:blue\", alpha=0.5)\n",
    "ax12.set_xlabel(None)\n",
    "ax12.set_ylabel('Performance (AUROC)')\n",
    "ax12.set_title(\"XGBoost trained on Hospital A (2013)\")\n",
    "ax12.grid(linestyle=':', axis='y')\n",
    "ax12.set_ylim(0.5, 1.0)\n",
    "fig12.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig13, ax13 = plt.subplots()\n",
    "\n",
    "sns.pointplot(data=heights2, errorbar=(\"pi\", 95), ax=ax13,\n",
    "              capsize=0.1, color=\"0\", linestyle=\"none\")\n",
    "sns.swarmplot(data=heights2, ax=ax13, color=\"tab:blue\", alpha=0.5)\n",
    "ax13.set_xlabel(None)\n",
    "ax13.set_ylabel('Performance (AUROC)')\n",
    "ax13.set_title(\"XGBoost trained on Hospital A (2016)\")\n",
    "ax13.grid(linestyle=':', axis='y')\n",
    "ax13.set_ylim(0.5, 1.0)\n",
    "fig13.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig14, ax14 = plt.subplots(1, 2, figsize=plots.stdfigsize(63, n_cols=2, layout=\"double\"))\n",
    "\n",
    "sns.pointplot(data=heights1, errorbar=(\"pi\", 95), ax=ax14[0],\n",
    "              capsize=0.1, color=\"0\", linestyle=\"none\")\n",
    "sns.swarmplot(data=heights1, ax=ax14[0], color=\"tab:blue\", alpha=0.5, size=2.2)\n",
    "ax14[0].set_xlabel(None)\n",
    "ax14[0].set_ylabel('Performance (AUROC)')\n",
    "ax14[0].set_title(\"XGBoost trained on Hospital A (2013)\")\n",
    "ax14[0].grid(linestyle=':', axis='y')\n",
    "ax14[0].set_ylim(0.5, 1.0)\n",
    "ax14[0].text(-0.1, 1.1, \"a\", transform=ax14[0].transAxes,\n",
    "               fontweight='bold', va='top')\n",
    "\n",
    "sns.pointplot(data=heights2, errorbar=(\"pi\", 95), ax=ax14[1],\n",
    "              capsize=0.1, color=\"0\", linestyle=\"none\")\n",
    "sns.swarmplot(data=heights2, ax=ax14[1], color=\"tab:blue\", alpha=0.5, size=2)\n",
    "ax14[1].set_xlabel(None)\n",
    "ax14[1].set_title(\"XGBoost trained on Hospital A (2016)\")\n",
    "ax14[1].grid(linestyle=':', axis='y')\n",
    "ax14[1].set_ylim(0.5, 1.0)\n",
    "ax14[1].text(-0.1, 1.1, \"b\", transform=ax14[1].transAxes,\n",
    "               fontweight='bold', va='top')\n",
    "\n",
    "fig14.tight_layout()\n",
    "# plt.savefig(figure_path / 'SIfig3.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calibration plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig15, ax15 = plt.subplots(2, 2)\n",
    "\n",
    "# Hospital A (2013) on Hospital A (2016)\n",
    "mean_fop_1_2 = np.mean(fops_1_2, axis=0)\n",
    "fop_1_2_CI95 = [np.percentile(fops_1_2, 2.5, axis=0),\n",
    "                np.percentile(fops_1_2, 97.5, axis=0)]\n",
    "\n",
    "ax15[0,0].plot(mean_mpv, mean_fop_1_2, marker=\"o\")\n",
    "ax15[0,0].fill_between(\n",
    "    mean_mpv, fop_1_2_CI95[0], fop_1_2_CI95[1], alpha=0.2)\n",
    "ax15[0,0].plot([0, 1], [0, 1], linestyle=\"--\", color=\"k\", alpha=0.8)\n",
    "\n",
    "ax15[0,0].tick_params(axis='x')\n",
    "ax15[0,0].tick_params(axis='y')\n",
    "ax15[0,0].set_ylabel(\"True Positive Rate\")\n",
    "ax15[0,0].set_title(\"Train 1, Test 2\")\n",
    "ax15[0,0].set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\n",
    "ax15[0,0].grid(linestyle=':')\n",
    "\n",
    "\n",
    "# Hospital A (2013) on Hospital B (2017-18)\n",
    "mean_fop_1_3 = np.mean(fops_1_3, axis=0)\n",
    "fop_1_3_CI95 = [np.percentile(fops_1_3, 2.5, axis=0),\n",
    "                np.percentile(fops_1_3, 97.5, axis=0)]\n",
    "\n",
    "ax15[0,1].plot(mean_mpv, mean_fop_1_3, marker=\"o\")\n",
    "ax15[0,1].fill_between(\n",
    "    mean_mpv, fop_1_3_CI95[0], fop_1_3_CI95[1], alpha=0.2)\n",
    "ax15[0,1].plot([0, 1], [0, 1], linestyle=\"--\", color=\"k\", alpha=0.8)\n",
    "\n",
    "ax15[0,1].tick_params(axis='x')\n",
    "ax15[0,1].tick_params(axis='y')\n",
    "ax15[0,1].set_title(\"Train 1, Test 3\")\n",
    "ax15[0,1].set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\n",
    "ax15[0,1].grid(linestyle=':')\n",
    "\n",
    "\n",
    "# Hospital A (2016) on Hospital A (2013)\n",
    "mean_fop_2_1 = np.mean(fops_2_1, axis=0)\n",
    "fop_2_1_CI95 = [np.percentile(fops_2_1, 2.5, axis=0),\n",
    "                np.percentile(fops_2_1, 97.5, axis=0)]\n",
    "\n",
    "ax15[1,0].plot(mean_mpv, mean_fop_2_1, marker=\"o\")\n",
    "ax15[1,0].fill_between(\n",
    "    mean_mpv, fop_2_1_CI95[0], fop_2_1_CI95[1], alpha=0.2)\n",
    "ax15[1,0].plot([0, 1], [0, 1], linestyle=\"--\", color=\"k\", alpha=0.8)\n",
    "\n",
    "ax15[1,0].tick_params(axis='x')\n",
    "ax15[1,0].tick_params(axis='y')\n",
    "ax15[1,0].set_xlabel(\"Mean estimated probability\")\n",
    "ax15[1,0].set_ylabel(\"Fraction of positive label\")\n",
    "ax15[1,0].set_title(\"Train 2, Test 1\")\n",
    "ax15[1,0].set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\n",
    "ax15[1,0].grid(linestyle=':')\n",
    "\n",
    "\n",
    "# Hospital A (2016) on Hospital B (2017-18)\n",
    "mean_fop_2_3 = np.mean(fops_2_3, axis=0)\n",
    "fop_2_3_CI95 = [\n",
    "    np.percentile(fops_2_3, 2.5, axis=0),\n",
    "    np.percentile(fops_2_3, 97.5, axis=0)\n",
    "    ]\n",
    "\n",
    "ax15[1,1].plot(mean_mpv, mean_fop_2_3, marker=\"o\")\n",
    "ax15[1,1].fill_between(\n",
    "    mean_mpv, fop_2_3_CI95[0], fop_2_3_CI95[1], alpha=0.2)\n",
    "ax15[1,1].plot([0, 1], [0, 1], linestyle=\"--\", color=\"k\", alpha=0.8)\n",
    "\n",
    "ax15[1,1].tick_params(axis='x')\n",
    "ax15[1,1].tick_params(axis='y')\n",
    "ax15[1,1].set_xlabel(\"Mean estimated probability\")\n",
    "ax15[1,1].set_title(\"Train 2, Test 3\")\n",
    "ax15[1,1].set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\n",
    "ax15[1,1].grid(linestyle=':')\n",
    "\n",
    "# plt.savefig(\"Calibration_generalization.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on MIMIC III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(basedir / \"Development_notebooks\" /  \"hyperparameters\" / \"bilateral_infiltrates_model_hyperparams.json\", \"r\") as bilat:\n",
    "    cxr_model_hyperparams = json.load(bilat)\n",
    "\n",
    "cxr_model_hyperparams['base_score'] = float(cxr_model_hyperparams['base_score'])    \n",
    "cxr_model_hyperparams['n_estimators'] = int(cxr_model_hyperparams['n_estimators'])\n",
    "cxr_model_hyperparams['max_depth'] = int(cxr_model_hyperparams['max_depth'])\n",
    "cxr_model_hyperparams['learning_rate'] = float(cxr_model_hyperparams['learning_rate'])\n",
    "cxr_model_hyperparams['gamma'] = float(cxr_model_hyperparams['gamma'])\n",
    "cxr_model_hyperparams['min_child_weight'] = float(cxr_model_hyperparams['min_child_weight'])\n",
    "cxr_model_hyperparams['max_delta_step'] = float(cxr_model_hyperparams['max_delta_step'])\n",
    "cxr_model_hyperparams['subsample'] = float(cxr_model_hyperparams['subsample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5 = training_data[cols[which][0]].to_numpy()\n",
    "Y5 = training_data[cols[which][1]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize\n",
    "vect = CountVectorizer(\n",
    "    tokenizer=tokenizer_better,\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=200\n",
    "    )\n",
    "\n",
    "vect.fit(X5)\n",
    "\n",
    "bilat_infilt_vect = vect.transform(X5).toarray()\n",
    "\n",
    "bilateral_infiltrates_model = XGBClassifier(\n",
    "    **cxr_model_hyperparams,\n",
    "    tree_method='hist',\n",
    "    random_state=0\n",
    "    )\n",
    "\n",
    "bilateral_infiltrates_model.fit(bilat_infilt_vect, Y5)\n",
    "\n",
    "# with open(\"src/bilateral_infiltrates_model.pkl\", \"rb\") as file:\n",
    "#     bilateral_infiltrates_model = pickle.load(file)\n",
    "    \n",
    "# with open(\"src/bilateral_infiltrates_model_vectorizer.pkl\", \"rb\") as file:\n",
    "#     vect = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write vect and bilateral_infiltrates_model to disk\n",
    "# import pickle\n",
    "\n",
    "# with open(\"src/bilateral_infiltrates_model.pickle\", \"wb\") as bilat:\n",
    "#     pickle.dump(bilateral_infiltrates_model, bilat)\n",
    "    \n",
    "# with open(\"src/bilateral_infiltrates_model_vectorizer.pkl\", \"wb\") as bilat:\n",
    "#     pickle.dump(vect, bilat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tprs_mimic = []\n",
    "aucs_mimic = []\n",
    "fops_mimic = []\n",
    "preds_mimic = []\n",
    "\n",
    "for i in tqdm(range(n_boot)):\n",
    "    # # If wanting to get one report per patient, uncomment the next line\n",
    "    # boot_mimic3 = mimic_iii.groupby('encounter_id').sample(n=1).reset_index(drop=True)\n",
    "    # This line resamples the data, WITH replacement\n",
    "    boot_mimic3 = mimic_iii.sample(n=len(mimic_iii), replace=True, axis=0).reset_index(drop=True)\n",
    "    \n",
    "    encounters = boot_mimic3['encounter_id'].unique()\n",
    "    \n",
    "    cv = KFold()\n",
    "    output1, output2, output3, output4, output5 = Parallel(n_jobs=5)(delayed(custom_cv_not_train)(\n",
    "        bilateral_infiltrates_model,\n",
    "        boot_mimic3,\n",
    "        cols2,\n",
    "        which2,\n",
    "        encounters,\n",
    "        vect,\n",
    "        train_index,\n",
    "        mean_fpr,\n",
    "        mean_mpv\n",
    "        ) for train_index, test_index in cv.split(encounters))\n",
    "    \n",
    "    aucs_mimic.append(np.mean([output1[0], output2[0], output3[0], output4[0], output5[0]]))\n",
    "    preds_mimic.extend(output1[1])\n",
    "    preds_mimic.extend(output2[1])\n",
    "    preds_mimic.extend(output3[1])\n",
    "    preds_mimic.extend(output4[1])\n",
    "    preds_mimic.extend(output5[1])\n",
    "    tprs_mimic.append(np.mean([output1[2], output2[2], output3[2], output4[2], output5[2]], axis=0))\n",
    "    fops_mimic.append(np.mean([output1[3], output2[3], output3[3], output4[3], output5[3]], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curve - test bilateral infiltrates model on MIMIC III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tpr_mimic = np.mean(tprs_mimic, axis=0)\n",
    "mean_tpr_mimic[-1] = 1.0\n",
    "tpr_mimic_CI95 = [\n",
    "    np.percentile(tprs_mimic, 2.5, axis=0),\n",
    "    np.percentile(tprs_mimic, 97.5, axis=0)\n",
    "    ]\n",
    "\n",
    "mean_auc_mimic = np.mean(aucs_mimic)\n",
    "auc_mimic_CI95 = [\n",
    "    np.percentile(aucs_mimic, 2.5),\n",
    "    np.percentile(aucs_mimic, 97.5)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig16, ax16 = plt.subplots(figsize=plots.stdfigsize(74, layout=\"single\"))\n",
    "\n",
    "ax16.plot(\n",
    "    mean_fpr,\n",
    "    mean_tpr_mimic,\n",
    "    label=f\"Mean AUROC: {mean_auc_mimic:.2f}\\n95%CI: {auc_mimic_CI95[0]:.2f}-{auc_mimic_CI95[1]:.2f}\"\n",
    "    )\n",
    "ax16.fill_between(\n",
    "    mean_fpr,\n",
    "    tpr_mimic_CI95[0],\n",
    "    tpr_mimic_CI95[1],\n",
    "    alpha=0.2\n",
    "    )\n",
    "\n",
    "ax16.plot([0, 1], [0, 1], linestyle=\"--\", color=\"k\", alpha=0.8)\n",
    "\n",
    "ax16.set_ylabel(\"True Positive Rate\")\n",
    "ax16.set_xlabel(\"False Positive Rate\")\n",
    "# ax16.set_title(\"Bilateral infiltrates model on MIMIC (2001-12)\")\n",
    "ax16.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\n",
    "ax16.grid(linestyle=':')\n",
    "ax16.legend(loc='best', frameon=False)\n",
    "\n",
    "fig16.tight_layout()\n",
    "# plt.savefig(figure_path / 'SIfig4.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calibration curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_fop_mimic = np.mean(fops_mimic, axis=0)\n",
    "fop_mimic_CI95 = [\n",
    "    np.percentile(fops_mimic, 2.5, axis=0),\n",
    "    np.percentile(fops_mimic, 97.5, axis=0)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig17, ax17 = plt.subplots()\n",
    "\n",
    "ax17.plot(mean_mpv, mean_fop_mimic, marker=\"o\")\n",
    "ax17.fill_between(\n",
    "    mean_mpv, fop_mimic_CI95[0], fop_mimic_CI95[1], alpha=0.2)\n",
    "ax17.plot([0, 1], [0, 1], linestyle=\"--\", color=\"k\", alpha=0.8)\n",
    "\n",
    "ax17.tick_params(axis='x')\n",
    "ax17.tick_params(axis='y')\n",
    "ax17.set_xlabel(\"Mean predicted probability\")\n",
    "ax17.set_ylabel(\"Fraction of positive labels\")\n",
    "ax17.set_title(\"Bilateral infiltrates model on MIMIC III\")\n",
    "ax17.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\n",
    "ax17.grid(linestyle=':')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_mimic = vect.transform(X4).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.explainers.Tree(\n",
    "    bilateral_infiltrates_model,\n",
    "    vect_mimic,\n",
    "    feature_perturbation='interventional',\n",
    "    feature_names=vect.get_feature_names_out(),\n",
    "    model_output='probability'\n",
    "    )\n",
    "\n",
    "shap_values = explainer(vect_mimic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig99, axis1 = plt.subplots(figsize=plots.stdfigsize(100, layout=\"single\"))\n",
    "\n",
    "shap.plots.beeswarm(shap_values, max_display=15, show=False, s=3,\n",
    "                    ax=axis1, plot_size=None, group_remaining_features=False)\n",
    "\n",
    "axis1.set_title(\"Bilateral Infiltrates Model on MIMIC (2001-12)\", fontsize=7)\n",
    "axis1.set_xlabel(\"SHAP values\", fontsize=7)\n",
    "axis1.tick_params(axis='both', which='both', labelsize=7)\n",
    "axis1.set_xlim(-0.6, 0.6)\n",
    "\n",
    "cb1 = plt.gcf().get_axes()[1]\n",
    "cb1.set_yticklabels(['0', str(vect_mimic.max())], fontsize=7)\n",
    "cb1.set_ylabel(\"Word count in report\", fontsize=7)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figure_path / \"SIfig2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.waterfall_plot(shap_values[25], max_display=15, show=False)\n",
    "\n",
    "# axis5 = plt.gca()\n",
    "# axis5.set_title(\"SHAP values for sample 25\", fontsize=20)\n",
    "\n",
    "# for eje6 in plt.gcf().get_axes():\n",
    "#     eje6.tick_params(axis='both', which='both', labelsize=14)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mimic_iii.loc[25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interrater agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig18, ax18 = plt.subplots(2, 3))\n",
    "\n",
    "# # Label frequency Hospital B (2017-18)\n",
    "# ax18[0,0].hist(segmented_cohort3_original.score_final)\n",
    "# ax18[0,0].set_ylabel(\"Counts\")\n",
    "# ax18[0,0].set_title(\"Hospital B (2017-18) label frequency\")\n",
    "# ax18[0,0].grid(linestyle=':')\n",
    "\n",
    "# # Label frequency Hospital A (2013)\n",
    "# ax18[0,1].hist(segmented.cxr_score)\n",
    "# ax18[0,1].set_title(\"Hospital A (2013) label frequency\")\n",
    "# ax18[0,1].grid(linestyle=':')\n",
    "\n",
    "# # Hospital A (2013) on Hospital B (2017-18)\n",
    "# ax18[0,2].hist(preds_1_3, bins=10)\n",
    "# ax18[0,2].set_title(\"Train Hospital A (2013), Test Hospital B (2017-18) XGBoost probabilites\")\n",
    "# ax18[0,2].grid(linestyle=':')\n",
    "\n",
    "\n",
    "# # Label frequency Hospital B (2017-18)\n",
    "# ax18[1,0].hist(segmented_cohort3_original.score_final)\n",
    "# ax18[1,0].set_ylabel(\"Counts\")\n",
    "# ax18[1,0].set_title(\"Hospital B (2017-18) label frequency\")\n",
    "# ax18[1,0].set_xlabel(\"Labels\")\n",
    "# ax18[1,0].grid(linestyle=':')\n",
    "\n",
    "# # Label frequency Hospital A (2016)\n",
    "# ax18[1,1].hist(segmented_cohort2.score)\n",
    "# ax18[1,1].set_title(\"Hospital A (2016) label frequency\")\n",
    "# ax18[1,1].set_xlabel(\"Labels\")\n",
    "# ax18[1,1].grid(linestyle=':')\n",
    "\n",
    "# # Hospital A (2016) on Hospital B (2017-18)\n",
    "# ax18[1,2].hist(preds_2_3, bins=10)\n",
    "# ax18[1,2].set_xlabel(\"Estimated probabilities\")\n",
    "# ax18[1,2].set_title(\"Train Hospital A (2016), Test Hospital B (2017-18) XGBoost probabilites\")\n",
    "# ax18[1,2].grid(linestyle=':')\n",
    "\n",
    "# fig18.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like an easy explanation for XGBoost doing better in predicting Hospital B (2017-18) when trained on Hospital A (2016) is simply the greater similarity in class/label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1, l2 = 0.1, 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "mimic_iii['cxr_score_probability'] = bilateral_infiltrates_model.predict_proba(vect_mimic)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = mimic_iii['curt_bl_infiltrates_(1=yes)'] == 1\n",
    "g = mimic_iii['eryn_bl_infiltrates_(1=yes)'] == 1\n",
    "\n",
    "x = mimic_iii['curt_bl_infiltrates_(1=yes)'] == 0\n",
    "y = mimic_iii['eryn_bl_infiltrates_(1=yes)'] == 0\n",
    "\n",
    "dis = mimic_iii['curt_bl_infiltrates_(1=yes)'] != mimic_iii['eryn_bl_infiltrates_(1=yes)']\n",
    "\n",
    "mimic_iii.loc[f & g, 'agreement'] = \"Agree Yes\"\n",
    "mimic_iii.loc[x & y, 'agreement'] = \"Agree No\"\n",
    "mimic_iii.loc[dis, 'agreement'] = \"Disagree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mean and 95% CI of 'cxr_score_probability', broken down by the values of the agreement column\n",
    "disagreement_df = mimic_iii.groupby('agreement')['cxr_score_probability'].agg(['mean', 'std', 'count'])\n",
    "disagreement_df['ci95'] = 1.96 * disagreement_df['std'] / np.sqrt(disagreement_df['count'])\n",
    "disagreement_df['lower'] = disagreement_df['mean'] - disagreement_df['ci95']\n",
    "disagreement_df['upper'] = disagreement_df['mean'] + disagreement_df['ci95']\n",
    "disagreement_df = disagreement_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig19, ax19 = plt.subplots(figsize=plots.stdfigsize(0, layout=\"single\"))\n",
    "\n",
    "sns.pointplot(data=mimic_iii, x='agreement', y='cxr_score_probability',\n",
    "              errorbar=(\"ci\", 95),capsize=0.1, ax=ax19, color=\"0\",\n",
    "              linestyle=\"none\")\n",
    "sns.swarmplot(data=mimic_iii, x='agreement', y='cxr_score_probability',\n",
    "              ax=ax19, color=\"tab:blue\", alpha=0.5, size=1.3)\n",
    "\n",
    "ax19.set_ylabel(\"BI Model probabilities\")\n",
    "ax19.grid(linestyle=':', axis='y')\n",
    "ax19.set_xlabel(\"\")\n",
    "ax19.set_ylim(0, 1.0)\n",
    "\n",
    "fig19.tight_layout()\n",
    "# plt.savefig(figure_path / 'fig3_disagreement.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(mimic_iii['curt_bl_infiltrates_(1=yes)'], bilateral_infiltrates_model.predict(vect_mimic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(mimic_iii['curt_bl_infiltrates_(1=yes)'], bilateral_infiltrates_model.predict(vect_mimic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mimic_iii['predicted'] = mimic_iii['cxr_score_probability'] >= threshold\n",
    "# If threshold == 0.5, the line of code above and the line of code below do the exact same thing\n",
    "mimic_iii['predicted'] = bilateral_infiltrates_model.predict(vect_mimic)\n",
    "\n",
    "cf = confusion_matrix(Y4, mimic_iii['predicted'])\n",
    "cf_mod = cf.transpose()[::-1, ::-1]\n",
    "\n",
    "strings = np.asarray([['True positives\\n', 'False positives\\n'],\n",
    "                      ['False negatives\\n', 'True negatives\\n']])\n",
    "\n",
    "labels = (np.asarray([\"{0} {1:.0f}\".format(string, value)\n",
    "                      for string, value in zip(strings.flatten(),\n",
    "                                               cf_mod.flatten())])\n",
    "         ).reshape(2, 2)\n",
    "\n",
    "fig20, ax20 = plt.subplots(figsize=plots.stdfigsize(0, layout=\"single\"))\n",
    "sns.heatmap(cf_mod, fmt='', annot=labels, cmap='Blues', cbar=False, ax=ax20)\n",
    "ax20.set_ylabel(\"BI Model adjudicated\")\n",
    "ax20.set_xlabel(\"Ground truth\")\n",
    "ax20.tick_params(axis='both', bottom=False, left=False,\n",
    "                labelbottom=False, labelleft=False)\n",
    "\n",
    "fig20.tight_layout()\n",
    "# plt.savefig(figure_path / 'fig3_cf.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig21, ax21 = plt.subplots(2, 2, figsize=plots.stdfigsize(155, n_rows=2, n_cols=2, layout=\"double\"))\n",
    "\n",
    "# ROC curve\n",
    "ax21[0,0].plot(\n",
    "    mean_fpr,\n",
    "    mean_tpr_mimic,\n",
    "    label=f\"Mean AUROC: {mean_auc_mimic:.2f}\"\n",
    "    )\n",
    "ax21[0,0].fill_between(\n",
    "    mean_fpr,\n",
    "    tpr_mimic_CI95[0],\n",
    "    tpr_mimic_CI95[1],\n",
    "    alpha=0.2\n",
    "    )\n",
    "ax21[0,0].plot([0, 1], [0, 1], linestyle=\"--\", color=\"k\", alpha=0.8, label=\"No-skill line\")\n",
    "\n",
    "# Calibration curve\n",
    "ax21[0,1].plot(mean_mpv, mean_fop_mimic, marker=\"o\")\n",
    "ax21[0,1].fill_between(\n",
    "    mean_mpv, fop_mimic_CI95[0], fop_mimic_CI95[1], alpha=0.2)\n",
    "ax21[0,1].plot([0, 1], [0, 1], linestyle=\"--\", color=\"k\", alpha=0.8, label=\"Perfectly calibrated\")\n",
    "\n",
    "# Confusion matrix\n",
    "sns.heatmap(cf_mod, fmt='', annot=labels, cmap='Blues', cbar=False, ax=ax21[1,0])\n",
    "\n",
    "# Interrater disagreement\n",
    "sns.pointplot(data=mimic_iii, x='agreement', y='cxr_score_probability',\n",
    "              errorbar=(\"ci\", 95),capsize=0.1, ax=ax21[1,1], color=\"0\",\n",
    "              linestyle=\"none\")\n",
    "sns.swarmplot(data=mimic_iii, x='agreement', y='cxr_score_probability',\n",
    "              ax=ax21[1,1], color=\"tab:blue\", alpha=0.5, size=1.3)\n",
    "\n",
    "# Plot properties\n",
    "ax21[0,0].set_ylabel(\"True Positive Rate\")\n",
    "ax21[0,0].set_xlabel(\"False Positive Rate\")\n",
    "ax21[0,0].set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\n",
    "ax21[0,0].grid(linestyle=':')\n",
    "ax21[0,0].legend(loc='lower right', frameon=False)\n",
    "ax21[0,0].text(-0.1, 1.05, \"a\", transform=ax21[0,0].transAxes,\n",
    "               fontweight='bold', va='top')\n",
    "\n",
    "ax21[0,1].tick_params(axis='x')\n",
    "ax21[0,1].tick_params(axis='y')\n",
    "ax21[0,1].set_xlabel(\"Mean predicted probability\")\n",
    "ax21[0,1].set_ylabel(\"Fraction of positive labels\")\n",
    "ax21[0,1].set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\n",
    "ax21[0,1].grid(linestyle=':')\n",
    "ax21[0,1].legend(loc='best', frameon=False)\n",
    "ax21[0,1].text(-0.1, 1.05, \"b\", transform=ax21[0,1].transAxes,\n",
    "               fontweight='bold', va='top')\n",
    "\n",
    "ax21[1,0].set_ylabel(\"Bilateral Infiltrates Model adjudicated\")\n",
    "ax21[1,0].set_xlabel(\"Ground truth\")\n",
    "ax21[1,0].tick_params(axis='both', bottom=False, left=False,\n",
    "                labelbottom=False, labelleft=False)\n",
    "ax21[1,0].text(-0.1, 1.05, \"c\", transform=ax21[1,0].transAxes,\n",
    "               fontweight='bold', va='top')\n",
    "\n",
    "ax21[1,1].set_ylabel(\"Mean Bilateral Inflitrates Model probabilities\")\n",
    "ax21[1,1].grid(linestyle=':', axis='y')\n",
    "ax21[1,1].set_xlabel(\"\")\n",
    "ax21[1,1].set_ylim(0, 1.0)\n",
    "ax21[1,1].text(-0.1, 1.05, \"d\", transform=ax21[1,1].transAxes,\n",
    "               fontweight='bold', va='top')\n",
    "\n",
    "\n",
    "fig21.tight_layout()\n",
    "# plt.savefig(figure_path / \"fig3.png\")\n",
    "# plt.savefig(figure_path / \"fig3.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SI Table on different choices for cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_hospital_a = vect.transform(X1).toarray()\n",
    "segmented['cxr_score_probability'] = bilateral_infiltrates_model.predict_proba(vect_hospital_a)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "thresholds = np.linspace(0, 1, 1001)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    predictions = segmented['cxr_score_probability'] >= threshold\n",
    "    \n",
    "    cf = confusion_matrix(Y1, predictions)\n",
    "    TN = cf[0,0]\n",
    "    FP = cf[0,1]\n",
    "    FN = cf[1,0]\n",
    "    TP = cf[1,1]\n",
    "    \n",
    "    results.append({\n",
    "        'threshold': threshold,\n",
    "        'false_negative_rate': round(FN / (FN + TP), 3),\n",
    "        'false_positive_rate': round(FP / (FP + TN), 3),\n",
    "        'precision': round(precision_score(Y1, predictions), 3),\n",
    "        'negative_predictive_value': round(TN / (TN + FN), 3),\n",
    "        'accuracy': round(accuracy_score(Y1, predictions), 3),\n",
    "        'f1': round(f1_score(Y1, predictions), 3),\n",
    "        'youden_j': round((TP / (TP + FN)) + (TN / (TN + FP)) - 1, 3)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "max_youden = results_df['youden_j'] == results_df['youden_j'].max()\n",
    "max_f1 = results_df['f1'] == results_df['f1'].max()\n",
    "max_accuracy = results_df['accuracy'] == results_df['accuracy'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.loc[max_accuracy].sort_values('threshold', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(results_df['threshold'], results_df['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.loc[max_f1].sort_values('threshold', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(results_df['threshold'], results_df['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.loc[max_youden].sort_values('threshold', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(results_df['threshold'], results_df['youden_j'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.loc[max_accuracy & max_f1].sort_values('threshold', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How would all of this look when raters agree vs. when they disagree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_iii_agree = mimic_iii.loc[(mimic_iii['curt_bl_infiltrates_(1=yes)'] == mimic_iii['eryn_bl_infiltrates_(1=yes)'])]\n",
    "mimic_iii_disagree = mimic_iii.loc[(mimic_iii['curt_bl_infiltrates_(1=yes)'] != mimic_iii['eryn_bl_infiltrates_(1=yes)'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mimic_iii_agree), len(mimic_iii_disagree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"AUROC agree: {roc_auc_score(mimic_iii_agree['curt_bl_infiltrates_(1=yes)'], mimic_iii_agree['cxr_score_probability'])}\")\n",
    "print(f\"AUROC disagree: {roc_auc_score(mimic_iii_disagree['curt_bl_infiltrates_(1=yes)'], mimic_iii_disagree['cxr_score_probability'])}\")\n",
    "\n",
    "print(f\"Accuracy agree: {accuracy_score(mimic_iii_agree['curt_bl_infiltrates_(1=yes)'], mimic_iii_agree['predicted'])}\")\n",
    "print(f\"Accuracy disagree: {accuracy_score(mimic_iii_disagree['curt_bl_infiltrates_(1=yes)'], mimic_iii_disagree['predicted'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibrationDisplay\n",
    "\n",
    "prob_true, prob_pred = calibration_curve(mimic_iii_agree['curt_bl_infiltrates_(1=yes)'], mimic_iii_agree['cxr_score_probability'], n_bins=10)\n",
    "CalibrationDisplay(prob_true, prob_pred, mimic_iii_agree['cxr_score_probability']).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_true, prob_pred = calibration_curve(mimic_iii_disagree['curt_bl_infiltrates_(1=yes)'], mimic_iii_disagree['cxr_score_probability'], n_bins=10)\n",
    "CalibrationDisplay(prob_true, prob_pred, mimic_iii_disagree['cxr_score_probability']).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real deal: the interrater disagreement graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_conf = mimic_iii.loc[(mimic_iii['cxr_score_probability'] >= l1) & (mimic_iii['cxr_score_probability'] < l2)]\n",
    "high_conf_no = mimic_iii.loc[mimic_iii['cxr_score_probability'] < l1]\n",
    "high_conf_yes = mimic_iii.loc[mimic_iii['cxr_score_probability'] >= l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(low_conf), len(high_conf_no), len(high_conf_yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy high confidence no: {accuracy_score(high_conf_no['curt_bl_infiltrates_(1=yes)'], high_conf_no['predicted'])}\")\n",
    "print(f\"Accuracy low confidence: {accuracy_score(low_conf['curt_bl_infiltrates_(1=yes)'], low_conf['predicted'])}\")\n",
    "print(f\"Accuracy high confidence yes: {accuracy_score(high_conf_yes['curt_bl_infiltrates_(1=yes)'], high_conf_yes['predicted'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I remember looking at the reports, and wondering about how frequently would the model give a low probability to a report that was rated \"yes\" by both raters. Or a high probability to a report that was rated \"no\" by both raters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I remember looking at the reports, and wondering about how frequently would the model give a low probability to a report that was rated \"yes\" by both raters. Or a high probability to a report that was rated \"no\" by both raters. This is the graph that answers that question.\n",
    "low_conf_agree = mimic_iii_agree.loc[(mimic_iii_agree['cxr_score_probability'] >= l1) & (mimic_iii_agree['cxr_score_probability'] < l2)]\n",
    "high_conf_no_agree = mimic_iii_agree.loc[mimic_iii_agree['cxr_score_probability'] < l1]\n",
    "high_conf_yes_agree = mimic_iii_agree.loc[mimic_iii_agree['cxr_score_probability'] >= l2]\n",
    "\n",
    "low_conf_disagree = mimic_iii_disagree.loc[(mimic_iii_disagree['cxr_score_probability'] >= l1) & (mimic_iii_disagree['cxr_score_probability'] < l2)]\n",
    "high_conf_no_disagree = mimic_iii_disagree.loc[mimic_iii_disagree['cxr_score_probability'] < l1]\n",
    "high_conf_yes_disagree = mimic_iii_disagree.loc[mimic_iii_disagree['cxr_score_probability'] >= l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy high confidence no: {accuracy_score(high_conf_no_agree['curt_bl_infiltrates_(1=yes)'], high_conf_no_agree['predicted'])}\")\n",
    "print(f\"Accuracy low confidence: {accuracy_score(low_conf_agree['curt_bl_infiltrates_(1=yes)'], low_conf_agree['predicted'])}\")\n",
    "print(f\"Accuracy high confidence yes: {accuracy_score(high_conf_yes_agree['curt_bl_infiltrates_(1=yes)'], high_conf_yes_agree['predicted'])}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Accuracy high confidence no: {accuracy_score(high_conf_no_disagree['curt_bl_infiltrates_(1=yes)'], high_conf_no_disagree['predicted'])}\")\n",
    "print(f\"Accuracy low confidence: {accuracy_score(low_conf_disagree['curt_bl_infiltrates_(1=yes)'], low_conf_disagree['predicted'])}\")\n",
    "print(f\"Accuracy high confidence yes: {accuracy_score(high_conf_yes_disagree['curt_bl_infiltrates_(1=yes)'], high_conf_yes_disagree['predicted'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
