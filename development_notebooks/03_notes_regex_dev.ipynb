{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42b30a18",
   "metadata": {},
   "source": [
    "## This notebook has many modalities:  \n",
    "- If interested in comparing the capturing or adjudicating regex patterns, uncomment or comment out lines in the code cell defining the `text_match_all_risk_factors` function.  \n",
    "- One thing is to count how many notes were text-matched, and another is how many notes were labeled \"yes\". Go to code cell #10 to modify what you want to count.  \n",
    "- The code cells creating the plots will depend on the above choices.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576071e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6c1682",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd8a2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom imports\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import src.plots as plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098bca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will have the regex patterns to match on text\n",
    "def text_match_all_risk_factors(attn_notes):\n",
    "    '''\n",
    "    Adds boolean columns (flags) for specific risk factors\n",
    "    and for cardiogenic language. These flags represent whether\n",
    "    the note text contained the regular expression pattern.\n",
    "    \n",
    "    Inputs:\n",
    "    - attn_notes: pandas dataframe, attending physician notes data\n",
    "    \n",
    "    Outputs:\n",
    "    - attn_notes: pandas dataframe, with a flag columns added\n",
    "    '''\n",
    "\n",
    "    # patterns to search for in the text\n",
    "    pneumonia_pattern = '(?<!\\w)(?:PCPpneumonia|pneumonia|Pneumonia|PNEUMONIA|pneumoniae|pneunonia|pneunoniae|pnuemonia|bronchopneumonia|parapneumonic|PNA|CAP|VAP|HAP|HCAP|hcap|infection|abx|PCP)(?!\\w)'\n",
    "    aspiration_pattern = '(?i)(?<!\\w)(?<!possibility\\sof\\s)(?<!\\(\\?)(?<!no\\s{4}e\\/o\\s)(?<!unclear\\sif\\sthis\\sis\\s)(?<!cannot\\srule\\sout\\s)(?<!risk\\sfor\\s)(?<!risk\\sof\\s)(?<!\\?\\s)(?<!cover\\sfor\\s)(?<!no\\switnessed\\s)(?:aspiration|aspirating)(?!\\svs)(?!\\svs.)(?!\\?)(?!\\ss\\/p\\sR\\smainstem\\sintubation)(?!\\sprecautions)(?!\\sand\\sdrainage)(?!\\w)'\n",
    "    inhalation_pattern = '(?i)(?<!\\w)(?:inhaled\\sswimming\\spool\\swater|inhalation\\sinjury)(?!\\w)'\n",
    "    pulm_contusion_pattern = '(?i)(?<!\\w)(?:pulmonary|pulmoanry)\\s+(?:contusion|contusions)(?!\\w)'\n",
    "    vasculitis_pattern = '(?i)(?<!\\w)(?<!\\?\\s)(?<!less\\slikely\\s)(?:pulmonary\\svasculitis|vasculitis)(?!\\slabs)(?!\\sworkup)(?!\\sand\\scarcinomatosis\\sis\\sless\\slikely)(?!\\shighly\\sunlikely)(?!\\sless\\slikely)(?!\\w)'\n",
    "    drowning_pattern = '(?i)(?<!\\w)(?:drowned|drowning)(?!\\w)'\n",
    "    \n",
    "    sepsis_exclusion = ['r/o sepsis', 'no longer in', 'sepsis or cardiogenic shock', 'cardiogenic vs septic', 'potential for septic shock', 'cardiac vs septic', 'searching for evidence of',\n",
    "                        'shock mixed cardiogenic/vasodilatory', 'sepsis vs cardiogemnic','shock-septic vs cargdiogenic', 'shock-septic vs cardiogenic', 'severe sepsis resolved',\n",
    "                        'now off low dose vasopressor', 'shock-septic vs hypovolemic resolved', 'septic schock-resolved', 'shock-septic vs hypovolemic', 'septic shock off pressors', \n",
    "                        'cannot rule out septic/vasodilatory shock', 'previously vasoactive support for sepsis', 'billiary sepsis', 'septic shock secondary to esbl bacteremia',\n",
    "                        'c/b septic joints', 'septic shock due to pseudomonas bacteremia', 'no evidence of hemorrhage or sepsis', 'no evidence of ongoing hemorrhage or sepsis',\n",
    "                        'admitted with septic shock about months ago', 'history of aspergillus pneumonia/sepsis', 'mssa bactermia septic shock resolved', 'hypotension/sepsis vs hypercoaguable',\n",
    "                        'septic shock ards copd exacerbation hcap bacteremia', 'septic shock found to have klebsiella bacteremia', 'suspected sepsis', 'septic emboli syndrome',\n",
    "                        'takotsubo possible', 'takatsubo with possible', \"septic shock suspect recurrent takatsubo's\",'without active hemorrhage or sepsis', 'w/u for sepsis underway',\n",
    "                        'also concern for sepsis', 'cytopenias likely due to sepsis', 'sedation sepsis', 'septic shock with picture', 'no signs of sepsis at this time', 'potentially sepsis',\n",
    "                        'does not have septic shock', 'sepsis unlikely', 'no evidence of sepsis', 'does not have sig signs/sxs infection or sepsis', 'no source of sepsis', 'h/o urosepsis']\n",
    "    # sepsis_pattern = '(?i)(?<!\\w)(?:sepsis|urosepsis|septiuc|septic|ssepsis|sseptic|spetic)(?!\\w)'\n",
    "    \n",
    "    shock_exclusion = ['is no longer in septic shock', 'chest compressions or shocks', 'shock now resolved', 'potential for septic', 'septic shock off pressors', 'septic shock with picture',\n",
    "                       'no longer in shock', 'septic shock-resolved', 'septic shock due to pseudomonas bacteremia', 'shock has resolved', 'septic shock source uncertain', 'not in shock',\n",
    "                       'weaned off pressors', 'septic shock due to e-coli bactermia resolved', 'most likely distributive liver failure vs sepsis', 'shock--improving', 'terminated by shock',\n",
    "                       'icd interrogation reported two shocks', 'unlikely to be cardiogenic shock', 'cpr/shocks', 'shocks before rosc', 'underwent cardiopulmonary resuscitation and',\n",
    "                       'now off low dose vasopressor requirement', 'schock-resolved', 'vs hypovolemic resolved', 'cannot rule out septic/vasodilatory', 'obstructive shock due to pe and septic',\n",
    "                       'no operative intervention recommended except in shock situation']\n",
    "    # shock_pattern = '(?i)(?<!\\w)(?:shock|shocks|schock)(?!\\w)'\n",
    "    \n",
    "    overdose_pattern = '(?i)(?<!\\w)(?:overdose|drug\\soverdose)(?!\\w)'\n",
    "    trauma_pattern = '(?i)(?<!\\w)(?<!OGT\\s)(?<!hx\\sof\\s)(?<!no\\sreported\\sfalls\\sor\\s)(?<!to\\sprevent\\s)(?<!thoracic\\sand\\s)(?<!per\\s)(?<!spoke\\swith\\s)(?<!pmh\\sremote\\s)(?:trauma|traumatic|barotrauma|barotraumatic)(?!\\sbay)(?!\\/critical\\scare\\sservice)(?!\\'s\\sserivice\\sblessing)(?!\\w)'\n",
    "    pancreatitis_pattern = '(?i)(?<!\\w)pancreatitis(?!\\w)'\n",
    "    burn_pattern = '(?i)(?<!\\w)(?:burn|burns)(?!\\w)'\n",
    "    trali_pattern = '(?<!\\w)(?:TRALI|transfusion(?:-|\\s)related\\sacute\\slung\\sinjury|transfusion(?:-|\\s)associated\\sacute\\slung\\sinjury)(?!\\w)'\n",
    "    ards_pattern = '(?i)(?<!\\w)(?:ards|acute\\srespiratory\\sdistress\\ssyndrome|acute\\slung\\sinjury|ali|ardsnet|acute\\shypoxemic\\srespiratory\\sfailure)(?!\\w)'\n",
    "    pregnant_pattern = '(?i)(?<!\\w)(?:IUP|G\\dP\\d)(?!\\w)'\n",
    "    chf_pattern = '(?i)(?<!\\w)(?<!h\\/o\\s)(?:congestive\\sheart\\sfailure|chf|diastolic\\sHF|systolic\\sHF|heart\\sfailure|diastolic\\sdysfunction|LV\\sdysfunction|low\\scardiac\\soutput\\ssyndrome|low\\scardiac\\soutput\\ssyndrom|low\\scardiac\\souput\\ssyndrome|low\\sCO\\sstate)(?!\\swith\\spreserved\\sef)(?!\\swas\\sanother\\spossible\\sexplan)(?!\\w)'\n",
    "    cardiogenic_pattern = '(?i)(?<!\\w)(?<!no\\se\\/o\\sobstructive\\sor\\s)(?<!versus\\s)(?<!rule\\sout\\s)(?<!ruled\\sout\\s)(?<!less\\slikley\\s)(?<!w\\/o\\sevidence\\ssuggestive\\sof\\s\\s)(?<!non\\s)(?<!less\\slikely\\s)(?<!not\\slikely\\s)(?<!unlikely\\sto\\sbe\\s)(?<!no\\sclear\\sevidence\\sof\\sacute\\s)(?<!non-)(?<!than\\s)(?<!no\\sevidence\\sof\\s)(?:cardiogenic|cardigenic|cardiogemic|cardiac\\spulmonary\\sedema|cardiac\\sand\\sseptic\\sshock|Shock.{1,15}suspect.{1,15}RV\\sfailure)(?!\\s\\(not\\slikely\\sgiven\\sECHO\\sresults\\))(?!\\sshock\\sunlikely)(?!\\svs\\.\\sseptic)(?!\\scomponent\\salthough\\sSvO2\\snormal)(?!\\w)'\n",
    "    non_cardiogenic_pattern = '(?i)(?<!\\w)(?<!cardiogenic\\sor\\s)(?<!cardiogenic\\svs\\s)(?<!and\\/or\\s)(?:non(?:-|\\s)cardiogenic|noncardiogenic|non(?:-|\\s)cardigenic|noncardigenic)(?!\\svs\\scardiogenic)(?!\\w)'\n",
    "    palliative_pattern = '(?i)(?<!\\w)(?:palliative\\scare|comfort\\scare|withdraw\\scare|comfort\\salone|withdraw\\ssupport\\sin\\sfavor\\sof\\spalliation)(?!\\w)'\n",
    "    cardiac_arrest_pattern = '(?i)(?<!\\w)(?:arrest|cardiorespiratory arrest)(?!\\w)'\n",
    "    dementia_pattern = '(?i)(?<!\\w)dementia(?!\\w)'\n",
    "    stroke_pattern = '(?i)(?<!\\w)(?:stroke|strokes|cerebellar\\shemorrhage|intracerebral\\shemorrhage|BG\\shemorrhage|cva|cerebrovascular\\saccident|cefrebellar\\sinfarcts\\/basilar\\sstenosis)(?!\\w)'\n",
    "    alcohol_pattern = '(?i)(?<!\\w)(?:alcohol\\swithdrawal|dts|dt''s|dt|alcohol\\sdependence|alcohol\\sabuse|etoh\\sabuse|etoh\\swithdrawal|etoh\\swithdrawl|etoh\\sw\\/drawal|delirium\\stremens)(?!\\w)'\n",
    "    seizure_pattern = '(?i)(?<!\\w)(?<!no\\se\\/o\\ssubclinical\\s)(?:seizure|seizures)(?!\\w)'\n",
    "    ami_pattern = '(?i)(?<!\\w)(?:ami|acute\\smyocardial\\sischemia|acute\\smyocardial\\sinfarction|myocardial\\sinfarction|nstemi|non-st\\selevation\\smi|stemi|st\\selevation\\smi|acute\\smi)(?!\\w)'\n",
    "\n",
    "    # Adding the flag/boolean columns\n",
    "    attn_notes['pneumonia_matched'] = attn_notes.notes_text.str.contains(pneumonia_pattern)\n",
    "    attn_notes['aspiration_matched'] = attn_notes.notes_text.str.contains(aspiration_pattern)\n",
    "    attn_notes['inhalation_matched'] = attn_notes.notes_text.str.contains(inhalation_pattern)\n",
    "    attn_notes['pulmonary_contusion_matched'] = attn_notes.notes_text.str.contains(pulm_contusion_pattern)\n",
    "    attn_notes['vasculitis_matched'] = attn_notes.notes_text.str.contains(vasculitis_pattern)\n",
    "    attn_notes['drowning_matched'] = attn_notes.notes_text.str.contains(drowning_pattern)\n",
    "    \n",
    "    # Sepsis and shock are a little special\n",
    "    boolean_sepsis_list = []\n",
    "    for seg_sepsis in attn_notes['seg_sepsis']:\n",
    "        # If any of the exclusion phrases is found in the text snippet, make False. Otherwise, make True.\n",
    "        boolean_sepsis_list.append(not any([phrase in seg_sepsis for phrase in sepsis_exclusion]) and seg_sepsis != \"Invalid\")\n",
    "    attn_notes['sepsis_matched'] = boolean_sepsis_list\n",
    "    # attn_notes['sepsis_matched'] = attn_notes.notes_text.str.contains(sepsis_pattern)\n",
    "    \n",
    "    boolean_shock_list = []\n",
    "    for seg_shock in attn_notes['seg_shock']:\n",
    "        # If any of the exclusion phrases is found in the text snippet, make False. Otherwise, make True.\n",
    "        boolean_shock_list.append(not any([phrase in seg_shock for phrase in shock_exclusion]) and seg_shock != \"Invalid\")\n",
    "    attn_notes['shock_matched'] = boolean_shock_list\n",
    "    # attn_notes['shock_matched'] = attn_notes.notes_text.str.contains(shock_pattern)\n",
    "\n",
    "    attn_notes['overdose_matched'] = attn_notes.notes_text.str.contains(overdose_pattern)\n",
    "    attn_notes['trauma_matched'] = attn_notes.notes_text.str.contains(trauma_pattern)\n",
    "    attn_notes['pancreatitis_matched'] = attn_notes.notes_text.str.contains(pancreatitis_pattern)\n",
    "    attn_notes['burn_matched'] = attn_notes.notes_text.str.contains(burn_pattern)\n",
    "    attn_notes['trali_matched'] = attn_notes.notes_text.str.contains(trali_pattern)\n",
    "    attn_notes['ards_matched'] = attn_notes.notes_text.str.contains(ards_pattern)\n",
    "    attn_notes['pregnant_matched'] = attn_notes.notes_text.str.contains(pregnant_pattern)  \n",
    "    attn_notes['chf_matched'] = attn_notes.notes_text.str.contains(chf_pattern)\n",
    "    attn_notes['cardiogenic_matched'] = attn_notes.notes_text.str.contains(cardiogenic_pattern)\n",
    "    attn_notes['non_cardiogenic_matched'] = attn_notes.notes_text.str.contains(non_cardiogenic_pattern)\n",
    "    attn_notes['palliative_matched'] = attn_notes.notes_text.str.contains(palliative_pattern)\n",
    "    attn_notes['cardiac_arrest_matched'] = attn_notes.notes_text.str.contains(cardiac_arrest_pattern)\n",
    "    attn_notes['dementia_matched'] = attn_notes.notes_text.str.contains(dementia_pattern)\n",
    "    attn_notes['stroke_matched'] = attn_notes.notes_text.str.contains(stroke_pattern)\n",
    "    attn_notes['alcohol_matched'] = attn_notes.notes_text.str.contains(alcohol_pattern)\n",
    "    attn_notes['seizure_matched'] = attn_notes.notes_text.str.contains(seizure_pattern)\n",
    "    attn_notes['ami_matched'] = attn_notes.notes_text.str.contains(ami_pattern)\n",
    "\n",
    "    return attn_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10525601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set plotting params\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "plt.style.reload_library()\n",
    "rcparams = plots.stdrcparams1()\n",
    "mpl.rcParams.update(rcparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b3df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = Path(\"../..\")\n",
    "analysis_location = basedir / 'Analysis_data'\n",
    "cohort = 'hospital_a_2013'\n",
    "path = analysis_location / cohort\n",
    "mimic3_path = analysis_location / \"MIMIC_III\" / \"labeled_subset\"\n",
    "\n",
    "# Figures\n",
    "figure_path = basedir / \"Figures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff530c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load risk factor file with notes\n",
    "notes = pd.read_csv(path / \"attending_notes_annotated.csv\")\n",
    "notes['notes_timestamp'] = pd.to_timedelta(notes['notes_timestamp'])\n",
    "\n",
    "# Reading in MIMIC III\n",
    "mimic_iii = pd.read_csv(mimic3_path / \"attending_notes.csv\")\n",
    "mimic_iii['notes_timestamp'] = pd.to_datetime(mimic_iii['notes_timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183cba4c",
   "metadata": {},
   "source": [
    "### Alright, text-match the notes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa29c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = text_match_all_risk_factors(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e0e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to subset label columns into those text-matched by EDW and by me\n",
    "annotated_sw = [i for i in list(notes.columns) if \"sw\" in i]\n",
    "annotated_regex = [i for i in list(notes.columns) if \"matched\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9c26d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = list(notes[annotated_sw].sum())\n",
    "counts_regex = list(notes[annotated_regex].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04389963",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = []\n",
    "\n",
    "annotations_nice = ['Pneumonia', 'Aspiration', 'Inhalation', 'Pulmonary contusion',\n",
    "                    'Vasculitis', 'Drowning', 'Sepsis', 'Shock', 'Overdose', 'Trauma',\n",
    "                    'Pancreatitis', 'Burn', 'TRALI', 'ARDS', 'Pregnant', 'Congestive Heart Failure',\n",
    "                    'Cardiogenic', 'Noncardiogenic', 'Palliative', 'Cardiac arrest',\n",
    "                    'Dementia', 'Stroke', 'Alcohol', 'Seizure', 'Acute myocardial infarction']\n",
    "\n",
    "for i in range(len(annotated_sw)):\n",
    "    temp = {'risk_factor': annotations_nice[i], 'counts': counts[i], 'method': \"Labeled 'yes'\"}\n",
    "    agg.append(temp)\n",
    "    \n",
    "for i in range(len(annotated_regex)):\n",
    "    temp = {'risk_factor': annotations_nice[i], 'counts': counts_regex[i], 'method': 'Regex-matched'}\n",
    "    agg.append(temp)\n",
    "    \n",
    "for_plot = pd.DataFrame(agg).sort_values(by='counts', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8fcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.barplot(x='counts', y='risk_factor', hue='method',\n",
    "            hue_order=[\"Labeled 'yes'\", 'Regex-matched'],\n",
    "            data=for_plot, errorbar=None, ax=ax)\n",
    "\n",
    "ax.set_xlabel('Count of notes')\n",
    "ax.set_ylabel('')\n",
    "ax.grid(linestyle=':', axis='x')\n",
    "ax.legend(loc='lower right', title=None, frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figure_path / 'risk_factor_count.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c40bf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# of_interest = [\n",
    "#     'Pneumonia', 'Aspiration', 'Inhalation', 'Pulmonary contusion',\n",
    "#     'Sepsis', 'Shock', 'Trauma', 'Pancreatitis', 'Congestive Heart Failure',\n",
    "#     'Cardiogenic', 'Alcohol', 'Acute myocardial infarction'\n",
    "#     ]\n",
    "\n",
    "of_interest = [\n",
    "    'Sepsis', 'Shock'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebbc4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# of_interest_sw = [\n",
    "#     'pneumonia_sw', 'aspiration_sw', 'inhalation_sw', 'pulmonary_contusion_sw',\n",
    "#     'sepsis_sw', 'shock_sw', 'trauma_sw', 'pancreatitis_sw', 'chf_sw',\n",
    "#     'cardiogenic_sw', 'alcohol_sw', 'ami_sw'\n",
    "#     ]\n",
    "\n",
    "# of_interest_regex = [\n",
    "#     'pneumonia_matched', 'aspiration_matched', 'inhalation_matched', 'pulmonary_contusion_matched',\n",
    "#     'sepsis_matched', 'shock_matched', 'trauma_matched', 'pancreatitis_matched', 'chf_matched',\n",
    "#     'cardiogenic_matched', 'alcohol_matched', 'ami_matched'\n",
    "#     ]\n",
    "\n",
    "of_interest_sw = [\n",
    "    'sepsis_sw', 'shock_sw'\n",
    "    ]\n",
    "\n",
    "of_interest_regex = [\n",
    "    'sepsis_matched', 'shock_matched'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad93f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = np.asarray([['True negatives\\n', 'False positives\\n'],\n",
    "                      ['False negatives\\n', 'True positives\\n']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5334a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "\n",
    "# fig2, ax2 = plt.subplots(4, 3, figsize=plots.stdfigsize(68, n_rows=4, n_cols=3, layout=\"double\"))\n",
    "\n",
    "# for theirs, mine in zip(of_interest_sw, of_interest_regex):\n",
    "#     # fillna(0) is to compare regex against positively-annotated records by SW\n",
    "#     # Another option is to use notnull() to compare regex against whether or not SW annotated (make 0 if her column is NaN, 1 otherwise)\n",
    "    \n",
    "#     y_true = notes[theirs].fillna(0).astype(int)\n",
    "#     y_pred = notes[mine].astype(int)\n",
    "#     cf = confusion_matrix(y_true, y_pred).transpose()[::-1, ::-1]\n",
    "#     sns.heatmap(cf, fmt='d', annot=True, cmap='Blues', cbar=False, ax=ax2[i//3,i%3])\n",
    "    \n",
    "#     ax2[i//3,i%3].set_title(of_interest[i], fontweight='bold')\n",
    "    \n",
    "#     if i % 3 == 0:\n",
    "#         ax2[i//3,i%3].set_ylabel(\"Regex-captured\")\n",
    "#         ax2[i//3,i%3].set_yticklabels(['Yes', 'No'], rotation=0)\n",
    "#     else:\n",
    "#         ax2[i//3,i%3].set_yticklabels([])\n",
    "#         ax2[i//3,i%3].set_yticks([])\n",
    "        \n",
    "        \n",
    "#     if i // 3 == 3:\n",
    "#         ax2[i//3,i%3].set_xlabel(\"Labeled as 'yes'\")\n",
    "#         ax2[i//3,i%3].set_xticklabels(['Yes', 'No'])\n",
    "#     else:\n",
    "#         ax2[i//3,i%3].set_xticklabels([])\n",
    "#         ax2[i//3,i%3].set_xticks([])\n",
    "        \n",
    "#     i += 1\n",
    "\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig(figure_path/ 'SIfig5.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26fddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "fig2, ax2 = plt.subplots(1, 2, figsize=plots.stdfigsize(75, n_cols=2, layout=\"double\"))\n",
    "\n",
    "for theirs, mine in zip(of_interest_sw, of_interest_regex):\n",
    "    # fillna(0) is to compare regex against positively-annotated records by SW\n",
    "    # Another option is to use notnull() to compare regex against whether or not SW annotated (make 0 if her column is NaN, 1 otherwise)\n",
    "    \n",
    "    y_true = notes[theirs].fillna(0).astype(int)\n",
    "    y_pred = notes[mine].astype(int)\n",
    "    cf = confusion_matrix(y_true, y_pred).transpose()[::-1, ::-1]\n",
    "    sns.heatmap(cf, fmt='d', annot=True, cmap='Blues', cbar=False, ax=ax2[i%2])\n",
    "    \n",
    "    ax2[i%2].set_title(of_interest[i], fontweight='bold')\n",
    "    \n",
    "    if i % 2 == 0:\n",
    "        ax2[i%2].set_ylabel(\"Regex-captured\")\n",
    "        ax2[i%2].set_yticklabels(['Yes', 'No'], rotation=0)\n",
    "    else:\n",
    "        ax2[i%2].set_yticklabels([])\n",
    "        ax2[i%2].set_yticks([])\n",
    "        \n",
    "    ax2[i%2].set_xlabel(\"Labeled as 'yes'\")\n",
    "    ax2[i%2].set_xticklabels(['Yes', 'No'])\n",
    "        \n",
    "    i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figure_path/ 'SIfig6.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ce631e",
   "metadata": {},
   "source": [
    "### Repeating the process for MIMIC-III notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd7ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_iii = text_match_all_risk_factors(mimic_iii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3cd2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to subset label columns into those labeled by Curt and by me\n",
    "annotated_regex = [i for i in list(mimic_iii.columns) if \"matched\" in i]\n",
    "annotated_curt = [i for i in list(mimic_iii.columns) if \"curt\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a33049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take away regex annotations that are not in Curt's annotations\n",
    "to_remove = []\n",
    "for element in annotated_regex:\n",
    "    \n",
    "    cleaned_element = element.replace(\"_matched\", \"\")\n",
    "    \n",
    "    bool_array = []\n",
    "    \n",
    "    for curt_annotation in annotated_curt:            \n",
    "        bool_array.append(cleaned_element in curt_annotation)\n",
    "        \n",
    "    if not any(bool_array):\n",
    "        to_remove.append(element)\n",
    "        \n",
    "for element in to_remove:\n",
    "    annotated_regex.remove(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420db03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_regex.sort()\n",
    "annotated_regex.remove(\"ards_matched\")\n",
    "annotated_regex.remove(\"pneumonia_matched\")\n",
    "annotated_regex.remove(\"shock_matched\")\n",
    "annotated_regex.remove(\"trauma_matched\")\n",
    "annotated_regex.remove(\"cardiogenic_matched\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868e51f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_curt = [\n",
    "    'curt_aspiration_(1=yes)',\n",
    "    'curt_burns_(1=yes)',\n",
    "    'curt_pancreatitis_(1=yes)',\n",
    "    'curt_pulmonary_contusion_(1=yes)',\n",
    "    'curt_sepsis_(1=yes)',\n",
    "    'curt_vasculitis_(1=yes)'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a8902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with names of the risk factors formatted nicely\n",
    "annotations_nice = [i.replace(\"_matched\", \"\").replace(\"_\", \" \").capitalize() for i in annotated_regex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7b3d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "fig3, ax3 = plt.subplots(3, 2, figsize=plots.stdfigsize(44, n_rows=3, n_cols=2, layout=\"double\"))\n",
    "\n",
    "for theirs, mine in zip(annotated_curt, annotated_regex):\n",
    "        \n",
    "    y_true = mimic_iii[theirs].astype(int)\n",
    "    y_pred = mimic_iii[mine].astype(int)\n",
    "    \n",
    "    cf = confusion_matrix(y_true, y_pred)\n",
    "    cf_mod = cf.transpose()[::-1, ::-1]\n",
    "    \n",
    "    sns.heatmap(cf_mod, fmt='d', annot=True, cmap='Blues', cbar=False, ax=ax3[i//2,i%2])\n",
    "    \n",
    "    ax3[i//2,i%2].set_title(annotations_nice[i], fontweight='bold')\n",
    "    \n",
    "    if i % 2 == 0:\n",
    "        ax3[i//2,i%2].set_yticklabels(['Yes', 'No'], rotation=0)\n",
    "        ax3[i//2,i%2].set_ylabel(\"Regex-adjudicated\")\n",
    "    else:\n",
    "        ax3[i//2,i%2].set_yticklabels([None, None])\n",
    "        ax3[i//2,i%2].set_yticks([])\n",
    "        \n",
    "    if i // 2 == 2:\n",
    "        ax3[i//2,i%2].set_xticklabels(['Yes', 'No'])\n",
    "        ax3[i//2,i%2].set_xlabel(\"Ground truth\")\n",
    "    else:\n",
    "        ax3[i//2,i%2].set_xticklabels([None, None])\n",
    "        ax3[i//2,i%2].set_xticks([])\n",
    "        \n",
    "    i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figure_path / 'fig6.png')\n",
    "# plt.savefig(figure_path / 'fig6.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfe068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4, ax4 = plt.subplots(1, 1, figsize=plots.stdfigsize(0, layout=\"single\"))\n",
    "\n",
    "y_true = mimic_iii['curt_sepsis_(1=yes)'].astype(int)\n",
    "y_pred = mimic_iii['sepsis_matched'].astype(int)\n",
    "    \n",
    "cf = confusion_matrix(y_true, y_pred).transpose()[::-1, ::-1]\n",
    "\n",
    "strings = np.asarray([['True positives\\n', 'False positives\\n'],\n",
    "                      ['False negatives\\n', 'True negatives\\n']])\n",
    "\n",
    "labels = (np.asarray([\"{0} {1:.0f}\".format(string, value)\n",
    "                      for string, value in zip(strings.flatten(),\n",
    "                                               cf.flatten())])\n",
    "         ).reshape(2, 2)\n",
    "    \n",
    "sns.heatmap(cf, fmt='', annot=labels, cmap='Blues', cbar=False, ax=ax4)\n",
    "    \n",
    "ax4.set_title(\"Sepsis\", fontweight='bold')\n",
    "ax4.set_ylabel(\"Regex-adjudicated\")\n",
    "ax4.set_xlabel(\"Ground truth\")\n",
    "ax4.tick_params(axis='both', bottom=False, left=False,\n",
    "                labelbottom=False, labelleft=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figure_path / 'fig6_sepsis.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908a910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_iii.loc[~mimic_iii['curt_trauma_(1=yes)'].astype(bool) & mimic_iii['trauma_matched'], ['notes_text', 'curt_trauma_(1=yes)', 'trauma_matched']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1deee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mimic_iii.loc[743, 'notes_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
