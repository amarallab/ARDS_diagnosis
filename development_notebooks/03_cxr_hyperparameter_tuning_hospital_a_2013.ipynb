{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "756d52cc",
   "metadata": {},
   "source": [
    "This notebook will attempt to find optimal hyperparameters for classifiers on chest imaging reports from Hospital A (2013) data. This was inspired by the following post, which also contributed a list of hyperparameters that should be optimized for random forest: https://towardsdatascience.com/hyperparameters-optimization-526348bb8e2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4442aab3",
   "metadata": {},
   "source": [
    "Idea is that if one wants to compare models, one might want to compare them after they have been tuned. Otherwise comparisons are a bit uncalled for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044f610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from joblib import Parallel, delayed\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1062887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook-specific imports\n",
    "from custom_functions import tokenizer_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b064b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data locations\n",
    "basedir = Path(\"../..\")\n",
    "analysis_location = basedir / 'Analysis_Data'\n",
    "training_path = analysis_location / 'train_ML'\n",
    "train_data1a = training_path / 'hospital_a_2013_bi_data_processed_minus_history_plus_conclusion-03-2021.csv'\n",
    "train_data1b = training_path / 'hospital_a_2013_cxr_annotated.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b286d",
   "metadata": {},
   "source": [
    "### Hospital A (2013) data read in and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a807f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open hospital_a_2013 processed files - segmented_reports\n",
    "segmented = pd.read_csv(train_data1b)\n",
    "\n",
    "# Replace some remaining punctuation marks\n",
    "segmented[\"seg_cxr_text\"] = segmented[\"seg_cxr_text\"].str.replace(r\"'\", r\"\", regex=True)\n",
    "segmented[\"seg_cxr_text\"] = segmented[\"seg_cxr_text\"].str.replace(r\"\\[\", r\"\", regex=True)\n",
    "segmented[\"seg_cxr_text\"] = segmented[\"seg_cxr_text\"].str.replace(r\"\\]\", r\"\", regex=True)\n",
    "segmented[\"seg_cxr_text\"] = segmented[\"seg_cxr_text\"].str.replace(r\",\", r\"\", regex=True)\n",
    "\n",
    "encounters = segmented['encounter_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae422ebc",
   "metadata": {},
   "source": [
    "### Importing machine learning libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7422f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models/algorithms/classifiers\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression as logit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Performance metrics\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, log_loss\n",
    "\n",
    "# Cross-validation\n",
    "from sklearn.model_selection import KFold\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "from hyperopt.pyll.base import scope \n",
    "\n",
    "# Text vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecf410f",
   "metadata": {},
   "source": [
    "### Evaluating performance of models with default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e980a0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_train_auc = []\n",
    "DT_test_auc = []\n",
    "DT_train_brier = []\n",
    "DT_test_brier = []\n",
    "\n",
    "LR_train_auc = []\n",
    "LR_test_auc = []\n",
    "LR_train_brier = []\n",
    "LR_test_brier = []\n",
    "\n",
    "RF_train_auc = []\n",
    "RF_test_auc = []\n",
    "RF_train_brier = []\n",
    "RF_test_brier = []\n",
    "\n",
    "XG_train_auc = []\n",
    "XG_test_auc = []\n",
    "XG_train_brier = []\n",
    "XG_test_brier = []\n",
    "XG_test_ll = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c7281f7",
   "metadata": {},
   "source": [
    "### Use this loop if wanting to ensure the split is done at the encounter level (avoiding potential data leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5741096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default is to do 5-fold CV\n",
    "cv = KFold()\n",
    "\n",
    "for train_index, test_index in cv.split(encounters):\n",
    "    train_encounters = encounters[train_index]\n",
    "    test_encounters = encounters[test_index]\n",
    "    \n",
    "    train = segmented['encounter_id'].isin(train_encounters)\n",
    "    test = segmented['encounter_id'].isin(test_encounters)\n",
    "    \n",
    "    X_train, X_test = segmented.loc[train, \"seg_cxr_text\"].to_numpy(), segmented.loc[test, \"seg_cxr_text\"].to_numpy()\n",
    "    Y_train, Y_test = segmented.loc[train, \"cxr_score\"].to_numpy(), segmented.loc[test, \"cxr_score\"].to_numpy()\n",
    "    \n",
    "    \n",
    "    #vectorize\n",
    "    vect = CountVectorizer(\n",
    "        tokenizer=tokenizer_better,\n",
    "        ngram_range=(1,2),\n",
    "        max_features=200\n",
    "        )\n",
    "    vect.fit(X_train)\n",
    "    X_train_vect = vect.transform(X_train).toarray()\n",
    "    X_test_vect = vect.transform(X_test).toarray()\n",
    "    features = {value: key for key, value in vect.vocabulary_.items()}\n",
    "    \n",
    "    # Train models\n",
    "    DT_model = tree.DecisionTreeClassifier(random_state=0)\n",
    "    DT_model.fit(X_train_vect, Y_train)\n",
    "    \n",
    "    LR_model = logit(\n",
    "        random_state=0,\n",
    "        max_iter=10000   # Setting it up to this number to avoid error message about not converging\n",
    "        )\n",
    "    LR_model.fit(X_train_vect, Y_train)\n",
    "    \n",
    "    RF_model = RandomForestClassifier(random_state=0)\n",
    "    RF_model.fit(X_train_vect, Y_train)\n",
    "\n",
    "    XG_model = XGBClassifier(random_state=0)\n",
    "    XG_model.fit(\n",
    "        X_train_vect,\n",
    "        Y_train,\n",
    "        eval_set=[(X_test_vect, Y_test)],\n",
    "        verbose=False\n",
    "        )\n",
    "       \n",
    "    \n",
    "    # Predictions\n",
    "    DT_train_preds = DT_model.predict_proba(X_train_vect)[:,1]\n",
    "    DT_test_preds = DT_model.predict_proba(X_test_vect)[:,1]\n",
    "    \n",
    "    LR_train_preds = LR_model.predict_proba(X_train_vect)[:,1]\n",
    "    LR_test_preds = LR_model.predict_proba(X_test_vect)[:,1]\n",
    "    \n",
    "    RF_train_preds = RF_model.predict_proba(X_train_vect)[:,1]\n",
    "    RF_test_preds = RF_model.predict_proba(X_test_vect)[:,1]\n",
    "    \n",
    "    XG_train_preds = XG_model.predict_proba(X_train_vect)[:,1]\n",
    "    XG_test_preds = XG_model.predict_proba(X_test_vect)[:,1]\n",
    "    \n",
    "    \n",
    "    # Gathering AUCs and Brier scores\n",
    "    DT_train_auc.append(roc_auc_score(Y_train, DT_train_preds))\n",
    "    DT_test_auc.append(roc_auc_score(Y_test, DT_test_preds))\n",
    "    DT_train_brier.append(brier_score_loss(Y_train, DT_train_preds))\n",
    "    DT_test_brier.append(brier_score_loss(Y_test, DT_test_preds))\n",
    "    \n",
    "    LR_train_auc.append(roc_auc_score(Y_train, LR_train_preds))\n",
    "    LR_test_auc.append(roc_auc_score(Y_test, LR_test_preds))\n",
    "    LR_train_brier.append(brier_score_loss(Y_train, LR_train_preds))\n",
    "    LR_test_brier.append(brier_score_loss(Y_test, LR_test_preds))\n",
    "    \n",
    "    RF_train_auc.append(roc_auc_score(Y_train, RF_train_preds))\n",
    "    RF_test_auc.append(roc_auc_score(Y_test, RF_test_preds))\n",
    "    RF_train_brier.append(brier_score_loss(Y_train, RF_train_preds))\n",
    "    RF_test_brier.append(brier_score_loss(Y_test, RF_test_preds))\n",
    "    \n",
    "    XG_train_auc.append(roc_auc_score(Y_train, XG_train_preds))\n",
    "    XG_test_auc.append(roc_auc_score(Y_test, XG_test_preds))\n",
    "    XG_train_brier.append(brier_score_loss(Y_train, XG_train_preds))\n",
    "    XG_test_brier.append(brier_score_loss(Y_test, XG_test_preds))\n",
    "    XG_test_ll.append(log_loss(Y_test, XG_test_preds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a72753d",
   "metadata": {},
   "source": [
    "### Use this loop if assuming each CXR report is an independent sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e6925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Default is to do 5-fold CV\n",
    "# cv = KFold()\n",
    "\n",
    "# for train_index, test_index in cv.split(X):\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    \n",
    "#     #vectorize\n",
    "#     vect = CountVectorizer(tokenizer=tokenizer_better,\n",
    "#                            ngram_range=(1,2),\n",
    "#                            max_features=200)\n",
    "#     vect.fit(X_train)\n",
    "#     X_train_vect = vect.transform(X_train).toarray()\n",
    "#     X_test_vect = vect.transform(X_test).toarray()\n",
    "    \n",
    "#     # Train models\n",
    "#     DT_model = tree.DecisionTreeClassifier(random_state=0)\n",
    "#     DT_model.fit(X_train_vect, Y_train)\n",
    "    \n",
    "#     LR_model = logit(random_state=0,\n",
    "#                      max_iter=10000)  # Setting it up to this number to avoid error message about not converging\n",
    "#     LR_model.fit(X_train_vect, Y_train)\n",
    "    \n",
    "#     RF_model = RandomForestClassifier(random_state=0,\n",
    "#                                       n_jobs=-1)\n",
    "#     RF_model.fit(X_train_vect, Y_train)\n",
    "    \n",
    "#     XG_model = XGBClassifier(random_state=0,\n",
    "#                              eval_metric='logloss',\n",
    "#                              n_jobs=-1)\n",
    "#     XG_model.fit(X_train_vect, Y_train)\n",
    "    \n",
    "    \n",
    "#     # Predictions\n",
    "#     DT_train_preds = DT_model.predict_proba(X_train_vect)[:,1]\n",
    "#     DT_test_preds = DT_model.predict_proba(X_test_vect)[:,1]\n",
    "    \n",
    "#     LR_train_preds = LR_model.predict_proba(X_train_vect)[:,1]\n",
    "#     LR_test_preds = LR_model.predict_proba(X_test_vect)[:,1]\n",
    "    \n",
    "#     RF_train_preds = RF_model.predict_proba(X_train_vect)[:,1]\n",
    "#     RF_test_preds = RF_model.predict_proba(X_test_vect)[:,1]\n",
    "    \n",
    "#     XG_train_preds = XG_model.predict_proba(X_train_vect)[:,1]\n",
    "#     XG_test_preds = XG_model.predict_proba(X_test_vect)[:,1]\n",
    "    \n",
    "    \n",
    "#     # Gathering AUCs and Brier scores\n",
    "#     DT_train_auc.append(roc_auc_score(Y_train, DT_train_preds))\n",
    "#     DT_test_auc.append(roc_auc_score(Y_test, DT_test_preds))\n",
    "#     DT_train_brier.append(brier_score_loss(Y_train, DT_train_preds))\n",
    "#     DT_test_brier.append(brier_score_loss(Y_test, DT_test_preds))\n",
    "    \n",
    "#     LR_train_auc.append(roc_auc_score(Y_train, LR_train_preds))\n",
    "#     LR_test_auc.append(roc_auc_score(Y_test, LR_test_preds))\n",
    "#     LR_train_brier.append(brier_score_loss(Y_train, LR_train_preds))\n",
    "#     LR_test_brier.append(brier_score_loss(Y_test, LR_test_preds))\n",
    "    \n",
    "#     RF_train_auc.append(roc_auc_score(Y_train, RF_train_preds))\n",
    "#     RF_test_auc.append(roc_auc_score(Y_test, RF_test_preds))\n",
    "#     RF_train_brier.append(brier_score_loss(Y_train, RF_train_preds))\n",
    "#     RF_test_brier.append(brier_score_loss(Y_test, RF_test_preds))\n",
    "    \n",
    "#     XG_train_auc.append(roc_auc_score(Y_train, XG_train_preds))\n",
    "#     XG_test_auc.append(roc_auc_score(Y_test, XG_test_preds))\n",
    "#     XG_train_brier.append(brier_score_loss(Y_train, XG_train_preds))\n",
    "#     XG_test_brier.append(brier_score_loss(Y_test, XG_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b13a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(7, 7))\n",
    "ax[0,0].boxplot(\n",
    "    [DT_train_auc, LR_train_auc, RF_train_auc, XG_train_auc],\n",
    "    tick_labels=['DT', 'LR', 'RF', 'XG']\n",
    "    )\n",
    "ax[0,0].set(ylim=[0.5, 1.05])\n",
    "ax[0,0].set_ylabel(\"AUROC\")\n",
    "ax[0,0].tick_params(axis='x')\n",
    "ax[0,0].tick_params(axis='y')\n",
    "ax[0,0].set_title(\"Train AUC\")\n",
    "\n",
    "ax[0,1].boxplot(\n",
    "    [DT_test_auc, LR_test_auc, RF_test_auc, XG_test_auc],\n",
    "    tick_labels=['DT', 'LR', 'RF', 'XG']\n",
    "    )\n",
    "ax[0,1].set_title(\"Test AUC\")\n",
    "ax[0,1].tick_params(axis='x')\n",
    "ax[0,1].tick_params(axis='y')\n",
    "ax[0,1].set(ylim=[0.5, 1.05])\n",
    "\n",
    "ax[1,0].boxplot(\n",
    "    [DT_train_brier, LR_train_brier, RF_train_brier, XG_train_brier],\n",
    "    tick_labels=['DT', 'LR', 'RF', 'XG']\n",
    "    )\n",
    "ax[1,0].set_title(\"Train Brier\")\n",
    "ax[1,0].set_ylabel(\"Brier score\")\n",
    "ax[1,0].tick_params(axis='x')\n",
    "ax[1,0].tick_params(axis='y')\n",
    "ax[1,0].set(ylim=[0.00, 0.25])\n",
    "\n",
    "ax[1,1].boxplot(\n",
    "    [DT_test_brier, LR_test_brier, RF_test_brier, XG_test_brier],\n",
    "    tick_labels=['DT', 'LR', 'RF', 'XG']\n",
    "    )\n",
    "ax[1,1].set_title(\"Test Brier\")\n",
    "ax[1,1].tick_params(axis='x')\n",
    "ax[1,1].tick_params(axis='y')\n",
    "ax[1,1].set(ylim=[0.00, 0.25])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcc4b7b",
   "metadata": {},
   "source": [
    "### Now, hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552d29d8",
   "metadata": {},
   "source": [
    "Choosing to do Bayesian optimization as it is more efficient (i.e. shorter time to reach a solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fc958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cv_func(model, df, encounters, train_index, test_index, score='auc'):\n",
    "    train_encounters = encounters[train_index]\n",
    "    test_encounters = encounters[test_index]\n",
    "    \n",
    "    train = df['encounter_id'].isin(train_encounters)\n",
    "    test = df['encounter_id'].isin(test_encounters)\n",
    "    \n",
    "    X_train = df.loc[train, \"seg_cxr_text\"].to_numpy()\n",
    "    X_test = df.loc[test, \"seg_cxr_text\"].to_numpy()\n",
    "    Y_train = df.loc[train, \"cxr_score\"].to_numpy()\n",
    "    Y_test = df.loc[test, \"cxr_score\"].to_numpy()\n",
    "    \n",
    "    #vectorize\n",
    "    vect = CountVectorizer(\n",
    "        tokenizer=tokenizer_better,\n",
    "        ngram_range=(1, 2),\n",
    "        max_features=200\n",
    "        )\n",
    "    \n",
    "    vect.fit(X_train)\n",
    "    X_train_vect = vect.transform(X_train).toarray()\n",
    "    X_test_vect = vect.transform(X_test).toarray()\n",
    "    \n",
    "    model.fit(X_train_vect, Y_train)\n",
    "    \n",
    "    test_preds = model.predict_proba(X_test_vect)[:,1]\n",
    "    \n",
    "    if score == 'auc':\n",
    "        test_score = roc_auc_score(Y_test, test_preds)\n",
    "    elif score == 'brier':\n",
    "        test_score = brier_score_loss(Y_test, test_preds)\n",
    "    elif score == 'log_loss':\n",
    "        test_score = log_loss(Y_test, test_preds)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid scoring scheme, enter either 'auc' or 'brier'\")\n",
    "        \n",
    "    return test_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c835523d",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f98384",
   "metadata": {},
   "outputs": [],
   "source": [
    "XG_param_grid = {\n",
    "    'base_score': hp.uniform('base_score', 0.0, 1.0),\n",
    "    'n_estimators': scope.int(hp.quniform(\"n_estimators\", 10, 10000, 10)),\n",
    "    'max_depth': scope.int(hp.quniform(\"max_depth\", 10, 10000, 10)),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.0, 1.0),\n",
    "    'gamma': hp.uniform('gamma', 0.0, 10.0),\n",
    "    'min_child_weight': hp.uniform('min_child_weight', 0.0, 100.0),\n",
    "    'max_delta_step': hp.uniform(\"max_delta_step\", 0.0, 100.0),\n",
    "    'subsample': hp.uniform('subsample', 0.001, 1.0)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2df5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian Optimization\n",
    "def objective(XG_param_grid):\n",
    "    XG_model = XGBClassifier(\n",
    "        eval_metric='logloss',\n",
    "        objective='binary:logistic',\n",
    "        base_score=XG_param_grid['base_score'],\n",
    "        n_estimators=XG_param_grid['n_estimators'],\n",
    "        max_depth=XG_param_grid['max_depth'],\n",
    "        learning_rate=XG_param_grid['learning_rate'],\n",
    "        gamma=XG_param_grid['gamma'],\n",
    "        min_child_weight=XG_param_grid['min_child_weight'],\n",
    "        max_delta_step=XG_param_grid['max_delta_step'],\n",
    "        subsample=XG_param_grid['subsample'],\n",
    "        tree_method='hist',\n",
    "        random_state=0)\n",
    "    \n",
    "    cv = KFold()\n",
    "    logloss = Parallel(n_jobs=5)(delayed(custom_cv_func)(\n",
    "        XG_model,\n",
    "        segmented,\n",
    "        encounters,\n",
    "        train_index,\n",
    "        test_index,\n",
    "        score='log_loss'\n",
    "        ) for train_index, test_index in cv.split(encounters))\n",
    "    \n",
    "    mean_logloss = np.mean(logloss)\n",
    "    var_logloss = np.var(logloss, ddof=1)\n",
    "\n",
    "    return {'loss': mean_logloss, 'loss_variance': var_logloss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256f35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_trials = Trials()\n",
    "\n",
    "# max_evals = 20*(# of ordinal hyperparams) + 15*(# categorical choices) = 185\n",
    "# stopping criteria, if needed: no improvement within window = 0.25*max_eval\n",
    "if __name__ == \"__main__\":\n",
    "    best_XG = fmin(\n",
    "        fn=objective,\n",
    "        space=XG_param_grid,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=160,\n",
    "        trials=xg_trials,\n",
    "        early_stop_fn=no_progress_loss(40)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eb46e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Default AUROC for XG: {np.mean(XG_test_auc):.3f}\")\n",
    "print(f\"Default Brier for XG: {np.mean(XG_test_brier):.3f}\")\n",
    "print(f\"Default Log loss for XG: {np.mean(XG_test_ll):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf1e891",
   "metadata": {},
   "outputs": [],
   "source": [
    "XG_model_tuned = XGBClassifier(\n",
    "    eval_metric='logloss',\n",
    "    objective='binary:logistic',\n",
    "    base_score=best_XG['base_score'],\n",
    "    n_estimators=int(best_XG['n_estimators']),\n",
    "    max_depth=int(best_XG['max_depth']),\n",
    "    learning_rate=best_XG['learning_rate'],\n",
    "    gamma=best_XG['gamma'],\n",
    "    min_child_weight=best_XG['min_child_weight'],\n",
    "    max_delta_step=best_XG['max_delta_step'],\n",
    "    subsample=best_XG['subsample'],\n",
    "    tree_method='hist',\n",
    "    random_state=0\n",
    "    )\n",
    "\n",
    "cv = KFold()\n",
    "auc = Parallel(n_jobs=5)(delayed(custom_cv_func)(\n",
    "    XG_model_tuned,\n",
    "    segmented,\n",
    "    encounters,\n",
    "    train_index,\n",
    "    test_index\n",
    "    ) for train_index, test_index in cv.split(encounters))\n",
    "\n",
    "cv = KFold()\n",
    "brier = Parallel(n_jobs=5)(delayed(custom_cv_func)(\n",
    "    XG_model_tuned,\n",
    "    segmented,\n",
    "    encounters,\n",
    "    train_index,\n",
    "    test_index,\n",
    "    score='brier'\n",
    "    ) for train_index, test_index in cv.split(encounters))\n",
    "\n",
    "cv = KFold()\n",
    "Logloss = Parallel(n_jobs=5)(delayed(custom_cv_func)(\n",
    "    XG_model_tuned,\n",
    "    segmented,\n",
    "    encounters,\n",
    "    train_index,\n",
    "    test_index,\n",
    "    score='log_loss'\n",
    "    ) for train_index, test_index in cv.split(encounters))\n",
    "\n",
    "print(f\"Tuned AUROC for XG: {np.mean(auc):.3f}\")\n",
    "print(f\"Tuned Brier for XG: {np.mean(brier):.3f}\")\n",
    "print(f\"Tuned Log loss for XG: {np.mean(Logloss):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c2e58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_hyperparam = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'base_score': str(best_XG['base_score']),\n",
    "    'n_estimators': str(int(best_XG['n_estimators'])),\n",
    "    'max_depth': str(int(best_XG['max_depth'])),\n",
    "    'learning_rate': str(best_XG['learning_rate']),\n",
    "    'gamma': str(best_XG['gamma']),\n",
    "    'min_child_weight': str(best_XG['min_child_weight']),\n",
    "    'max_delta_step': str(best_XG['max_delta_step']),\n",
    "    'subsample': str(best_XG['subsample'])\n",
    "    }\n",
    "\n",
    "xg_hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0420d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hyperparameters/XG_hyperparams_hospital_a_2013.json\", 'w') as file_json:\n",
    "    json.dump(xg_hyperparam, file_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
