{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55e29559",
   "metadata": {},
   "source": [
    "This notebook will attempt to find optimal hyperparameters for classifiers on chest imaging reports from Hospital System A (2013), Hospital System A (2016), and Hospital System B (2017-2018), which is collectively known as the whole training dataset. This was inspired by the following post, which also contributed a list of hyperparameters that should be optimized for random forest: https://towardsdatascience.com/hyperparameters-optimization-526348bb8e2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72190a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from joblib import Parallel, delayed\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ad947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook-specific imports\n",
    "from custom_functions import tokenizer_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebea63f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data locations\n",
    "basedir = Path(\"../..\")\n",
    "training_dataset = basedir / \"Analysis_Data\" / \"train_ML\" / \"cxr_whole_training_dataset.csv\"\n",
    "training_data = pd.read_csv(\n",
    "    training_dataset,\n",
    "    dtype={\n",
    "        \"encounter_id\": str,\n",
    "        \"cxr_timestamp\": str,\n",
    "        \"cxr_score\": int,\n",
    "        \"cxr_findings\": str,\n",
    "        \"seg_cxr_text\": str\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Removing remaining punctuation marks\n",
    "training_data['seg_cxr_text'] = training_data['seg_cxr_text'].str.replace(r\"'\", r\"\", regex=True)\n",
    "training_data['seg_cxr_text'] = training_data['seg_cxr_text'].str.replace(r\"\\[\", r\"\", regex=True)\n",
    "training_data['seg_cxr_text'] = training_data['seg_cxr_text'].str.replace(r\"\\]\", r\"\", regex=True)\n",
    "training_data['seg_cxr_text'] = training_data['seg_cxr_text'].str.replace(r\",\", r\"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d15a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "encounters = training_data[\"encounter_id\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f237096",
   "metadata": {},
   "source": [
    "### Importing machine learning libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8cad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models/algorithms/classifiers\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Performance metrics\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, log_loss, accuracy_score\n",
    "\n",
    "# Cross-validation\n",
    "from sklearn.model_selection import KFold\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "from hyperopt.pyll.base import scope \n",
    "\n",
    "# Text vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d143b37",
   "metadata": {},
   "source": [
    "### Now, hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c12333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cv_func(model, df, encounters, train_index, test_index, score='auc'):\n",
    "    train_encounters = encounters[train_index]\n",
    "    test_encounters = encounters[test_index]\n",
    "    \n",
    "    train = df['encounter_id'].isin(train_encounters)\n",
    "    test = df['encounter_id'].isin(test_encounters)\n",
    "    \n",
    "    X_train = df.loc[train, \"seg_cxr_text\"].to_numpy()\n",
    "    X_test = df.loc[test, \"seg_cxr_text\"].to_numpy()\n",
    "    Y_train = df.loc[train, \"cxr_score\"].to_numpy()\n",
    "    Y_test = df.loc[test, \"cxr_score\"].to_numpy()\n",
    "    \n",
    "    #vectorize\n",
    "    vect = CountVectorizer(\n",
    "        tokenizer=tokenizer_better,\n",
    "        ngram_range=(1,2),\n",
    "        max_features=200\n",
    "        )\n",
    "    \n",
    "    vect.fit(X_train)\n",
    "    X_train_vect = vect.transform(X_train).toarray()\n",
    "    X_test_vect = vect.transform(X_test).toarray()\n",
    "    \n",
    "    model.fit(X_train_vect, Y_train)\n",
    "    \n",
    "    if score == 'auc':\n",
    "        test_preds = model.predict_proba(X_test_vect)[:,1]\n",
    "        test_score = roc_auc_score(Y_test, test_preds)\n",
    "    elif score == 'aucpr':\n",
    "        test_preds = model.predict_proba(X_test_vect)[:,1]\n",
    "        test_score = average_precision_score(Y_test, test_preds)\n",
    "    elif score == 'log_loss':\n",
    "        test_preds = model.predict_proba(X_test_vect)[:,1]\n",
    "        test_score = log_loss(Y_test, test_preds)\n",
    "    elif score == 'accuracy':\n",
    "        test_preds = model.predict(X_test_vect)\n",
    "        test_score = accuracy_score(Y_test, test_preds)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid scoring scheme, enter either 'auc' or 'brier'\")\n",
    "        \n",
    "    return test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1c2364",
   "metadata": {},
   "outputs": [],
   "source": [
    "XG_param_grid = {\n",
    "    'base_score': hp.uniform('base_score', 0.0, 1.0),\n",
    "    'n_estimators': scope.int(hp.quniform(\"n_estimators\", 10, 10000, 10)),\n",
    "    'max_depth': scope.int(hp.quniform(\"max_depth\", 10, 10000, 10)),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.0, 1.0),\n",
    "    'gamma': hp.uniform('gamma', 0.0, 10.0),\n",
    "    'min_child_weight': hp.uniform('min_child_weight', 0.0, 100.0),\n",
    "    'max_delta_step': hp.uniform(\"max_delta_step\", 0.0, 100.0),   # This is the hyperparameter that could help with label imbalance\n",
    "    'subsample': hp.uniform('subsample', 0.001, 1.0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dd4ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian Optimization\n",
    "def objective(XG_param_grid):\n",
    "    XG_model = XGBClassifier(\n",
    "        eval_metric='logloss',\n",
    "        objective='binary:logistic',\n",
    "        base_score=XG_param_grid['base_score'],\n",
    "        n_estimators=XG_param_grid['n_estimators'],\n",
    "        max_depth=XG_param_grid['max_depth'],\n",
    "        learning_rate=XG_param_grid['learning_rate'],\n",
    "        gamma=XG_param_grid['gamma'],\n",
    "        min_child_weight=XG_param_grid['min_child_weight'],\n",
    "        max_delta_step=XG_param_grid['max_delta_step'],\n",
    "        subsample=XG_param_grid['subsample'],\n",
    "        tree_method='hist',\n",
    "        random_state=0\n",
    "    )\n",
    "    \n",
    "    cv = KFold()\n",
    "    logloss = Parallel(n_jobs=5)(delayed(custom_cv_func)(\n",
    "        XG_model,\n",
    "        training_data,\n",
    "        encounters,\n",
    "        train_index,\n",
    "        test_index,\n",
    "        score='log_loss'\n",
    "        ) for train_index, test_index in cv.split(encounters))\n",
    "    \n",
    "    mean_logloss = np.mean(logloss)\n",
    "    var_logloss = np.var(logloss, ddof=1)\n",
    "\n",
    "    return {'loss': mean_logloss, 'loss_variance': var_logloss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6140355",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_trials = Trials()\n",
    "\n",
    "# max_evals = 20*(# of ordinal hyperparams) + 15*(# categorical choices) = 160\n",
    "# stopping criteria, if needed: no improvement within window = 0.25*max_eval\n",
    "if __name__ == \"__main__\":\n",
    "    best_XG = fmin(\n",
    "        fn=objective,\n",
    "        space=XG_param_grid,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=160,\n",
    "        trials=xg_trials,\n",
    "        early_stop_fn=no_progress_loss(40)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e7c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "XG_model_tuned = XGBClassifier(\n",
    "   eval_metric='logloss',\n",
    "   objective='binary:logistic',\n",
    "   base_score=best_XG['base_score'],\n",
    "   n_estimators=int(best_XG['n_estimators']),\n",
    "   max_depth=int(best_XG['max_depth']),\n",
    "   learning_rate=best_XG['learning_rate'],\n",
    "   gamma=best_XG['gamma'],\n",
    "   min_child_weight=best_XG['min_child_weight'],\n",
    "   max_delta_step=best_XG['max_delta_step'],\n",
    "   subsample=best_XG['subsample'],\n",
    "   tree_method='hist',\n",
    "   random_state=0\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2b40fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold()\n",
    "auc = Parallel(n_jobs=5)(delayed(custom_cv_func)(\n",
    "   XG_model_tuned,\n",
    "   training_data,\n",
    "   encounters,\n",
    "   train_index,\n",
    "   test_index,\n",
    "   score='auc') for train_index, test_index in cv.split(encounters))\n",
    "\n",
    "cv = KFold()\n",
    "brier = Parallel(n_jobs=5)(delayed(custom_cv_func)(\n",
    "   XG_model_tuned,\n",
    "   training_data,\n",
    "   encounters,\n",
    "   train_index,\n",
    "   test_index,\n",
    "   score='accuracy') for train_index, test_index in cv.split(encounters))\n",
    "\n",
    "cv = KFold()\n",
    "Logloss = Parallel(n_jobs=5)(delayed(custom_cv_func)(\n",
    "   XG_model_tuned,\n",
    "   training_data,\n",
    "   encounters,\n",
    "   train_index,\n",
    "   test_index,\n",
    "   score='log_loss') for train_index, test_index in cv.split(encounters))\n",
    "\n",
    "print(f\"Tuned AUROC for XG: {np.mean(auc):.3f}\")\n",
    "print(f\"Tuned accuracy for XG: {np.mean(brier):.3f}\")\n",
    "print(f\"Tuned Log loss for XG: {np.mean(Logloss):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899b85dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_hyperparam = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'base_score': str(best_XG['base_score']),\n",
    "    'n_estimators': str(int(best_XG['n_estimators'])),\n",
    "    'max_depth': str(int(best_XG['max_depth'])),\n",
    "    'learning_rate': str(best_XG['learning_rate']),\n",
    "    'gamma': str(best_XG['gamma']),\n",
    "    'min_child_weight': str(best_XG['min_child_weight']),\n",
    "    'max_delta_step': str(best_XG['max_delta_step']),\n",
    "    'subsample': str(best_XG['subsample'])\n",
    "    }\n",
    "\n",
    "xg_hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a67710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"hyperparameters/bilateral_infiltrates_model_hyperparams.json\", 'w') as file_json:\n",
    "#     json.dump(xg_hyperparam, file_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
