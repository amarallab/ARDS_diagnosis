{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook will contain development of code to pull relevant numbers and phrases from Echocardiography reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.spatial.distance import hamming\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src.diagnosis_tools import *\n",
    "import src.plots as plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom display of tables for easier inspection\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set plotting params\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "plt.style.reload_library()\n",
    "rcparams = plots.stdrcparams1()\n",
    "mpl.rcParams.update(rcparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data locations\n",
    "basedir = Path(\"../..\")\n",
    "analysis_location = basedir / 'Analysis_Data'\n",
    "training_location = analysis_location / 'train_ML'\n",
    "preprocess_location = basedir / \"Preprocessed_Data\"\n",
    "cohort = 'hospital_a_2013'\n",
    "path = analysis_location / cohort\n",
    "echo_validation = path / 'ECHO_validation'\n",
    "\n",
    "# Figures\n",
    "figure_path = basedir / \"Figures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo = pd.read_csv(path / \"echo_reports.csv\")\n",
    "echo['echo_timestamp'] = pd.to_timedelta(echo['echo_timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = np.asarray([['True negatives\\n', 'False positives\\n'],\n",
    "                      ['False negatives\\n', 'True positives\\n']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These will be dictionaries whose keys will become the column names for the flags\n",
    "# and the lists will be the regex patterns to search for\n",
    "\n",
    "# (?i) is to inactivate case-sensitivity\n",
    "# (?:) is to indicate that contents inside a parenthesis shouldn't be read as a \"capturing group\"\n",
    "# Default behavior of () is to consider it a capturing group\n",
    "echo_prefix = {'lvef': ['(?i)lv\\s+ejection\\s+fraction',\n",
    "                        '(?i)left\\s+ventricular\\s+ejection\\s+fraction',\n",
    "                        '(?i)lvef',\n",
    "                        '(?i)left\\s+ventricular\\s+ef',\n",
    "                        '(?i)lvef\\s+is',\n",
    "                        '(?i)left\\s+ventricle\\s+ejection\\s+fraction\\s+is',\n",
    "                        '(?i)lv\\s+ejection\\s+fraction\\s+is'],\n",
    "               \n",
    "               # Match \"cardiopulmonary bypass\" ensuring at least one whitespace character between those words\n",
    "              'cp_bypass': ['(?i)cardiopulmonary\\s+bypass'],\n",
    "              \n",
    "              'la_dimension': ['(?i)la\\s+diameter',\n",
    "                               '(?i)la\\s+dimension'],\n",
    "\n",
    "              'la_volume_index': ['(?i)la\\s+volume',\n",
    "                                  '(?i)LA\\s+Vol\\s+BP\\s+A/L\\s+Index'],\n",
    "              \n",
    "              'lv_hypertrophy': ['(?i)(?<!borderline )(?:left\\s+ventricular|lv|lv\\s+concentric)\\s*hypertrophy',\n",
    "                                 '(?i)(?<!borderline )LVH'],\n",
    "              \n",
    "              'diastolic_dysfunction': ['(?i)(grade\\s*ii)',\n",
    "                                        '(?i)(grade\\s*iii)']}\n",
    "\n",
    "echo_suffix = {'lvef': '\\D{0,20}(\\d{1,3}|\\d{1,2}\\s*-\\s*\\d{1,3})-{0,1}\\s*%', # Sample matches: 45%, 45 %, 45-55%, 45 - 55 %, 45- 100%, 45- %\n",
    "               'cp_bypass': '(?!\\s*N\\/A|\\s*Patient\\s+was\\s+not\\s+placed\\s+on\\s+cardiopulmonary\\s+bypass|\\s*NA)',  # Don't match if N/A or Patient wasn't placed on CPB\n",
    "               'la_dimension': '\\D{0,25}(\\d\\.\\s*\\d)\\s*(?:cm|centimeter)', # Sample matches: 2.7cm, 2.7 cm, 2.7   centimeter\n",
    "               \n",
    "                # Match anything until \"ml\" appears once or never, then match anything until the number of interest appears\n",
    "                # followed by either ml/m or ml per square meter\n",
    "               'la_volume_index': '.*?(?:ml)?.*?(\\d+\\.\\s*\\d+)\\s+(?:(?=ml\\/m)|(?=ml\\s+per\\s+square\\s+meter))',\n",
    "               'lv_hypertrophy': '',\n",
    "               # Matches anything, either never or up to 30 characters, then an arbitrary number of white spaces,\n",
    "               # as long as \"diastolic dysfunction\" immediately follows.\n",
    "               'diastolic_dysfunction': '.{0,30}\\s*?(?=diastolic\\s+dysfunction)'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo = flag_echos(echo, echo_prefix, echo_suffix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating performance by metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Left ventricular ejection fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_lvef = echo[['echo_text', 'ejection_fraction', 'lvef_flag', 'lvef_value']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating flags by comparing against the flags already there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = evaluate_lvef['ejection_fraction'].isna()\n",
    "evaluate_lvef.loc[f, 'ejection_fraction'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = evaluate_lvef['ejection_fraction']\n",
    "y_pred = evaluate_lvef['lvef_flag']\n",
    "cf_lvef = confusion_matrix(y_true, y_pred).transpose()[::-1, ::-1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=plots.stdfigsize(0, layout=\"single\"))\n",
    "sns.heatmap(cf_lvef, fmt='d', annot=True, cmap='Blues', cbar=False, ax=ax)\n",
    "ax.set_xticklabels(['Yes', 'No'])\n",
    "ax.set_yticklabels(['Yes', 'No'], rotation=0)\n",
    "ax.set_ylabel(\"Regex-matched\")\n",
    "ax.set_xlabel(\"Text-matched\")\n",
    "ax.set_title(\"Left ventricular ejection fraction\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figure_path / 'SIfig7_lvef_cf.png')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comparing captured values against a labeled subset of ECHOs. Specifically, I'll annotate 10% of ECHOs that had a value captured and a flag present, and 10% of ECHOs that had a flag but no value.  \n",
    "I'll use Hamming distance (measure better suited for this binary task, because: either regex captures the right value or it doesn't)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = evaluate_lvef['ejection_fraction'] == 1\n",
    "# b = evaluate_lvef['lvef_value'].isna()\n",
    "# no_value_lvef = evaluate_lvef.loc[a & b].sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Writing the ECHO texts to a txt file for ease of annotating\n",
    "# no_value_lvef = no_value_lvef.reset_index().drop(columns=['index'])\n",
    "\n",
    "# # Also, keeping the original file to not have to do double-work\n",
    "# no_value_lvef.to_csv(echo_validation / \"annot_echos_lvef_no_value.csv\", index=False)\n",
    "\n",
    "# for i in range(len(no_value_lvef)):\n",
    "#     with open(echo_validation / f\"annot_echos_lvef_no_value{i+1}.txt\", \"w\") as f:\n",
    "#         f.write(no_value_lvef.loc[i, 'echo_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = evaluate_lvef['ejection_fraction'] == 1\n",
    "# b = evaluate_lvef['lvef_value'].notnull()\n",
    "# with_value_lvef = evaluate_lvef.loc[a & b].sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with_value_lvef = with_value_lvef.reset_index().drop(columns=['index'])\n",
    "\n",
    "# with_value_lvef.to_csv(echo_validation / \"annot_echos_lvef_with_value.csv\", index=False)\n",
    "\n",
    "# for i in range(len(with_value_lvef)):\n",
    "#     with open(echo_validation / f\"annot_echos_lvef_with_value{i+1}.txt\", \"w\") as f:\n",
    "#         f.write(with_value_lvef.loc[i, 'echo_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_value_lvef = pd.read_csv(echo_validation / \"annot_echos_lvef_no_value.csv\")\n",
    "with_value_lvef = pd.read_csv(echo_validation / \"annot_echos_lvef_with_value.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_no_value_lvef = hamming(no_value_lvef['lvef_value'], no_value_lvef['annot_lvef_value'])\n",
    "dist_with_value_lvef = hamming(with_value_lvef['lvef_value'], with_value_lvef['annot_lvef_value'])\n",
    "\n",
    "print(dist_no_value_lvef, dist_with_value_lvef)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cardiopulmonary bypass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this one, only value performance can be assessed since there's no prior flag indicating cardiopulmonary bypass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_cpb = echo[['echo_text', 'cp_bypass_flag', 'cp_bypass_value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Writing the ECHO texts to a txt file for ease of annotating\n",
    "# evaluate_cpb = evaluate_cpb.reset_index().drop(columns=['index'])\n",
    "\n",
    "# # Also, keeping the original file to not have to do double-work\n",
    "# evaluate_cpb.to_csv(echo_validation / \"annot_echos_cpb.csv\", index=False)\n",
    "\n",
    "# for i in range(len(evaluate_cpb)):\n",
    "#     with open(echo_validation / f\"annot_echos_cpb{i+1}.txt\", \"w\") as f:\n",
    "#         f.write(evaluate_cpb.loc[i, 'echo_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_cpb = pd.read_csv(echo_validation / \"annot_echos_cpb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_evaluate_cpb = hamming(evaluate_cpb['cp_bypass_value'], evaluate_cpb['annot_cp_bypass_value'])\n",
    "\n",
    "print(dist_evaluate_cpb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Left atrial dimension/diameter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flagging performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_lad = echo[['echo_text', 'la_diameter', 'la_dimension_flag', 'la_dimension_value']]\n",
    "f = evaluate_lad['la_diameter'].isna()\n",
    "evaluate_lad.loc[f, 'la_diameter'] = 0\n",
    "evaluate_lad.loc[~f, 'la_diameter'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = evaluate_lad['la_diameter']\n",
    "y_pred = evaluate_lad['la_dimension_flag']\n",
    "cf_lad = confusion_matrix(y_true, y_pred).transpose()[::-1, ::-1]\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=plots.stdfigsize(0, layout=\"single\"))\n",
    "sns.heatmap(cf_lad, fmt='d', annot=True, cmap='Blues', cbar=False, ax=ax1)\n",
    "ax1.set_xticklabels(['Yes', 'No'])\n",
    "ax1.set_yticklabels(['Yes', 'No'], rotation=0)\n",
    "ax1.set_ylabel(\"Regex-matched\")\n",
    "ax1.set_xlabel(\"Text-matched\")\n",
    "ax1.set_title(\"Left atrial dimension/diameter\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figure_path / 'SIfig7_la_dim_cf.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, value performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = evaluate_lad['la_dimension_flag'] == 1\n",
    "# g = evaluate_lad['la_dimension_value'].isna()\n",
    "# no_value_lad = evaluate_lad.loc[f & g].sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Writing the ECHO texts to a txt file for ease of annotating\n",
    "# no_value_lad = no_value_lad.reset_index().drop(columns=['index'])\n",
    "\n",
    "# # Also, keeping the original file to not have to do double-work\n",
    "# no_value_lad.to_csv(echo_validation / \"annot_echos_lad_no_value.csv\", index=False)\n",
    "\n",
    "# for i in range(len(no_value_lad)):\n",
    "#     with open(echo_validation / f\"annot_echos_lad_no_value{i+1}.txt\", \"w\") as f:\n",
    "#         f.write(no_value_lad.loc[i, 'echo_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = evaluate_lad['la_dimension_flag'] == 1\n",
    "# b = evaluate_lad['la_dimension_value'].notnull()\n",
    "# with_value_lad = evaluate_lad.loc[a & b].sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with_value_lad = with_value_lad.reset_index().drop(columns=['index'])\n",
    "\n",
    "# with_value_lad.to_csv(echo_validation / \"annot_echos_lad_with_value.csv\", index=False)\n",
    "\n",
    "# for i in range(len(with_value_lad)):\n",
    "#     with open(echo_validation / f\"annot_echos_lad_with_value{i+1}.txt\", \"w\") as f:\n",
    "#         f.write(with_value_lad.loc[i, 'echo_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_value_lad = pd.read_csv(echo_validation / \"annot_echos_lad_no_value.csv\")\n",
    "with_value_lad = pd.read_csv(echo_validation / \"annot_echos_lad_with_value.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_no_value_lad = hamming(no_value_lad['la_dimension_value'], no_value_lad['annot_la_dimension_value'])\n",
    "dist_with_value_lad = hamming(with_value_lad['la_dimension_value'], with_value_lad['annot_la_dimension_value'])\n",
    "\n",
    "print(dist_no_value_lad, dist_with_value_lad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Left atrial volume index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_lav = echo[['echo_text', 'la_volume', 'la_volume_index_flag', 'la_volume_index_value']]\n",
    "f = evaluate_lav['la_volume'].isna()\n",
    "evaluate_lav.loc[f, 'la_volume'] = 0\n",
    "evaluate_lav.loc[~f, 'la_volume'] = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flagging performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = evaluate_lav['la_volume']\n",
    "y_pred = evaluate_lav['la_volume_index_flag']\n",
    "cf_lav = confusion_matrix(y_true, y_pred).transpose()[::-1, ::-1]\n",
    "\n",
    "fig2, ax2 = plt.subplots(figsize=plots.stdfigsize(0, layout=\"single\"))\n",
    "sns.heatmap(cf_lav, fmt='d', annot=True, cmap='Blues', cbar=False, ax=ax2)\n",
    "ax2.set_xticklabels(['Yes', 'No'])\n",
    "ax2.set_yticklabels(['Yes', 'No'], rotation=0)\n",
    "ax2.set_ylabel(\"Regex-matched\")\n",
    "ax2.set_xlabel(\"Text-matched\")\n",
    "ax2.set_title(\"Left atrial volume index\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figure_path / 'SIfig7_la_vol_cf.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = evaluate_lav['la_volume'] == 1\n",
    "# g = evaluate_lav['la_volume_index_value'].isna()\n",
    "# no_value_lav = evaluate_lav.loc[f & g].sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Writing the ECHO texts to a txt file for ease of annotating\n",
    "# no_value_lav = no_value_lav.reset_index().drop(columns=['index'])\n",
    "\n",
    "# # Also, keeping the original file to not have to do double-work\n",
    "# no_value_lav.to_csv(echo_validation / \"annot_echos_lav_no_value.csv\", index=False)\n",
    "\n",
    "# for i in range(len(no_value_lav)):\n",
    "#     with open(echo_validation / f\"annot_echos_lav_no_value{i+1}.txt\", \"w\") as f:\n",
    "#         f.write(no_value_lav.loc[i, 'echo_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = evaluate_lav['la_volume'] == 1\n",
    "# b = evaluate_lav['la_volume_index_value'].notnull()\n",
    "# with_value_lav = evaluate_lav.loc[a & b].sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with_value_lav = with_value_lav.reset_index().drop(columns=['index'])\n",
    "\n",
    "# with_value_lav.to_csv(echo_validation / \"annot_echos_lav_with_value.csv\", index=False)\n",
    "\n",
    "# for i in range(len(with_value_lav)):\n",
    "#     with open(echo_validation / f\"annot_echos_lav_with_value{i+1}.txt\", \"w\") as f:\n",
    "#         f.write(with_value_lav.loc[i, 'echo_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_value_lav = pd.read_csv(echo_validation / \"annot_echos_lav_no_value.csv\")\n",
    "with_value_lav = pd.read_csv(echo_validation / \"annot_echos_lav_with_value.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_no_value_lav = hamming(no_value_lav['la_volume_index_value'], no_value_lav['annot_la_volume_index_value'])\n",
    "dist_with_value_lav = hamming(with_value_lav['la_volume_index_value'], with_value_lav['annot_la_volume_index_value'])\n",
    "\n",
    "print(dist_no_value_lav, dist_with_value_lav)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Left ventricular hypertrophy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_lv_hyper = echo[['echo_text', 'lv_hypertrophy', 'lv_hypertrophy_flag', 'lv_hypertrophy_value']]\n",
    "f = evaluate_lv_hyper['lv_hypertrophy'].isna()\n",
    "evaluate_lv_hyper.loc[f, 'lv_hypertrophy'] = 0\n",
    "evaluate_lv_hyper.loc[~f, 'lv_hypertrophy'] = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flagging performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = evaluate_lv_hyper['lv_hypertrophy']\n",
    "y_pred = evaluate_lv_hyper['lv_hypertrophy_flag']\n",
    "cf_lv_hyper = confusion_matrix(y_true, y_pred).transpose()[::-1, ::-1]\n",
    "\n",
    "labels = (np.asarray([\"{0} {1:.0f}\".format(string, value)\n",
    "                      for string, value in zip(strings.flatten(),\n",
    "                                               cf_lv_hyper.flatten())])\n",
    "         ).reshape(2, 2)\n",
    "\n",
    "fig3, ax3 = plt.subplots(figsize=plots.stdfigsize(0, layout=\"single\"))\n",
    "sns.heatmap(cf_lv_hyper, fmt='d', annot=True, cmap='Blues', cbar=False, ax=ax3)\n",
    "ax3.set_xticklabels(['Yes', 'No'])\n",
    "ax3.set_yticklabels(['Yes', 'No'], rotation=0)\n",
    "ax3.set_ylabel(\"Regex-matched\")\n",
    "ax3.set_xlabel(\"Text-matched\")\n",
    "ax3.set_title(\"Left ventricular hypertrophy\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figure_path / 'SIfig7_lv_hyper_cf.png')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspection of the 13 supposedly \"false positives\" yields that every single ECHO text mentions \"mild concentric lv hypertrophy\" or \"moderate concentric lv hypertrophy\". So, no clue as to why those weren't text-matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = evaluate_lv_hyper['lv_hypertrophy'] == 0\n",
    "# o = evaluate_lv_hyper['lv_hypertrophy_flag'] == 1\n",
    "\n",
    "# evaluate_lv_hyper.loc[p&o]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Since the flag comparison is useless, will use the same approach as if no flag existed.\n",
    "# evaluate_lv_hyper_sample = evaluate_lv_hyper.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Writing the ECHO texts to a txt file for ease of annotating\n",
    "# evaluate_lv_hyper_sample = evaluate_lv_hyper_sample.reset_index().drop(columns=['index'])\n",
    "\n",
    "# # Also, keeping the original file to not have to do double-work\n",
    "# evaluate_lv_hyper_sample.to_csv(echo_validation / \"annot_echos_lv_hyper.csv\", index=False)\n",
    "\n",
    "# for i in range(len(evaluate_lv_hyper_sample)):\n",
    "#     with open(echo_validation / f\"annot_echos_lv_hyper{i+1}.txt\", \"w\") as f:\n",
    "#         f.write(evaluate_lv_hyper_sample.loc[i, 'echo_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_lv_hyper_sample = pd.read_csv(echo_validation / \"annot_echos_lv_hyper.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist_evaluate_lv_hyper = hamming(evaluate_lv_hyper_sample['lv_hypertrophy_value'],\n",
    "#                                  evaluate_lv_hyper_sample['annot_lv_hypertrophy_value'])\n",
    "\n",
    "# print(dist_evaluate_lv_hyper)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grade II or III diastolic dysfunction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While e_e could serve as a flag, issue is that I wrote this as capturing the value and the flag at once. So it can't be compared to e_e, as e_e is a number where the value stratifies the degrees of diastolic dysfunction, but this column is probably just a flag indicating whether the number is in the report or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_dd = echo[['echo_text','diastolic_dysfunction_value', 'diastolic_dysfunction_flag']].sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Writing the ECHO texts to a txt file for ease of annotating\n",
    "# evaluate_dd = evaluate_dd.reset_index().drop(columns=['index'])\n",
    "\n",
    "# # Also, keeping the original file to not have to do double-work\n",
    "# evaluate_dd.to_csv(echo_validation / \"annot_echos_dd.csv\", index=False)\n",
    "\n",
    "# for i in range(len(evaluate_dd)):\n",
    "#     with open(echo_validation / f\"annot_echos_dd{i+1}.txt\", \"w\") as f:\n",
    "#         f.write(evaluate_dd.loc[i, 'echo_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dd = pd.read_csv(echo_validation / \"annot_echos_dd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_evaluate_dd = 1 - hamming(evaluate_dd['diastolic_dysfunction_flag'], evaluate_dd['annot_diastolic_dysfunction_flag'])\n",
    "\n",
    "print(dist_evaluate_dd)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = [i for i in list(echo.columns)[3:] if \"value\" not in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to subset label columns into those text-matched by EDW and by me\n",
    "annotations = []\n",
    "annotations_regex = []\n",
    "\n",
    "for i in all_cols:\n",
    "    if \"flag\" in i:\n",
    "        annotations_regex.append(i)\n",
    "    else:\n",
    "        annotations.append(i)\n",
    "        \n",
    "annotations.remove('la_enlargement')\n",
    "annotations.remove('lvids')\n",
    "annotations.remove('lvidd')\n",
    "annotations.remove('bowing')\n",
    "annotations.remove('e_e')\n",
    "annotations.remove('lateral')\n",
    "annotations.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = list(echo[annotations].sum())\n",
    "counts_regex = list(echo[annotations_regex].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = []\n",
    "\n",
    "annotations_nice = ['LV ejection fraction', 'CP Bypass',\n",
    "                    'LA diameter', 'LA volume index',\n",
    "                    'LV hypertrophy', 'Diastolic dysfunction']\n",
    "\n",
    "annotations_short = ['LV ejection fraction', 'LA diameter',\n",
    "                     'LA volume index', 'LV hypertrophy']\n",
    "\n",
    "for i in range(len(annotations)):\n",
    "    temp = {'factor': annotations_short[i], 'counts': counts[i], 'method': 'Text-match'}\n",
    "    agg.append(temp)\n",
    "    \n",
    "for i in range(len(annotations_regex)):\n",
    "    temp = {'factor': annotations_nice[i], 'counts': counts_regex[i], 'method': 'Regex-match'}\n",
    "    agg.append(temp)\n",
    "    \n",
    "for_plot = pd.DataFrame(agg).sort_values(by='counts', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4, ax4 = plt.subplots(figsize=plots.stdfigsize(0, layout=\"single\"))\n",
    "sns.barplot(x='counts', y='factor', hue='method',\n",
    "            data=for_plot, errorbar=None, ax=ax4)\n",
    "\n",
    "ax4.set_xlabel('Count of matched ECHOs')\n",
    "ax4.set_ylabel('')\n",
    "# ax4.set_title(f\"Total ECHO reports: {len(echo)}\")\n",
    "ax4.grid(linestyle=':', axis='x')\n",
    "ax4.legend(loc='lower right', title=None, frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figure_path / 'SIfig7_echos.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig5, ax5 = plt.subplots(2, 2, figsize=plots.stdfigsize(49, n_rows=2, n_cols=2, layout=\"double\"))\n",
    "\n",
    "sns.heatmap(cf_lvef, fmt='d', annot=True, cmap='Blues', cbar=False, ax=ax5[0,0])\n",
    "ax5[0,0].set_xticklabels([None, None])\n",
    "ax5[0,0].set_xticks([])\n",
    "ax5[0,0].set_yticklabels(['Yes', 'No'], rotation=0)\n",
    "ax5[0,0].set_ylabel(\"Regex-matched\")\n",
    "ax5[0,0].set_xlabel(None)\n",
    "ax5[0,0].set_title(\"LV ejection fraction\", fontweight='bold')\n",
    "\n",
    "sns.heatmap(cf_lad, fmt='d', annot=True, cmap='Blues', cbar=False, ax=ax5[0,1])\n",
    "ax5[0,1].set_xticklabels([None, None])\n",
    "ax5[0,1].set_xticks([])\n",
    "ax5[0,1].set_yticklabels([None, None], rotation=0)\n",
    "ax5[0,1].set_yticks([])\n",
    "ax5[0,1].set_ylabel(None)\n",
    "ax5[0,1].set_xlabel(None)\n",
    "ax5[0,1].set_title(\"LA diameter\", fontweight='bold')\n",
    "\n",
    "sns.heatmap(cf_lav, fmt='d', annot=True, cmap='Blues', cbar=False, ax=ax5[1,0])\n",
    "ax5[1,0].set_xticklabels(['Yes', 'No'])\n",
    "ax5[1,0].set_yticklabels(['Yes', 'No'], rotation=0)\n",
    "ax5[1,0].set_ylabel(\"Regex-matched\")\n",
    "ax5[1,0].set_xlabel(\"Text-matched\")\n",
    "ax5[1,0].set_title(\"LA volume index\", fontweight='bold')\n",
    "\n",
    "sns.heatmap(cf_lv_hyper, fmt='d', annot=True, cmap='Blues', cbar=False, ax=ax5[1,1])\n",
    "ax5[1,1].set_xticklabels(['Yes', 'No'])\n",
    "ax5[1,1].set_yticklabels([None, None], rotation=0)\n",
    "ax5[1,1].set_yticks([])\n",
    "ax5[1,1].set_ylabel(None)\n",
    "ax5[1,1].set_xlabel(\"Text-matched\")\n",
    "ax5[1,1].set_title(\"LV hypertrophy\", fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "# fig5.savefig(figure_path / 'SIfig7.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
