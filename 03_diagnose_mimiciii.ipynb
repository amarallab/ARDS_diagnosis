{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2569717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    cohen_kappa_score\n",
    ")\n",
    "from tqdm import tqdm   # For keeping track of loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6deafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom imports\n",
    "from src.diagnosis_tools import (\n",
    "    mark_hypoxemic_episodes,\n",
    "    mark_abnormal_cxr,\n",
    "    mark_cxr_within_48h_of_post_vent_hypoxemia,\n",
    "    mark_note_within_7d,\n",
    "    mark_notes_with_ml,\n",
    "    text_match_risk_factors,\n",
    "    diagnose_or_exclude_encounters,\n",
    "    flag_echos\n",
    ")\n",
    "import src.plots as plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0387444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set plotting params\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "plt.style.reload_library()\n",
    "rcparams = plots.stdrcparams1()\n",
    "mpl.rcParams.update(rcparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a7801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom display of tables for easier inspection\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9500f0d",
   "metadata": {},
   "source": [
    "While criteria to identify ARDS includes more than these, from the perspective of files these will be the important files/criteria:  \n",
    "-PF ratios (ARDS if PF<=300 mmHg and PEEP>=5 cm H20 anytime during encounter)  \n",
    "-Chest X-ray reports (ARDS if bilateral pulmonary opacities identified within 48 h window of PF ratio <= 300).  \n",
    "-First and second criteria happening within 7 days of a known ARDS risk factor (-1 to 7 days of latest timestamp of above combo). Search attending physician notes for this.  \n",
    "-If no risk factor found, seek language ruling out cardiac failure in attending physician notes.  \n",
    "-If no cardiac failure language found, use objective criteria form echocardiography reports to rule out cardiac failure, otherwise, ARDS is adjudicated (window of entire hospitalization)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3753e8a",
   "metadata": {},
   "source": [
    "## Read in the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f04b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = Path(\"..\")\n",
    "training_location = basedir / 'Analysis_Data' / 'train_ML'\n",
    "path = basedir / 'Analysis_Data' / 'MIMIC_III' / 'labeled_subset'\n",
    "raw_path = basedir / 'Raw_Data' / 'MIMIC_III' / 'labeled_subset'\n",
    "characteristics_path = basedir / 'Raw_Data' / 'MIMIC_III' / 'mimic_characteristics'\n",
    "figure_path = basedir / 'Figures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5106dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = pd.read_csv(path / \"pf_ratio.csv\")\n",
    "pf['pf_ratio_timestamp'] = pd.to_datetime(pf['pf_ratio_timestamp'])\n",
    "pf['vent_start_timestamp'] = pd.to_datetime(pf['vent_start_timestamp'])\n",
    "\n",
    "try:\n",
    "    peep = pd.read_csv(path / \"peep.csv\")\n",
    "    peep['peep_timestamp'] = pd.to_datetime(peep['peep_timestamp'])\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    peep = None\n",
    "    print(\"This dataset doesn't seem to have peep separately specified.\")\n",
    "\n",
    "cxr = pd.read_csv(path / \"cxr.csv\")\n",
    "cxr['cxr_timestamp'] = pd.to_datetime(cxr['cxr_timestamp'])\n",
    "\n",
    "notes = pd.read_csv(path / \"attending_notes.csv\")\n",
    "notes['notes_timestamp'] = pd.to_datetime(notes['notes_timestamp'])\n",
    "\n",
    "echo = pd.read_csv(path / \"echo_reports.csv\")\n",
    "echo['echo_timestamp'] = pd.to_datetime(echo['echo_timestamp'])\n",
    "\n",
    "bnp = pd.read_csv(path / \"bnp.csv\")\n",
    "bnp['bnp_timestamp'] = pd.to_datetime(bnp['bnp_timestamp'])\n",
    "\n",
    "final_numbers = pd.read_excel(raw_path / \"ARDS_Criteria_Curt.xlsx\")\n",
    "final_numbers_eryn = pd.read_excel(raw_path / \"ARDS_Criteria_Eryn.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53173be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_encounters = pf['encounter_id'].drop_duplicates()\n",
    "\n",
    "if peep is not None:\n",
    "    peep_encounters = peep['encounter_id'].drop_duplicates()\n",
    "else:\n",
    "    peep_encounters = None\n",
    "    \n",
    "cxr_encounters = cxr['encounter_id'].drop_duplicates()\n",
    "notes_encounters = notes['encounter_id'].drop_duplicates()\n",
    "echo_encounters = echo['encounter_id'].drop_duplicates()\n",
    "bnp_encounters = bnp['encounter_id'].drop_duplicates()\n",
    "\n",
    "if peep is None:\n",
    "    total_encounters = pd.merge(pf_encounters, cxr_encounters, how='outer').drop_duplicates()\n",
    "    print(f\"Patient encounters with PF ratios or CXRs: {len(total_encounters)}\")\n",
    "else:\n",
    "    total_encounters = pd.merge(pf_encounters, peep_encounters, how='outer').drop_duplicates()\n",
    "    total_encounters = pd.merge(total_encounters, cxr_encounters, how='outer').drop_duplicates()\n",
    "    print(f\"Patient encounters with PF ratios, PEEP, or CXRs: {len(total_encounters)}\")\n",
    "    \n",
    "total_encounters = pd.merge(total_encounters, notes_encounters, how='outer').drop_duplicates()\n",
    "total_encounters = pd.merge(total_encounters, echo_encounters, how='outer').drop_duplicates()\n",
    "total_encounters = pd.merge(total_encounters, bnp_encounters, how='outer').drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a8c6e",
   "metadata": {},
   "source": [
    "#### This is to get the ARDS recognition rate in the MIMIC-III subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a9bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "ards_recognized = final_numbers[[\n",
    "    'HADM_ID',\n",
    "    'ARDS DOCUMENTED IN NOTE (1=yes)'\n",
    "    ]].drop_duplicates() \\\n",
    "        .groupby('HADM_ID')['ARDS DOCUMENTED IN NOTE (1=yes)'] \\\n",
    "        .sum().to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ards_by_Curt = final_numbers[[\n",
    "    'HADM_ID',\n",
    "    'FINAL ARDS CURT (1=YES)'\n",
    "    ]].drop_duplicates() \\\n",
    "        .groupby('HADM_ID')['FINAL ARDS CURT (1=YES)'] \\\n",
    "        .sum().to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c138ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognition_comparison = pd.merge(ards_recognized, ards_by_Curt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e7c079",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognition_comparison.loc[\n",
    "    recognition_comparison['FINAL ARDS CURT (1=YES)'] == 1,\n",
    "    'ARDS DOCUMENTED IN NOTE (1=yes)'\n",
    "    ].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedc293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = recognition_comparison['FINAL ARDS CURT (1=YES)'] == 1\n",
    "g.sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ef26448",
   "metadata": {},
   "source": [
    "## Now, diagnosis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e9cabc4",
   "metadata": {},
   "source": [
    "### PF ratio table: Flagging hypoxemic windows (will check for PEEP >= 5 cm H2O if PEEP available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54918ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf, hypox_df = mark_hypoxemic_episodes(pf, peep, 'encounter_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2551732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Encounters with hypoxemia: {hypox_df['encounter_id'].nunique()}\")\n",
    "print(f\"Uniquely-identified hypoxemic entries: {len(hypox_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de99263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "peep_yes = final_numbers['Meet PEEP>=5 Criteria? (1=yes)'] == 1\n",
    "hypoxemia_yes = final_numbers['Meet PF<300 Criteria? (1=yes)'] == 1\n",
    "\n",
    "hypox_df_label = final_numbers.loc[peep_yes & hypoxemia_yes].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6bf6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Encounters with hypoxemia by Curt: {hypox_df_label['HADM_ID'].nunique()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce20d331",
   "metadata": {},
   "source": [
    "### Chest X-ray: Flagging abnormal CXRs and whether they are within 48 h of a hypoxemic record"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "897419f6",
   "metadata": {},
   "source": [
    "#### Flagging those CXR that are \"abnormal\" (bilateral pulmonary opacities consistent with pulmonary edema)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04df9c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = training_location / 'cxr_whole_training_dataset.csv'\n",
    "\n",
    "cxr = mark_abnormal_cxr(\n",
    "    cxr,\n",
    "    train_data,\n",
    "    train_col=['segmented_report', 'score'],\n",
    "    test_label_col='curt_bl_infiltrates_(1=yes)',\n",
    "    thresholding=\"default\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95ee526c",
   "metadata": {},
   "source": [
    "#### Flagging CXRs that are within 48 h of a hypoxemic entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e339e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cxr, hypox_pred_abn_cxr_48h = mark_cxr_within_48h_of_post_vent_hypoxemia(\n",
    "    hypox_df,\n",
    "    cxr,\n",
    "    'encounter_id',\n",
    "    'cxr_timestamp'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e61146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Abnormal CXRs - label: {cxr['curt_bl_infiltrates_(1=yes)'].sum()}\")\n",
    "print(f\"Predicted Abnormal CXRs: {cxr['cxr_score_predicted'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a92997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\n",
    "#     f\"\"\"\n",
    "#     Encounters with abnormal CXRs by Curt: {cxr.loc[\n",
    "#         cxr['curt_bl_infiltrates_(1=yes)'].astype(bool),\n",
    "#         'encounter_id'].nunique()}\n",
    "#     \"\"\"\n",
    "#     )\n",
    "\n",
    "print(\n",
    "    f\"\"\"Encounters with predicted abnormal CXRs: {cxr.loc[\n",
    "        cxr['cxr_score_predicted'],\n",
    "        'encounter_id'\n",
    "        ].nunique()}\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd81b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"\"\"Encounters with hypoxemia and CXRs within 48h: {cxr.loc[\n",
    "        cxr['within_48h'],\n",
    "        'encounter_id'\n",
    "        ].nunique()}\"\"\"\n",
    "    )\n",
    "\n",
    "print(f\"Uniquely-identified entries: {len(cxr.loc[cxr['within_48h']])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d949ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"\"\"Encounters with hypoxemia and predicted abnormal CXRs within 48h: {hypox_pred_abn_cxr_48h[\n",
    "        'encounter_id'\n",
    "        ].nunique()}\"\"\"\n",
    "    )\n",
    "\n",
    "print(f\"Uniquely-identified entries: {len(hypox_pred_abn_cxr_48h)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d8566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth!\n",
    "f = hypox_df_label['BL-PF within 48h Criteria? (1=yes)'] == 1\n",
    "hypox_abn_cxr_48h = hypox_df_label.loc[f]\n",
    "\n",
    "print(\n",
    "    f\"\"\"Encounters with hypoxemia and abnormal CXRs within 48h by Curt: {hypox_abn_cxr_48h[\n",
    "        'HADM_ID'\n",
    "        ].nunique()}\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b97d574",
   "metadata": {},
   "source": [
    "#### DETOUR start  \n",
    "Disagreement graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb09cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "within_48 = cxr.loc[cxr['within_48h']]\n",
    "outside_48 = cxr.loc[~cxr['within_48h']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b676837",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1, l2 = 0.1, 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dc2651",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_disagree = []\n",
    "r = cxr['cxr_score_probability'] < l1\n",
    "s = cxr['cxr_score_probability'] >= l1\n",
    "t = cxr['cxr_score_probability'] < l2\n",
    "u = cxr['cxr_score_probability'] >= l2\n",
    "\n",
    "\n",
    "for z in tqdm(range(100)):\n",
    "    lows = cxr.loc[r].sample(n=r.sum(), replace=True, axis=0)\n",
    "    intermediates = cxr.loc[s&t].sample(n=(s&t).sum(), replace=True, axis=0)\n",
    "    highs = cxr.loc[u].sample(n=u.sum(), replace=True, axis=0)\n",
    "    boot_within_48 = pd.concat([lows, intermediates, highs], ignore_index=True)\n",
    "    \n",
    "    \n",
    "    a1 = boot_within_48['cxr_score_probability'] < l1\n",
    "    temp = boot_within_48[a1].dropna(subset=['eryn_bl_infiltrates_(1=yes)', 'curt_bl_infiltrates_(1=yes)', 'seg_cxr_text'])\n",
    "    disagreements_curt = 0\n",
    "    disagreements_eryn = 0\n",
    "    \n",
    "    for idx, row in temp.iterrows():\n",
    "        disagreements_curt += int(row[\"cxr_score_predicted\"] != row[\"curt_bl_infiltrates_(1=yes)\"])\n",
    "        disagreements_eryn += int(row[\"cxr_score_predicted\"] != row[\"eryn_bl_infiltrates_(1=yes)\"])\n",
    "    agg_disagree.append({'model_confidence': 'High\\nconfidence\\nNo', 'disagreement': disagreements_curt/len(temp), 'physician': 'Intensivist'})\n",
    "    agg_disagree.append({'model_confidence': 'High\\nconfidence\\nNo', 'disagreement': disagreements_eryn/len(temp), 'physician': 'Internist'})\n",
    "\n",
    "\n",
    "    a3 = boot_within_48['cxr_score_probability'] >= l1\n",
    "    a4 = boot_within_48['cxr_score_probability'] < l2\n",
    "    temp = boot_within_48[a3&a4].dropna(subset=['eryn_bl_infiltrates_(1=yes)', 'curt_bl_infiltrates_(1=yes)', 'seg_cxr_text'])\n",
    "    disagreements_curt = 0\n",
    "    disagreements_eryn = 0\n",
    "    \n",
    "    for idx, row in temp.iterrows():\n",
    "        disagreements_curt += int(row[\"cxr_score_predicted\"] != row[\"curt_bl_infiltrates_(1=yes)\"])\n",
    "        disagreements_eryn += int(row[\"cxr_score_predicted\"] != row[\"eryn_bl_infiltrates_(1=yes)\"])\n",
    "    agg_disagree.append({'model_confidence': \"Low confidence\", 'disagreement': disagreements_curt/len(temp),'physician': 'Intensivist'})\n",
    "    agg_disagree.append({'model_confidence': 'Low confidence', 'disagreement': disagreements_eryn/len(temp), 'physician': 'Internist'})\n",
    "\n",
    "\n",
    "    a7 = boot_within_48['cxr_score_probability'] >= l2\n",
    "    temp = boot_within_48[a7].dropna(subset=['eryn_bl_infiltrates_(1=yes)', 'curt_bl_infiltrates_(1=yes)', 'seg_cxr_text'])\n",
    "    disagreements_curt = 0\n",
    "    disagreements_eryn = 0\n",
    "    \n",
    "    for idx, row in temp.iterrows():\n",
    "        disagreements_curt += int(row[\"cxr_score_predicted\"] != row[\"curt_bl_infiltrates_(1=yes)\"])\n",
    "        disagreements_eryn += int(row[\"cxr_score_predicted\"] != row[\"eryn_bl_infiltrates_(1=yes)\"])\n",
    "    agg_disagree.append({'model_confidence': \"High\\nconfidence\\nYes\", 'disagreement': disagreements_curt/len(temp), 'physician': 'Intensivist'})\n",
    "    agg_disagree.append({'model_confidence': 'High\\nconfidence\\nYes', 'disagreement': disagreements_eryn/len(temp), 'physician': 'Internist'})\n",
    "    \n",
    "disagreement_df = pd.DataFrame(agg_disagree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7531365",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.sum(), (s&t).sum(), u.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2563f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(1, 1, figsize=plots.stdfigsize(62, n_rows=1, n_cols=1, layout=\"single\"))\n",
    "\n",
    "sns.pointplot(data=disagreement_df, x='model_confidence', y='disagreement', hue='physician',\n",
    "              dodge=0.4, errorbar=(\"ci\", 95), capsize=0.1, ax=ax1, color=\"0\", legend=False,\n",
    "              linestyle=\"none\")\n",
    "sns.swarmplot(data=disagreement_df, x='model_confidence', y='disagreement', hue='physician',\n",
    "              dodge=True, palette=[\"tab:blue\", \"tab:orange\"], ax=ax1, alpha=0.65, size=2.1)\n",
    "\n",
    "ax1.set_ylabel(\"Fraction disagreed\")\n",
    "ax1.grid(linestyle=':', axis='y')\n",
    "ax1.legend(loc='upper left', frameon=False)\n",
    "ax1.set_xlabel(\"\")\n",
    "ax1.set_ylim(0, 0.4)\n",
    "\n",
    "fig1.tight_layout()\n",
    "# plt.savefig(figure_path / 'SIfig8.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855ebfc8",
   "metadata": {},
   "source": [
    "#### DETOUR end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "097d0427",
   "metadata": {},
   "source": [
    "### Attending physician notes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a512ed13",
   "metadata": {},
   "source": [
    "#### Flag notes within -1 to 7 days of latest of hypoxemia or abnormal CXR report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448e799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = mark_note_within_7d(\n",
    "    notes,\n",
    "    hypox_df,\n",
    "    hypox_pred_abn_cxr_48h,\n",
    "    'encounter_id',\n",
    "    'cxr_timestamp'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e508ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"\"\"Encounters with notes within 7 days of hypox_abn_cxr: {notes.loc[\n",
    "        notes['within_7d'],\n",
    "        'encounter_id'\n",
    "        ].nunique()}\"\"\"\n",
    "        )\n",
    "\n",
    "print(f\"Uniquely-identified entries: {len(notes.loc[notes['within_7d']])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbc3ab46",
   "metadata": {},
   "source": [
    "#### Flag notes mentioning any risk factor. Separately, flag notes with cardiac failure language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebe9f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = mark_notes_with_ml(\n",
    "    notes,\n",
    "    training_location,\n",
    "    train_col=['seg_pneumonia', 'pneumonia_sw'],\n",
    "    test_label_col='curt_pneumonia_(1=yes)',\n",
    "    thresholding=\"default\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc5679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = text_match_risk_factors(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff16f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes, diagnosed, excluded, for_objective_assessment = diagnose_or_exclude_encounters(\n",
    "    notes,\n",
    "    hypox_pred_abn_cxr_48h,\n",
    "    'encounter_id'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c18eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"{notes.encounter_id.nunique()}, {diagnosed.encounter_id.nunique()}, {excluded.encounter_id.nunique()}, {for_objective_assessment.encounter_id.nunique()}\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d21a26c",
   "metadata": {},
   "source": [
    "### BNP and ECHO reports: Objective assessment of cardiac failure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39c51bb0",
   "metadata": {},
   "source": [
    "#### First, let's annotate the ECHO reports with the values/statements of interest:  \n",
    "- lvef < 40%  \n",
    "- cardiopulmonary bypass  \n",
    "- left atrial dimension > 4 cm or volume index > 28 mL/m2  \n",
    "- left ventricular hypertrophy  \n",
    "- Grade II or III diastolic dysfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8399e8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These will be dictionaries whose keys will become the column names for the flags\n",
    "# and the lists will be the regex patterns to search for\n",
    "\n",
    "# (?i) is to inactivate case-sensitivity\n",
    "# (?:) is to indicate that contents inside a parenthesis shouldn't be read as a \"capturing group\"\n",
    "# Default behavior of () is to consider it a capturing group\n",
    "echo_prefix = {'lvef': ['(?i)lv\\s+ejection\\s+fraction',\n",
    "                        '(?i)left\\s+ventricular\\s+ejection\\s+fraction',\n",
    "                        '(?i)lvef',\n",
    "                        '(?i)left\\s+ventricular\\s+ef',\n",
    "                        '(?i)lvef\\s+is',\n",
    "                        '(?i)left\\s+ventricle\\s+ejection\\s+fraction\\s+is',\n",
    "                        '(?i)lv\\s+ejection\\s+fraction\\s+is'],\n",
    "               \n",
    "               # Match \"cardiopulmonary bypass\" ensuring at least one whitespace character between those words\n",
    "              'cp_bypass': ['(?i)cardiopulmonary\\s+bypass'],\n",
    "              \n",
    "              'la_dimension': ['(?i)la\\s+diameter',\n",
    "                               '(?i)la\\s+dimension'],\n",
    "\n",
    "              'la_volume_index': ['(?i)la\\s+volume',\n",
    "                                  '(?i)LA\\s+Vol\\s+BP\\s+A/L\\s+Index'],\n",
    "              \n",
    "              'lv_hypertrophy': ['(?i)(?:left\\s+ventricular|lv|lv\\s+concentric)\\s*hypertrophy',\n",
    "                                 '(?i)LVH'],\n",
    "              \n",
    "              'diastolic_dysfunction': ['(?i)(grade\\s*ii)',\n",
    "                                        '(?i)(grade\\s*iii)']}\n",
    "\n",
    "echo_suffix = {'lvef': '\\D{0,20}(\\d{1,3}|\\d{1,2}\\s*-\\s*\\d{1,3})-{0,1}\\s*%', # Sample matches: 45%, 45 %, 45-55%, 45 - 55 %, 45- 100%, 45- %\n",
    "               'cp_bypass': '(?!\\s*N\\/A|\\s*Patient\\s+was\\s+not\\s+placed\\s+on\\s+cardiopulmonary\\s+bypass|\\s*NA)',  # Don't match if N/A or Patient wasn't placed on CPB\n",
    "               'la_dimension': '\\D{0,25}(\\d\\.\\s*\\d)\\s*(?:cm|centimeter)', # Sample matches: 2.7cm, 2.7 cm, 2.7   centimeter\n",
    "               \n",
    "                # Match anything until \"ml\" appears once or never, then match anything until the number of interest appears\n",
    "                # followed by either ml/m or ml per square meter\n",
    "               'la_volume_index': '.*?(?:ml)?.*?(\\d+\\.\\s*\\d+)\\s+(?:(?=ml\\/m)|(?=ml\\s+per\\s+square\\s+meter))',\n",
    "               'lv_hypertrophy': '',\n",
    "               # Matches anything, either never or up to 30 characters, then an arbitrary number of white spaces,\n",
    "               # as long as \"diastolic dysfunction\" immediately follows.\n",
    "               'diastolic_dysfunction': '.{0,30}\\s*?(?=diastolic\\s+dysfunction)'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7245cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "echo = flag_echos(echo, echo_prefix, echo_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4144079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encounters entering objective assessment\n",
    "print(\n",
    "    f\"\"\"There are {for_objective_assessment[\n",
    "        'encounter_id'\n",
    "        ].nunique()} unique encounters entering objective assessment\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3703148",
   "metadata": {},
   "source": [
    "#### 1. Taking away encounters that have BNP > 100 pg/mL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598fded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = bnp['bnp_value'] > 100\n",
    "encounters_with_bnp_greater_than_100 = list(bnp.loc[a, 'encounter_id'].unique())\n",
    "\n",
    "j = for_objective_assessment['encounter_id'].isin(encounters_with_bnp_greater_than_100)\n",
    "remaining_after_bnp = for_objective_assessment.loc[~j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23330b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encounters remaining after bnp exclusion\n",
    "print(\n",
    "    f\"{len(encounters_with_bnp_greater_than_100)} encounters had BNP > 100 pg/mL. {remaining_after_bnp['encounter_id'].nunique()} encounters remain.\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4c4e3d5",
   "metadata": {},
   "source": [
    "#### 2.Taking away encounters that have left ventricular ejection fraction < 40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da1af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = echo['lvef_value'] < 40\n",
    "encounters_with_lvef_smaller_than_40 = list(echo.loc[b, 'encounter_id'].unique())\n",
    "\n",
    "j = remaining_after_bnp['encounter_id'].isin(encounters_with_lvef_smaller_than_40)\n",
    "remaining_after_lvef = remaining_after_bnp.loc[~j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeb2023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encounters remaining after lvef exclusion\n",
    "print(\n",
    "    f\"{len(encounters_with_lvef_smaller_than_40)} encounters had LVEF < 40%. {remaining_after_lvef['encounter_id'].nunique()} encounters remain.\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29e729db",
   "metadata": {},
   "source": [
    "#### 3. Taking away encounters that had cardiopulmonary bypass in the report (as a proxy for having had cardiopulmonary bypass during the ECHO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c57445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpb = echo['cp_bypass_value'].notnull()\n",
    "encounters_with_cardiopulmonary_bypass = list(echo.loc[cpb, 'encounter_id'].unique())\n",
    "\n",
    "j = remaining_after_lvef['encounter_id'].isin(encounters_with_cardiopulmonary_bypass)\n",
    "remaining_after_cpb = remaining_after_lvef.loc[~j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735f66e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encounters remaining after cardiopulmonary bypass exclusion\n",
    "print(\n",
    "    f\"{len(encounters_with_cardiopulmonary_bypass)} encounters had cardiopulmonary bypass. {remaining_after_cpb['encounter_id'].nunique()} encounters remain.\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fce316c",
   "metadata": {},
   "source": [
    "#### 4. Taking away encounters that have two out of three additional criteria:  \n",
    "- Left atrial enlargement (either left atrial dimension > 4 cm or left atrial volume index > 28 mL/m^2)  \n",
    "- Left ventricular hypertrophy  \n",
    "- Grade III or Grade IV diastolic dysfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cfb3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring the presence of criteria as 0 or 1\n",
    "la_dim = echo['la_dimension_value'] > 4\n",
    "la_vol_idx = echo['la_volume_index_value'] > 28\n",
    "echo.loc[:, 'la_enlargement_bool'] = (la_dim | la_vol_idx).astype(int)\n",
    "echo.loc[:, 'lv_hypertrophy_bool'] = echo['lv_hypertrophy_value'].notnull().astype(int)\n",
    "echo.loc[:, 'diastolic_dysfunction_bool'] = echo['diastolic_dysfunction_value'].notnull().astype(int)\n",
    "\n",
    "echo['additional_criteria_count'] = echo['la_enlargement_bool'] + \\\n",
    "                                    echo['lv_hypertrophy_bool'] + \\\n",
    "                                    echo['diastolic_dysfunction_bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f9cbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_crit = echo['additional_criteria_count'] > 1\n",
    "encounters_with_additional_criteria = list(echo.loc[add_crit, 'encounter_id'].unique())\n",
    "\n",
    "j = remaining_after_cpb['encounter_id'].isin(encounters_with_additional_criteria)\n",
    "remaining_after_additional_criteria = remaining_after_cpb.loc[~j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc77230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encounters remaining after additional criteria exclusion\n",
    "print(\n",
    "      f\"{len(encounters_with_additional_criteria)} encounters had two out of three additional criteria. {remaining_after_additional_criteria['encounter_id'].nunique()} encounters remain.\"\n",
    "      )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eac40f49",
   "metadata": {},
   "source": [
    "# Diagnosed encounters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc040d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosed_encntrs = diagnosed['encounter_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6e4865",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"Encounters diagnosed:\\n\\nPF+CXR+Notes: {diagnosed_encntrs}\".format(\n",
    "    diagnosed_encntrs = diagnosed['encounter_id'].nunique())\n",
    "text2 = \"\\nNo risk factor nor objective evidence of cardiac failure: {encntrs_remaining}\".format(\n",
    "    encntrs_remaining = remaining_after_additional_criteria['encounter_id'].nunique())\n",
    "text3 = \"\\nTotal encounters diagnosed: {total}\".format(\n",
    "    total = diagnosed_encntrs+remaining_after_additional_criteria['encounter_id'].nunique())\n",
    "\n",
    "print(text1+text2+text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29c738e",
   "metadata": {},
   "source": [
    "### Massaging the encounters to get list of pipeline diagnosed vs. not diagnosed table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3686ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "encounters_diagnosed_by_pipeline = pd.merge(\n",
    "    diagnosed['encounter_id'].drop_duplicates(),\n",
    "    remaining_after_additional_criteria['encounter_id'].drop_duplicates(),\n",
    "    how='outer'\n",
    "    ).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472a79d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating table with all MIMIC encounters and a diagnosed flag for each\n",
    "encounter_summary = pd.merge(\n",
    "    total_encounters,\n",
    "    encounters_diagnosed_by_pipeline,\n",
    "    how='outer',\n",
    "    indicator=True\n",
    "    )\n",
    "\n",
    "encounter_summary = encounter_summary.replace(\n",
    "    to_replace={\n",
    "        '_merge': {\n",
    "            \"left_only\": 'No',\n",
    "            \"both\": 'Yes'\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "encounter_summary = encounter_summary.rename(\n",
    "    columns={\n",
    "        '_merge': \"pipeline_diagnosed\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e27dc2d",
   "metadata": {},
   "source": [
    "### Now, massaging the labels table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1797885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is Curt's table: Changing column names to match the other tables\n",
    "final_numbers.rename(\n",
    "    columns={\n",
    "        'HADM_ID': 'encounter_id',\n",
    "        'FINAL ARDS CURT (1=YES)': 'curt_diagnosed'\n",
    "        },\n",
    "    inplace=True\n",
    "    )\n",
    "\n",
    "final_numbers_eryn.rename(\n",
    "    columns={\n",
    "        'HADM_ID ERYN': 'encounter_id',\n",
    "        'FINAL ARDS ERYN (1=YES)': 'eryn_diagnosed'\n",
    "        },\n",
    "    inplace=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23985282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The final_numbers table contains a bunch of other stuff.\n",
    "# This subsets the table for the two columns we care about in this analysis\n",
    "# And then takes care of instances where an encounter might have two different diagnoses:\n",
    "# If it was ever ARDS, consider it ARDS.\n",
    "encounters_by_Curt = final_numbers[[\n",
    "    'encounter_id',\n",
    "    'curt_diagnosed']] \\\n",
    "        .drop_duplicates() \\\n",
    "        .groupby('encounter_id')['curt_diagnosed'] \\\n",
    "        .sum().to_frame().reset_index()   \n",
    "        \n",
    "encounters_by_Eryn = final_numbers_eryn[[\n",
    "    'encounter_id',\n",
    "    'eryn_diagnosed']] \\\n",
    "        .drop_duplicates() \\\n",
    "        .groupby('encounter_id')['eryn_diagnosed'] \\\n",
    "        .sum().to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b31f121",
   "metadata": {},
   "source": [
    "### Merging adjudications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b878c8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding encounters diagnosed by Curt\n",
    "pipeline_v_curt = pd.merge(encounter_summary, encounters_by_Curt, how='outer')\n",
    "\n",
    "pipeline_v_curt = pipeline_v_curt.replace(\n",
    "    to_replace={\n",
    "        'curt_diagnosed': {0: \"No\", 1: \"Yes\"}\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea7afb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding encounters diagnosed by Eryn\n",
    "eryn_v_curt = pd.merge(encounters_by_Curt, encounters_by_Eryn, how='outer')\n",
    "\n",
    "eryn_v_curt = eryn_v_curt.replace(\n",
    "    to_replace={\n",
    "        'curt_diagnosed': {0: \"No\", 1: \"Yes\"},\n",
    "        'eryn_diagnosed': {0: \"No\", 1: \"Yes\"}\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4f5041",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d970a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = pipeline_v_curt['curt_diagnosed']\n",
    "y_pred = pipeline_v_curt['pipeline_diagnosed']\n",
    "cf = confusion_matrix(y_true, y_pred).transpose()[::-1, ::-1]\n",
    "\n",
    "strings = np.asarray([['True positives\\n', 'False positives\\n'],\n",
    "                      ['False negatives\\n', 'True negatives\\n']])\n",
    "\n",
    "labels = (np.asarray([\"{0} {1:.0f}\".format(string, value)\n",
    "                      for string, value in zip(strings.flatten(),\n",
    "                                               cf.flatten())])\n",
    "          ).reshape(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45be996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true1 = eryn_v_curt['curt_diagnosed']\n",
    "y_pred1 = eryn_v_curt['eryn_diagnosed']\n",
    "cf1 = confusion_matrix(y_true1, y_pred1).transpose()[::-1, ::-1]\n",
    "\n",
    "labels1 = (np.asarray([\"{0} {1:.0f}\".format(string, value)\n",
    "                      for string, value in zip(strings.flatten(),\n",
    "                                               cf1.flatten())])\n",
    "           ).reshape(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b54d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=plots.stdfigsize(0, n_rows=2, layout='single'))\n",
    "\n",
    "sns.heatmap(cf, fmt='', annot=labels, cmap='Blues', cbar=False, ax=ax[0])\n",
    "ax[0].set_ylabel(\"Pipeline adjudicated\")\n",
    "ax[0].set_xlabel(\"Ground truth\")\n",
    "ax[0].tick_params(axis='both', bottom=False, left=False,\n",
    "                  labelbottom=False, labelleft=False)\n",
    "ax[0].text(-0.06, 1.05, \"b\", transform=ax[0].transAxes,\n",
    "           fontweight='bold', va='top')\n",
    "\n",
    "sns.heatmap(cf1, fmt='', annot=labels1, cmap='Blues', cbar=False, ax=ax[1])\n",
    "ax[1].set_ylabel(\"Less-experienced physician adjudicated\")\n",
    "ax[1].set_xlabel(\"Ground truth\")\n",
    "ax[1].tick_params(axis='both', bottom=False, left=False,\n",
    "                  labelbottom=False, labelleft=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figure_path / 'fig8b_diagnosis_mimic_default.png')\n",
    "# plt.savefig(figure_path / 'fig8b_diagnosis_mimic_default.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28d4a7c",
   "metadata": {},
   "source": [
    "## Clinical characteristics of ARDS patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f726f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_los_mortality = pd.read_csv(characteristics_path / 'age_los_mortality.csv')[\n",
    "    ['HADM_ID', 'age', 'LOS', 'HOSPITAL_EXPIRE_FLAG']\n",
    "    ].drop_duplicates()\n",
    "\n",
    "gender = pd.read_csv(characteristics_path / 'gender.csv')[\n",
    "    ['HADM_ID', 'GENDER']\n",
    "    ].drop_duplicates()\n",
    "\n",
    "height = pd.read_csv(characteristics_path / 'height.csv')[\n",
    "    ['HADM_ID', 'CHARTTIME', 'height', 'unit']\n",
    "    ].drop_duplicates()\n",
    "\n",
    "plateau_pressure = pd.read_csv(characteristics_path / 'plateau_pressure.csv')[\n",
    "    ['HADM_ID', 'CHARTTIME', 'plateau_pressure', 'unit']\n",
    "    ].drop_duplicates()\n",
    "\n",
    "tidal_volume = pd.read_csv(characteristics_path / 'tidal_volume.csv')[\n",
    "    ['HADM_ID', 'CHARTTIME', 'tidal_volume', 'unit', 'LABEL']\n",
    "    ].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7ed858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting by encounters that actually went through the pipeline\n",
    "age_los_mortality = age_los_mortality.loc[age_los_mortality['HADM_ID'].isin(pipeline_v_curt['encounter_id'])]\n",
    "gender = gender.loc[gender['HADM_ID'].isin(pipeline_v_curt['encounter_id'])]\n",
    "height = height.loc[height['HADM_ID'].isin(pipeline_v_curt['encounter_id'])]\n",
    "plateau_pressure = plateau_pressure.loc[plateau_pressure['HADM_ID'].isin(pipeline_v_curt['encounter_id'])]\n",
    "tidal_volume = tidal_volume.loc[tidal_volume['HADM_ID'].isin(pipeline_v_curt['encounter_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07b38f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flagging which encounters were diagnosed with ARDS by whom\n",
    "pipeline_diagnosed = age_los_mortality['HADM_ID'].isin(pipeline_v_curt.loc[pipeline_v_curt['pipeline_diagnosed'] == 'Yes', 'encounter_id'])\n",
    "age_los_mortality['pipeline_diagnosed'] = pipeline_diagnosed\n",
    "\n",
    "curt_diagnosed = age_los_mortality['HADM_ID'].isin(pipeline_v_curt.loc[pipeline_v_curt['curt_diagnosed'] == 'Yes', 'encounter_id'])\n",
    "age_los_mortality['curt_diagnosed'] = curt_diagnosed\n",
    "\n",
    "\n",
    "pipeline_diagnosed = tidal_volume['HADM_ID'].isin(pipeline_v_curt.loc[pipeline_v_curt['pipeline_diagnosed'] == 'Yes', 'encounter_id'])\n",
    "tidal_volume['pipeline_diagnosed'] = pipeline_diagnosed\n",
    "\n",
    "curt_diagnosed = tidal_volume['HADM_ID'].isin(pipeline_v_curt.loc[pipeline_v_curt['curt_diagnosed'] == 'Yes', 'encounter_id'])\n",
    "tidal_volume['curt_diagnosed'] = curt_diagnosed\n",
    "\n",
    "\n",
    "pipeline_diagnosed = plateau_pressure['HADM_ID'].isin(pipeline_v_curt.loc[pipeline_v_curt['pipeline_diagnosed'] == 'Yes', 'encounter_id'])\n",
    "plateau_pressure['pipeline_diagnosed'] = pipeline_diagnosed\n",
    "\n",
    "curt_diagnosed = plateau_pressure['HADM_ID'].isin(pipeline_v_curt.loc[pipeline_v_curt['curt_diagnosed'] == 'Yes', 'encounter_id'])\n",
    "plateau_pressure['curt_diagnosed'] = curt_diagnosed\n",
    "\n",
    "\n",
    "pipeline_diagnosed = pf['encounter_id'].isin(pipeline_v_curt.loc[pipeline_v_curt['pipeline_diagnosed'] == 'Yes', 'encounter_id'])\n",
    "curt_diagnosed = pf['encounter_id'].isin(pipeline_v_curt.loc[pipeline_v_curt['curt_diagnosed'] == 'Yes', 'encounter_id'])\n",
    "pf['curt_diagnosed'] = curt_diagnosed\n",
    "pf['pipeline_diagnosed'] = pipeline_diagnosed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582bfab7",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de873cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes patients have a birthday while in the hospital\n",
    "# So they were one age on their first ICU stay, and another in subsequent stays\n",
    "# Taking the age at the first ICU stay\n",
    "for_age = age_los_mortality[\n",
    "    ['HADM_ID', 'age', 'pipeline_diagnosed', 'curt_diagnosed']\n",
    "    ].drop_duplicates().sort_values(by=['HADM_ID', 'age']).drop_duplicates(subset='HADM_ID', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d703b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_age.loc[for_age['pipeline_diagnosed'], 'age'].describe(), for_age.loc[for_age['curt_diagnosed'], 'age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ec1780",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_age.loc[~for_age['pipeline_diagnosed'], 'age'].describe(), for_age.loc[~for_age['curt_diagnosed'], 'age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54c79ec",
   "metadata": {},
   "source": [
    "### Length of stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfab1c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_los = age_los_mortality[\n",
    "    ['HADM_ID', 'LOS', 'pipeline_diagnosed', 'curt_diagnosed']\n",
    "    ].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a330d1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_los.loc[for_los['pipeline_diagnosed'], 'LOS'].describe(), for_los.loc[for_los['curt_diagnosed'], 'LOS'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae2d196",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_los.loc[~for_los['pipeline_diagnosed'], 'LOS'].describe(), for_los.loc[~for_los['curt_diagnosed'], 'LOS'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf4af3f",
   "metadata": {},
   "source": [
    "### Mortality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d03da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_mortality = age_los_mortality[\n",
    "    ['HADM_ID', 'HOSPITAL_EXPIRE_FLAG', 'pipeline_diagnosed', 'curt_diagnosed']\n",
    "    ].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2e4a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerator\n",
    "for_mortality.loc[\n",
    "    ~for_mortality['pipeline_diagnosed'],\n",
    "    ['HADM_ID', 'HOSPITAL_EXPIRE_FLAG']].drop_duplicates()['HOSPITAL_EXPIRE_FLAG'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba74f325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denominator\n",
    "for_mortality.loc[\n",
    "    ~for_mortality['pipeline_diagnosed'],\n",
    "    ['HADM_ID', 'HOSPITAL_EXPIRE_FLAG']].drop_duplicates().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8649cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerator\n",
    "for_mortality.loc[\n",
    "    ~for_mortality['curt_diagnosed'],\n",
    "    ['HADM_ID', 'HOSPITAL_EXPIRE_FLAG']].drop_duplicates()['HOSPITAL_EXPIRE_FLAG'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8806474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denominator\n",
    "for_mortality.loc[\n",
    "    ~for_mortality['curt_diagnosed'],\n",
    "    ['HADM_ID', 'HOSPITAL_EXPIRE_FLAG']].drop_duplicates().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7c041e",
   "metadata": {},
   "source": [
    "### Low Tidal Volume Ventilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cab1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tidal_volume = tidal_volume.loc[tidal_volume['LABEL'] == \"Tidal Volume (set)\"].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f79b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "tidal_volume = pd.merge(tidal_volume, gender, on=\"HADM_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86509be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all entries in height column from cm to inches\n",
    "height.loc[height['unit'] == 'cm', \"height\"] = height.loc[height['unit'] == 'cm', 'height'] / 2.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cce7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "height = height.groupby([\"HADM_ID\", \"CHARTTIME\"])['height'].min().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfada753",
   "metadata": {},
   "outputs": [],
   "source": [
    "tidal_volume = pd.merge(\n",
    "    tidal_volume.drop(columns=['CHARTTIME', 'unit', 'LABEL']).drop_duplicates(),\n",
    "    height[['HADM_ID', 'height']].drop_duplicates(),\n",
    "    on='HADM_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b438fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "male = tidal_volume['GENDER'] == 'M'\n",
    "female = tidal_volume['GENDER'] == 'F'\n",
    "\n",
    "tidal_volume.loc[male, 'standardized_tidal_volume'] = tidal_volume.loc[male, 'tidal_volume'] / (50 + 2.3*(tidal_volume.loc[male, 'height'] - 60))\n",
    "tidal_volume.loc[female, 'standardized_tidal_volume'] = tidal_volume.loc[female, 'tidal_volume'] / (45.5 + 2.3*(tidal_volume.loc[female, 'height'] - 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffd2e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltvv = tidal_volume['standardized_tidal_volume'] <= 6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b3eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tidal_volume.loc[ltvv & ~tidal_volume['pipeline_diagnosed'], 'HADM_ID'].nunique(), tidal_volume.loc[~tidal_volume['pipeline_diagnosed'], 'HADM_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c8a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "tidal_volume.loc[ltvv & ~tidal_volume['curt_diagnosed'], 'HADM_ID'].nunique(), tidal_volume.loc[~tidal_volume['curt_diagnosed'], 'HADM_ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2f86e9",
   "metadata": {},
   "source": [
    "### Plateau pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071bec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plateau_proper = plateau_pressure['plateau_pressure'] > 30\n",
    "plateau_pressure.loc[plateau_proper & plateau_pressure['pipeline_diagnosed'], 'HADM_ID'].nunique(), plateau_pressure.loc[plateau_pressure['pipeline_diagnosed'], 'HADM_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08585fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plateau_pressure.loc[plateau_proper & plateau_pressure['curt_diagnosed'], 'HADM_ID'].nunique(), plateau_pressure.loc[plateau_pressure['curt_diagnosed'], 'HADM_ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b452d89",
   "metadata": {},
   "source": [
    "### PF ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b891d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_min = pf.groupby(['encounter_id', 'pipeline_diagnosed', 'curt_diagnosed'])['pf_ratio_value'].min().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f82d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.loc[pipeline_diagnosed, 'pf_ratio_value'].describe(), pf.loc[curt_diagnosed, 'pf_ratio_value'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53459d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.loc[~pipeline_diagnosed, 'pf_ratio_value'].describe(), pf.loc[~curt_diagnosed, 'pf_ratio_value'].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ards",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
